# Dmitriy Rabotyagov <noonedeadpunk@ya.ru>, 2019. #zanata
# Dmitriy Rabotyagov <noonedeadpunk@ya.ru>, 2020. #zanata
# Dmitriy Rabotyagov <noonedeadpunk@ya.ru>, 2022. #zanata
# Dmitriy Rabotyagov <noonedeadpunk@ya.ru>, 2024. #zanata
# Dmitriy Chubinidze <dcu995@gmail.com>, 2025. #zanata
# Ivan Anfimov <lazekteam@gmail.com>, 2025. #zanata
msgid ""
msgstr ""
"Project-Id-Version: openstack-ansible 31.0.0.0b2.dev27\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-04-28 08:23+0000\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"PO-Revision-Date: 2025-04-29 07:06+0000\n"
"Last-Translator: Ivan Anfimov <lazekteam@gmail.com>\n"
"Language-Team: Russian\n"
"Language: ru\n"
"X-Generator: Zanata 4.3.3\n"
"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && n"
"%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2)\n"

msgid ""
"(see: https://docs.openstack.org/os-traits/latest/reference/traits.html)"
msgstr ""
"(см.: https://docs.openstack.org/os-traits/latest/reference/traits.html)"

msgid ""
"1. Persistent proxy configuration is a standard practice and network clients "
"on the target hosts will be able to access external resources after "
"deployment."
msgstr ""
"1. Постоянная конфигурация прокси-сервера является стандартной практикой, и "
"сетевые клиенты на целевых хостах смогут получать доступ к внешним ресурсам "
"после развертывания."

msgid ""
"1. The default configuration file suggests setting a persistent proxy "
"configuration on all target hosts and defines a persistent ``no_proxy`` "
"environment variable which lists all hosts/containers' management addresses "
"as well as the load balancer internal/external addresses."
msgstr ""
"1. Файл конфигурации по умолчанию предлагает установить постоянную "
"конфигурацию прокси-сервера на всех целевых хостах и ​​определяет постоянную "
"переменную среды ``no_proxy``, в которой перечислены все адреса управления "
"хостами/контейнерами, а также внутренние/внешние адреса балансировщика "
"нагрузки."

msgid "10"
msgstr "10"

msgid "16GB RAM"
msgstr "16 ГБ оперативной памяти"

msgid "172.29.236.0/22"
msgstr "172.29.236.0/22"

msgid "172.29.236.0/24"
msgstr "172.29.236.0/24"

msgid "172.29.236.10"
msgstr "172.29.236.10"

msgid "172.29.236.11"
msgstr "172.29.236.11"

msgid "172.29.236.12"
msgstr "172.29.236.12"

msgid "172.29.236.13"
msgstr "172.29.236.13"

msgid "172.29.236.14"
msgstr "172.29.236.14"

msgid "172.29.236.16"
msgstr "172.29.236.16"

msgid "172.29.236.17"
msgstr "172.29.236.17"

msgid "172.29.236.18"
msgstr "172.29.236.18"

msgid "172.29.236.19"
msgstr "172.29.236.19"

msgid "172.29.236.20"
msgstr "172.29.236.20"

msgid "172.29.236.9"
msgstr "172.29.236.9"

msgid "172.29.237.0/24"
msgstr "172.29.237.0/24"

msgid "172.29.237.10"
msgstr "172.29.237.10"

msgid "172.29.237.11"
msgstr "172.29.237.11"

msgid "172.29.237.12"
msgstr "172.29.237.12"

msgid "172.29.237.13"
msgstr "172.29.237.13"

msgid "172.29.237.14"
msgstr "172.29.237.14"

msgid "172.29.237.201"
msgstr "172.29.237.201"

msgid "172.29.237.202"
msgstr "172.29.237.202"

msgid "172.29.237.203"
msgstr "172.29.237.203"

msgid "172.29.238.0/24"
msgstr "172.29.238.0/24"

msgid "172.29.238.11"
msgstr "172.29.238.11"

msgid "172.29.238.12"
msgstr "172.29.238.12"

msgid "172.29.238.201"
msgstr "172.29.238.201"

msgid "172.29.238.202"
msgstr "172.29.238.202"

msgid "172.29.238.203"
msgstr "172.29.238.203"

msgid "172.29.239.0/24"
msgstr "172.29.239.0/24"

msgid "172.29.239.10"
msgstr "172.29.239.10"

msgid "172.29.239.11"
msgstr "172.29.239.11"

msgid "172.29.239.12"
msgstr "172.29.239.12"

msgid "172.29.239.201"
msgstr "172.29.239.201"

msgid "172.29.239.202"
msgstr "172.29.239.202"

msgid "172.29.239.203"
msgstr "172.29.239.203"

msgid "172.29.240.0/22"
msgstr "172.29.240.0/22"

msgid "172.29.240.0/24"
msgstr "172.29.240.0/24"

msgid "172.29.240.10"
msgstr "172.29.240.10"

msgid "172.29.240.11"
msgstr "172.29.240.11"

msgid "172.29.240.12"
msgstr "172.29.240.12"

msgid "172.29.240.13"
msgstr "172.29.240.13"

msgid "172.29.240.14"
msgstr "172.29.240.14"

msgid "172.29.240.16"
msgstr "172.29.240.16"

msgid "172.29.240.17"
msgstr "172.29.240.17"

msgid "172.29.241.0/24"
msgstr "172.29.241.0/24"

msgid "172.29.241.11"
msgstr "172.29.241.11"

msgid "172.29.241.12"
msgstr "172.29.241.12"

msgid "172.29.242.0/24"
msgstr "172.29.242.0/24"

msgid "172.29.242.10"
msgstr "172.29.242.10"

msgid "172.29.242.11"
msgstr "172.29.242.11"

msgid "172.29.242.12"
msgstr "172.29.242.12"

msgid "172.29.243.0/24"
msgstr "172.29.243.0/24"

msgid "172.29.243.10"
msgstr "172.29.243.10"

msgid "172.29.244.0/22"
msgstr "172.29.244.0/22"

msgid "172.29.244.0/24"
msgstr "172.29.244.0/24"

msgid "172.29.244.11"
msgstr "172.29.244.11"

msgid "172.29.244.12"
msgstr "172.29.244.12"

msgid "172.29.244.13"
msgstr "172.29.244.13"

msgid "172.29.244.14"
msgstr "172.29.244.14"

msgid "172.29.244.15"
msgstr "172.29.244.15"

msgid "172.29.244.16"
msgstr "172.29.244.16"

msgid "172.29.244.17"
msgstr "172.29.244.17"

msgid "172.29.244.18"
msgstr "172.29.244.18"

msgid "172.29.244.19"
msgstr "172.29.244.19"

msgid "172.29.244.20"
msgstr "172.29.244.20"

msgid "172.29.244.201"
msgstr "172.29.244.201"

msgid "172.29.244.202"
msgstr "172.29.244.202"

msgid "172.29.244.203"
msgstr "172.29.244.203"

msgid "172.29.245.0/24"
msgstr "172.29.245.0/24"

msgid "172.29.245.10"
msgstr "172.29.245.10"

msgid "172.29.245.11"
msgstr "172.29.245.11"

msgid "172.29.245.12"
msgstr "172.29.245.12"

msgid "172.29.245.201"
msgstr "172.29.245.201"

msgid "172.29.245.202"
msgstr "172.29.245.202"

msgid "172.29.245.203"
msgstr "172.29.245.203"

msgid "172.29.246.0/24"
msgstr "172.29.246.0/24"

msgid "172.29.246.10"
msgstr "172.29.246.10"

msgid "172.29.246.11"
msgstr "172.29.246.11"

msgid "172.29.246.12"
msgstr "172.29.246.12"

msgid "172.29.246.201"
msgstr "172.29.246.201"

msgid "172.29.246.202"
msgstr "172.29.246.202"

msgid "172.29.246.203"
msgstr "172.29.246.203"

msgid "172.29.247.0/24"
msgstr "172.29.247.0/24"

msgid "172.29.247.10"
msgstr "172.29.247.10"

msgid "172.29.247.11"
msgstr "172.29.247.11"

msgid ""
"2. An alternative method applies proxy configuration in a transient manner "
"during the execution of Ansible playbooks and defines a minimum set of "
"management network IP addresses for ``no_proxy`` that are required for the "
"playbooks to succeed. These proxy settings do not persist after an Ansible "
"playbook run and the completed deployment does not require them in order to "
"be functional."
msgstr ""
"2. Альтернативный метод применяет конфигурацию прокси-сервера временно во "
"время выполнения плейбуков Ansible и определяет минимальный набор IP-адресов "
"сети управления для ``no_proxy``, которые требуются для успешного выполнения "
"плейбуков. Эти настройки прокси-сервера не сохраняются после запуска "
"плейбука Ansible, и завершенное развертывание не требует их для "
"функционирования."

msgid ""
"2. The deployer must ensure that a persistent proxy configuration has "
"complete coverage of all OpenStack management network host/containers' IP "
"addresses in the ``no_proxy`` environment variable. It is necessary to use a "
"list of IP addresses, CIDR notation is not valid for ``no_proxy``."
msgstr ""
"2. Оператор должен убедиться, что постоянная конфигурация прокси имеет "
"полное покрытие всех IP-адресов хостов/контейнеров сети управления OpenStack "
"в переменной среды ``no_proxy``. Необходимо использовать список IP-адресов, "
"нотация CIDR недопустима для ``no_proxy``."

msgid "20"
msgstr "20"

msgid "203.0.113.0/28"
msgstr "203.0.113.0/28"

msgid "21"
msgstr "21"

msgid "22"
msgstr "22"

msgid ""
"3. Transient proxy configuration guarantees that proxy environment variables "
"will not persist, ensuring direct communication between services on the "
"OpenStack management network after deployment. Target host network clients "
"such as ``wget`` will not be able to access external resources after "
"deployment."
msgstr ""
"3. Временная конфигурация прокси гарантирует, что переменные среды прокси не "
"будут сохраняться, обеспечивая прямую связь между службами в сети управления "
"OpenStack после развертывания. Клиенты целевой хост-сети, такие как "
"``wget``, не смогут получить доступ к внешним ресурсам после развертывания."

msgid "30"
msgstr "30"

msgid "31"
msgstr "31"

msgid "32"
msgstr "32"

msgid ""
"4. The maximum length of ``no_proxy`` should not exceed 1024 characters due "
"to a fixed size buffer in the ``pam_env`` PAM module. Longer environment "
"variables will be truncated during deployment operations and this will lead "
"to unpredictable errors during or after deployment."
msgstr ""
"4. Максимальная длина ``no_proxy`` не должна превышать 1024 символов из-за "
"фиксированного размера буфера в модуле PAM ``pam_env``. Более длинные "
"переменные среды будут усечены во время операций развертывания, и это "
"приведет к непредсказуемым ошибкам во время или после развертывания."

msgid "400"
msgstr "400"

msgid "50GB free disk space on the root partition"
msgstr "50 Гб свободного дискового пространства на root разделе"

msgid "8 CPU Cores"
msgstr "8 ядер CPU"

msgid "8 vCPU's"
msgstr "8 vCPU"

msgid ""
"80GB free disk space on the root partition, or 60GB+ on a blank secondary "
"disk. Using a secondary disk requires the use of the "
"``bootstrap_host_data_disk_device`` parameter. Please see `Building an AIO`_ "
"for more details."
msgstr ""
"80 Гб свободного дискового пространства, или 60 Гб+ на чистом дополнительном "
"диске. Использование дополнительного диска требует использования параметра "
"``bootstrap_host_data_disk_device``. Пожалуйста, обратитесь к разделу "
"`Установка AIO`_ для деталей."

msgid "8GB RAM"
msgstr "8 ГБ оперативной памяти"

msgid ""
":dev_docs:`Configuring a homogeneous production environment <user/prod/"
"example.html>`"
msgstr ""
":dev_docs:`Настройка однородного рабочего окружения  <user/prod/example."
"html>`"

msgid ":dev_docs:`Configuring a test environment <user/test/example.html>`"
msgstr ":dev_docs:`Настройка тестового окружения <user/test/example.html>`"

msgid ""
":dev_docs:`Configuring the inventory <reference/inventory/configure-"
"inventory.html>`"
msgstr ""
":dev_docs:`Настройка inventory <reference/inventory/configure-inventory."
"html>`"

msgid ""
":dev_docs:`Container networking architecture <reference/architecture/"
"container-networking.html>`"
msgstr ""
":dev_docs:`Сетевая архитектура контейнеров <reference/architecture/container-"
"networking.html>`"

msgid ":dev_docs:`Production environment <user/prod/example.html>`"
msgstr ":dev_docs:`Рабочее окружение <user/prod/example.html>`"

msgid ""
":dev_docs:`Using provider network groups for a heterogeneous environment "
"<user/prod/provnet_groups.html>`"
msgstr ""
":dev_docs:`Использование сетей провайдера для разнородного окружения <user/"
"prod/provnet_groups.html>`"

msgid ""
"A Load Balancer (HAProxy) is usually deployed on infrastructure hosts. With "
"infrastructure hosts being spread across Availability Zones we need to come "
"up with a more complex design which is aimed at solving the following issues:"
msgstr ""
"Балансировщик нагрузки (HAProxy) обычно развертывается на хостах "
"инфраструктуры. Поскольку хосты инфраструктуры распределены по зонам "
"доступности, нам необходимо разработать более сложную конструкцию, "
"направленную на решение следующих проблем:"

msgid "A ``compute_hosts`` group consisting of two compute hosts"
msgstr "Группа ``compute_hosts`` состоит из двух вычислительных хостов"

msgid ""
"A ``network_hosts`` group consisting of three collapsed infrastructure/"
"network (control plane) hosts"
msgstr ""
"Группа ``network_hosts`` состоит из трех инфраструктурных/сетевых "
"(управляющих) хостов"

msgid ""
"A basic compute kit environment, with the Image (glance) and Compute (nova) "
"services set to use file-backed storage."
msgstr ""
"Базовая вычислительная среда со службами образов (glance) и вычислительной "
"службой (nova), настроенными на использование файлового хранилища."

msgid ""
"A deployment with a mixture of architectures, or adding a new architecture "
"to an existing single architecure deployment requires some additional steps "
"to be taken by both the deployer and end users to ensure that the behaviour "
"is as desired."
msgstr ""
"Окружения с различающимися архитектурами, или добавление новой архитектуры в "
"существующие однородное окружение требуют выполнение некоторых "
"дополнительных шагов как для оператора, так и для конечного пользователя, "
"чтобы убедиться в корректности поведения окружения."

msgid ""
"A list of service ports can be found in the `OpenStack Install Guide`__."
msgstr ""
"Список портов служб можно найти в `Руководстве по установке OpenStack`__."

msgid ""
"A selection of network configuration example files are given in the ``etc/"
"network`` and ``etc/netplan`` for ubuntu systems, and it is expected that "
"these will need adjustment for the specific requirements of each deployment."
msgstr ""
"Выборка файлов примеров конфигурации сети приведена в ``etc/network`` и "
"``etc/netplan`` для систем Ubuntu, и ожидается, что их потребуется настроить "
"в соответствии с конкретными требованиями каждого развертывания."

msgid ""
"A self-signed certificate authority is generated on the deploy host during "
"the first run of the playbook."
msgstr ""
"Самоподписанный центр сертификации создается на хосте развертывания во время "
"первого запуска сценария."

msgid ""
"A single RabbitMQ server backend (e.g. server or cluster) is the default "
"deployment for OpenStack-Ansible (OSA). This broker messaging backend "
"provides the queue services for both RPC and Notification communications "
"through its integration with the oslo.messaging rabbit driver. The `oslo-"
"messaging.yml`_ file provides the default configuration to associate the "
"oslo.messaging RPC and Notify services to the RabbitMQ server backend."
msgstr ""
"Единый бекэнд RabbitMQ сервера (сервер или кластер серверов) это стандартная "
"конфигурация развертывания OpenStack-Ansible (OSA). Данный брокер обмена "
"сообщениями предоставляет сервисы очередей как для RPC, так и для обмена "
"уведомлениями при помощи интеграции с rabbit драйвером oslo.messaging. Файл "
"`oslo-messaging.yml`_  предоставляет стандартную настройку для связи oslo."
"messaging сервисов  RPC и уведомлений с RabbitMQ сервером."

msgid ""
"A word of caution: the name of the Ceph alternative lib implementation "
"(ceph_alternative_lib) varies between Gnocchi versions."
msgstr ""
"Небольшое предупреждение: имя альтернативной библиотеки Ceph "
"(ceph_alternative_lib) отличается для различных версий Gnocchi."

msgid "AZ1 Storage Network"
msgstr "Сеть хранения данных AZ1"

msgid "AZ1 Tunnel (Geneve) Network"
msgstr "Туннелированная сеть AZ1 (Geneve)"

msgid "AZ2 Storage Network"
msgstr "Сеть хранения данных AZ2"

msgid "AZ2 Tunnel (Geneve) Network"
msgstr "Туннелированная сеть AZ2 (Geneve)"

msgid "AZ3 Storage Network"
msgstr "Сеть хранения данных AZ3"

msgid "AZ3 Tunnel (Geneve) Network"
msgstr "Туннелированная сеть AZ3 (Geneve)"

msgid "Above example will create following groups:"
msgstr "Пример выше создаст следующие группы:"

msgid "Absolute minimum server resources (currently used for gate checks):"
msgstr ""
"Минимальные системные требования (используются для регулярного тестирования):"

msgid "Add HW_ARCH_XXXX Trait to Every Compute Host in OpenStack."
msgstr ""
"Добавьте признак HW_ARCH_XXXX к каждому вычислительному узлу в OpenStack."

msgid "Add the new compute nodes to ``openstack_user_config.yml``."
msgstr "Добавьте новые вычислительные ноды в ``openstack_user_config.yml``."

msgid "Add them also to your pipeline:"
msgstr "Добавьте их также для обработки в pipeline.yaml:"

msgid "Adding S3 API support"
msgstr "Добавление поддержки S3 API"

msgid "Additional VLANs may be required for the following purposes:"
msgstr "Дополнительные VLAN-ы могут потребоваться для следующих целей:"

msgid ""
"Additional options may be implemented by simply concatenating them with a "
"space between each set of options, for example:"
msgstr ""
"Дополнительные параметры можно указать просто разделив их пробелом, например:"

msgid "Additional resources"
msgstr "Дополнительные ресурсы"

msgid "Advanced security.txt ACL"
msgstr "Расширенный security.txt ACL"

msgid ""
"All public endpoints reside behind HAProxy, resulting in the only "
"certificate management for externally visible https services are those for "
"HAProxy. Certain internal services such as RabbitMQ also require proper SSL "
"configuration."
msgstr ""
"Все публичные точки доступа находятся за HAProxy, в результате чего "
"единственными управляющими сертификатами для внешне видимых https-сервисов "
"являются те сертификаты, которые используются для HAProxy. Некоторые "
"внутренние сервисы, такие как RabbitMQ, также требуют надлежащей "
"конфигурации SSL."

msgid ""
"All the upstream repositories used are defined in the ``openstack-ansible`` "
"integrated repository, in the ``inventory/group_vars/<service_group>/"
"source_git.yml`` file."
msgstr ""
"Все используемые upstream репозитории определены в интегрированном "
"репозиторие ``openstack-ansible``, в файле ``inventory/group_vars/"
"<service_group>/source_git.yml``."

msgid ""
"All-in-one (AIO) builds are a great way to perform an OpenStack-Ansible "
"build for:"
msgstr ""
"Все-в-одном (AIO) - это отличный способ выполнить установку OpenStack-"
"Ansible для:"

msgid ""
"Along with HAProxy configuration we also need to ensure that the endpoint "
"catalog will be populated with correct URIs. Each service has a set of "
"variables that needs to be overridden. Usually such variables have the "
"following format:"
msgstr ""
"Наряду с конфигурацией HAProxy нам также необходимо убедиться, что каталог "
"точек доступа будет заполнен правильными URI. У каждой службы есть набор "
"переменных, которые необходимо переопределить. Обычно такие переменные имеют "
"следующий формат:"

msgid ""
"Alternatively, if the AIO was deployed using the ``metal`` scenario, these "
"files will be available on the host itself."
msgstr ""
"В ином случае, если AIO было развернуто используя ``metal`` сценарий, эти "
"файлы будут доступны непосредственно на хосте."

msgid ""
"Alternatively, you can detect IPs used inside your containers to configure "
"HAProxy binds. This can be done by reffering to ``container_networks`` "
"mapping:"
msgstr ""
"В качестве альтернативы вы можете обнаружить IP-адреса, используемые внутри "
"ваших контейнеров для настройки привязок HAProxy. Это можно сделать, "
"обратившись к сопоставлению ``container_networks``:"

msgid ""
"Alternatively, you can simply ignore SSL issues by setting ``verify: false`` "
"in the definition for your cloud in ``clouds.yaml``. This will disable SSL "
"verification entirely for this cloud. For example:"
msgstr ""
"В качестве альтернативы вы можете просто игнорировать проблемы SSL, "
"установив ``verify: false`` для вашего облака в ``clouds.yaml``. Это "
"полностью отключит проверку SSL для этого облака. Например:"

msgid ""
"Although AIO builds aren't recommended for large production deployments, "
"they're great for smaller proof-of-concept deployments."
msgstr ""
"Хоть AIO и не рекомендуется для больших рабочих окружений, он отлично "
"подходит для небольших установок для проверки концепта."

msgid ""
"Although most CPU hardware traits such as instruction set extensions are "
"detected and handled automatically in OpenStack, CPU architecture is not. It "
"is necessary to manually add an architecture trait to the resource provider "
"corresponding to every compute host. The required traits are:"
msgstr ""
"Хотя большинство аппаратных спецификаций, таких как набор инструкций и "
"расширений, определяются автоматически в OpenStack, то архитектура "
"процессора не определяется. Необходимо вручную добавить спецификацию "
"архитектуры в провайдер ресурсов, который соответствует каждому "
"вычислительному хосту. Следующие спецификации необходимы:"

msgid "Amazon S3"
msgstr "Amazon S3"

msgid ""
"An additional provider interface definition named ``physnet2`` using "
"different interfaces between hosts may resemble the following:"
msgstr ""
"Дополнительный интерфейс провайдера с именем ``physnet2`` использующий "
"различные интерфейсы между хостами может быть настроен следующим образом:"

msgid ""
"Another challenge is to organize shared storage for Glance Images, as "
"``rbd`` can't be used consistently anymore. While Glance Interoperable "
"Import interface could be leveraged for syncing images between ``rbd`` "
"backends, in fact not all clients and services can work with Glances `import "
"API <https://docs.openstack.org/api-ref/image/v2/#interoperable-image-"
"import>`_. One of the most obvious solutions here can be usage of Swift API, "
"while configuring Ceph RadosGW policy to replicate the bucket between "
"independent instances located in their Availability Zones."
msgstr ""
"Еще одна проблема заключается в организации общего хранилища для образов "
"Glance, поскольку ``rbd`` больше не может использоваться согласованно. Хотя "
"интерфейс Glance Interoperable Import можно использовать для синхронизации "
"образов между ``rbd`` бекэндами, на самом деле не все клиенты и службы могут "
"работать с `import API <https://docs.openstack.org/api-ref/image/v2/"
"#interoperable-image-import>`_ Glance. Одним из наиболее очевидных решений "
"здесь может быть использование Swift API при настройке политики Ceph RadosGW "
"для репликации контейнера между независимыми инстансами, расположенными в их "
"зонах доступности."

msgid "Apply ansible-hardening"
msgstr "Применение ansible-hardening"

msgid ""
"Architectural decisions by the deployer to isolate the OpenStack networks"
msgstr "Архитектурные решения оператора изолировать сети OpenStack"

msgid "Architecture emulation by Nova"
msgstr "Эмуляция архитектуры при помощи Nova"

msgid ""
"As IP provisioning is quite random inside containers, it may not always be "
"handy to bind HAProxy to a specific IP address. If that's the case, you can "
"bind HAProxy to an interface instead, since we always know the interface "
"names inside containers. With that keepalived public/internal VIPs are "
"supposed to be added in ``used_ips``, so you still can define them freely."
msgstr ""
"Поскольку предоставление IP-адресов внутри контейнеров довольно случайно, не "
"всегда может быть удобно привязывать HAProxy к определенному IP-адресу. Если "
"это так, вы можете привязать HAProxy к интерфейсу, поскольку мы всегда знаем "
"имена интерфейсов внутри контейнеров. При этом предполагается, что публичные/"
"внутренние VIP-адреса keepalived будут добавлены в ``used_ips``, поэтому вы "
"по-прежнему можете свободно их определять."

msgid ""
"As a prerequisite for this type of setup you need to ensure that "
"corresponding `A` or `CNAME` records are present for your domain. Also, you "
"need to ensure having a valid wildcard or SAN certificates for public/"
"internal endpoints."
msgstr ""
"В качестве предварительного условия для этого типа настройки вам необходимо "
"убедиться, что соответствующие записи `A` или `CNAME` присутствуют для "
"вашего домена. Также вам необходимо убедиться, что у вас есть действительные "
"wildcard или сертификаты SAN для публичных/внутренних точек доступа."

msgid ""
"As for this environment, the load balancer is created in the LXC containers "
"on the infrastructure hosts, we need to ensure absence of the default route "
"on ``eth0`` interface. To prevent that from happening, we override "
"``lxc_container_networks`` in ``/etc/openstack_deploy/group_vars/haproxy/"
"lxc_network.yml`` file:"
msgstr ""
"Что касается этой среды, то балансировщик нагрузки создается в контейнерах "
"LXC на хостах инфраструктуры, где нам нужно обеспечить отсутствие маршрута "
"по умолчанию на интерфейсе ``eth0``. Чтобы этого не произошло, мы "
"переопределяем ``lxc_container_networks`` в файле ``/etc/openstack_deploy/"
"group_vars/haproxy/lxc_network.yml``:"

msgid ""
"As the AIO includes all three cluster members of MariaDB/Galera, the cluster "
"has to be re-initialized after the host is rebooted."
msgstr ""
"Так как на AIO расположены все три участника кластера MariaDB/Galera, "
"кластер должен быть повторно инициализирован после перезагрузки сервера."

msgid ""
"As we are using Ceph for this environment, so the ``cinder-volume`` runs in "
"a container on the Ceph Monitor hosts. To achieve this, implement ``/etc/"
"openstack_deploy/env.d/cinder.yml`` with the following content:"
msgstr ""
"Поскольку мы используем Ceph для этой среды, ``cinder-volume`` запускается в "
"контейнере на хостах Ceph Monitor. Чтобы добиться этого, реализуйте ``/etc/"
"openstack_deploy/env.d/cinder.yml`` со следующим содержимым:"

msgid ""
"As well as load balancing public endpoints, HAProxy is also used to load "
"balance internal connections."
msgstr ""
"Помимо балансировки нагрузки публичных точек доступа, HAProxy также "
"используется для балансировки нагрузки внутренних соединений."

msgid ""
"As you might have spotted, we are defining a default route for the container "
"through eth20. However, by default all containers have their default route "
"through eth0, which is a local LXC bridge where address is recieved through "
"DHCP. In order to avoid a conflict, you need to ensure that the default "
"route will not be set for eth0 inside the container. For that, create a file "
"`/etc/openstack_deploy/group_vars/haproxy` with the following content:"
msgstr ""
"Как вы могли заметить, мы определяем маршрут по умолчанию для контейнера "
"через eth20. Однако по умолчанию все контейнеры имеют свой маршрут по "
"умолчанию через eth0, который является локальным мостом LXC, где адрес "
"получается через DHCP. Чтобы избежать конфликта, вам нужно убедиться, что "
"маршрут по умолчанию не будет установлен для eth0 внутри контейнера. Для "
"этого создайте файл `/etc/openstack_deploy/group_vars/haproxy` со следующим "
"содержимым:"

msgid ""
"As you might see, `href` is pointing not to the expected location. While "
"some clients may not refer to href link provided by service, others might "
"use it as source of truth and which will result in failures."
msgstr ""
"Как вы могли заметить, `href` указывает не на ожидаемое местоположение. Хотя "
"некоторые клиенты могут не ссылаться на ссылку href, предоставленную "
"сервисом, другие могут использовать ее как источник истины, что приведет к "
"сбоям."

msgid "Bare metal systems with SSD storage: ~ 30-50 minutes"
msgstr "Физические серверы с SSD накопителем: ~30-50 минут"

msgid "Before creating custom groups, please review the following:"
msgstr ""
"Перед созданием пользовательских групп, пожалуйста, ознакомьтесь со "
"следующим:"

msgid "Before reading this document, please review the following scenario:"
msgstr ""
"Перед прочтением данного документа, пожалуйста, ознакомьтесь со следующим "
"сценарием:"

msgid ""
"Before rebooting, in ``/etc/sysconfig/selinux``, make sure that "
"``SELINUX=enforcing`` is changed to ``SELINUX=disabled``. SELinux enabled is "
"not currently supported in OpenStack-Ansible for CentOS/Rocky/RHEL due to a "
"lack of maintainers for the feature."
msgstr ""
"Перед перезагрузкой убедитесь, что в ``/etc/sysconfig/selinux`` параметр "
"``SELINUX=enforcing`` установлен в значение ``SELINUX=disabled``. SELinux на "
"данный момент не поддерживается в OpenStack-Ansible для CentOS/Rocky/RHEL из-"
"за нехватки ресурсов для сопровождения данной возможности."

msgid ""
"Below you can find an example for defining endpoints for Keystone and Nova:"
msgstr ""
"Ниже вы можете найти пример определения точек доступа для Keystone и Nova:"

msgid "Bootstrap Ansible and the required roles"
msgstr "Начальная подготовка Ansible и требуемых ролей"

msgid "Bootstrap the AIO configuration"
msgstr "Начальная подготовка конфигурации AIO"

msgid "Building an AIO"
msgstr "Установка AIO"

msgid ""
"But this approach is not correct and will result in issues in some clients "
"or use cases, despite the service appearing completely functional. The "
"problem with the approach above is related to how services return the `self` "
"URL when it's asked for. Most services will reply with their current micro-"
"version and URI to this micro-version in reply."
msgstr ""
"Но этот подход не является правильным и приведет к проблемам в некоторых "
"клиентах или вариантах использования, несмотря на то, что служба выглядит "
"полностью функциональной. Проблема с подходом выше связана с тем, как службы "
"возвращают `self` URL, когда его запрашивают. Большинство служб ответят "
"своей текущей микроверсией и URI этой микроверсии в ответе."

msgid ""
"But when your setup grows, gnocchi might slow down or block your ceph "
"installation. You might experience slow requests and stuck PGs in your Ceph. "
"As this might have multiple causes, take a look at the presentations linked "
"in the `Performance Tests for Gnocchi`_ section. They also include various "
"parameters which you might tune."
msgstr ""
"Но когда ваша установка вырастет, gnocchi может замедлять или блокировать "
"ваш ceph. Вы можете столкнуться с медленными запросами или заблокированными "
"PG в ceph. Так как это может иметь несколько причин, взгляните на "
"прикрепленные презентации в секции `Тесты производительности для Gnocchi`_. "
"Они также содержат различные параметры, которые вы можете захотеть "
"оптимизировать."

msgid ""
"By default the AIO bootstrap scripts deploy a base set of OpenStack services "
"with sensible defaults for the purpose of a gate check, development or "
"testing system."
msgstr ""
"По умолчанию скрипты подготовки AIO разворачивают базовый набор сервисов "
"OpenStack с благоразумными настройками по умолчанию для автоматических "
"тестов, разработки или проверки работы систем."

msgid ""
"By default this header is set to block access to all features apart from the "
"following from the same origin; fullscreen, clipboard read, clipboard write "
"and spatial navigation."
msgstr ""
"По умолчанию этот заголовок настроен на блокировку доступа ко всем функциям, "
"за исключением следующих из того же источника: полноэкранный режим, чтение "
"буфера обмена, запись буфера обмена и пространственная навигация."

msgid "By default, OSA enables *only* the Swift API in radosgw."
msgstr "По умолчанию, OSA включает *только* Swift API в radosgw."

msgid ""
"By default, OpenStack-Ansible does not secure connections to the internal "
"VIP. To enable this you must set the following variables in the ``/etc/"
"openstack_deploy/user_variables.yml`` file:"
msgstr ""
"По умолчанию OpenStack-Ansible не защищает соединения с внутренним VIP. "
"Чтобы включить это, необходимо задать следующие переменные в файле ``/etc/"
"openstack_deploy/user_variables.yml``:"

msgid ""
"By default, OpenStack-Ansible uses port-based endpoints. This means, that "
"each service will be served on its own unique port for both public and "
"internal endpoints. For example, Keystone will be added as ``https://domain."
"com:5000/v3``, Nova as ``https://domain.com:8774/v2.1`` and so on."
msgstr ""
"По умолчанию OpenStack-Ansible использует точки доступа на основе портов. "
"Это означает, что каждая служба будет обслуживаться на своем собственном "
"уникальном порту как для публичных, так и для внутренних точек доступа. "
"Например, Keystone будет добавлен как ``https://domain.com:5000/v3``,  а "
"Nova как ``https://domain.com:8774/v2.1`` и так далее."

msgid ""
"By default, self-signed certificates will be used to secure traffic but user-"
"provided certificates are also supported."
msgstr ""
"По умолчанию для защиты трафика будут использоваться самоподписанные "
"сертификаты, но также поддерживаются сертификаты, предоставленные "
"пользователем."

msgid ""
"By default, the Content Security Policy (CSP) enables a minimum set of "
"resources to allow Horizon to work, which includes access the Nova console. "
"If you require access to other resources these can be set by overriding the "
"``haproxy_security_headers_csp`` variable in the ``/etc/openstack_deploy/"
"user_variables.yml`` file."
msgstr ""
"По умолчанию политика безопасности контента (CSP) включает минимальный набор "
"ресурсов, позволяющий Horizon работать, включая доступ к консоли Nova. Если "
"вам требуется доступ к другим ресурсам, их можно задать, переопределив "
"переменную ``haproxy_security_headers_csp`` в файле ``/etc/openstack_deploy/"
"user_variables.yml``."

msgid ""
"By design, this header is difficult to disable once set. It is recommended "
"that during testing you set a short time of 1 day and after testing increase "
"the time to 1 year."
msgstr ""
"По замыслу этот заголовок трудно отключить после установки. Рекомендуется во "
"время тестирования установить короткое время в 1 день, а после тестирования "
"увеличить время до 1 года."

msgid "CIDR"
msgstr "CIDR"

msgid "CPU/motherboard that supports `hardware-assisted virtualization`_"
msgstr "Процессор/материнская плата поддерживают `аппаратную виртуализацию`_"

msgid "Ceilometer Changes"
msgstr "Изменения Ceilometer"

msgid ""
"Ceilometer needs additional pip packages to talk to Ceph Rados Gateway. To "
"install it, edit the default ceilometer_pip_packages in your user_variables."
"yml file:"
msgstr ""
"Для ceilometer требуются дополнительные pip пакеты для взаимодействия с Ceph "
"Rados Gateway. Для их установки отредактируйте ceilometer_pip_packages в "
"файле user_variables.yml:"

msgid "Ceph (preferred)"
msgstr "Ceph (рекомендован)"

msgid "Ceph Changes"
msgstr "Изменения Ceph"

msgid "Ceph as metric storage"
msgstr "Ceph, как хранилище метрик"

msgid "Ceph production example"
msgstr "Пример настройки Ceph в рабочем окружении"

msgid "Certbot certificates"
msgstr "Сертификаты Certbot"

msgid ""
"Certbot defaults to using Let's Encrypt as the Certificate Authority, other "
"Certificate Authorities can be used by setting the "
"``haproxy_ssl_letsencrypt_certbot_server`` variable in the ``/etc/"
"openstack_deploy/user_variables.yml`` file:"
msgstr ""
"По умолчанию Certbot использует Let's Encrypt в качестве центра "
"сертификации. Другие центры сертификации можно использовать, установив "
"переменную ``haproxy_ssl_letsencrypt_certbot_server`` в файле ``/etc/"
"openstack_deploy/user_variables.yml``:"

msgid ""
"Changes will not apply to any existing running guests on the compute node, "
"so this configuration should be done before launching any instances. For "
"existing deployments it is recommended that you migrate instances off the "
"compute node before enabling."
msgstr ""
"Изменения не будут применяться к существующим запущенным гостевым ОС на "
"вычислительном узле, поэтому эту настройку следует выполнить до запуска "
"любых инстансов. Для существующих развертываний рекомендуется перенести "
"инстансы с вычислительного узла перед включением."

msgid ""
"Clone OpenStack-Ansible repository to home user directory. It means, that "
"instead of ``/opt/openstack-ansible`` repository will be in ``~/openstack-"
"ansible``."
msgstr ""
"Склонируйте репозиторий OpenStack-Ansible в домашний каталог пользователя. "
"Это значит, что вместо ``/opt/openstack-ansible`` репозиторий будет в ``~/"
"openstack-ansible``."

msgid ""
"Communication between HAProxy and service backends can be encrypted. "
"Currently it is disabled by default. It can be enabled for all services by "
"setting the following variable:"
msgstr ""
"Связь между HAProxy и бекэндами сервисов может быть зашифрована. В настоящее "
"время по умолчанию она отключена. Ее можно включить для всех сервисов, "
"установив следующую переменную:"

msgid "Compute hosts act as OVN gateway hosts"
msgstr "Вычислительные хосты действуют как шлюзы OVN"

msgid "Configuration examples"
msgstr "Примеры конфигурации"

msgid "Configure Nova Scheduler to Check Architecture."
msgstr "Настройте Nova Scheduler для проверки архитектуры."

msgid ""
"Configure the ``bootstrap-ansible.sh`` script used to install Ansible and "
"Ansible role dependencies on the deployment host to use a proxy by setting "
"the environment variables ``HTTPS_PROXY`` or ``HTTP_PROXY``."
msgstr ""
"Скрипт ``bootstrap-ansible.sh``, используемый для установки Ansible и "
"зависимостей Ansible ролей на хосте развертывания, использует настройки "
"прокси, заданные переменными окружения ``HTTPS_PROXY`` или ``HTTP_PROXY``."

msgid "Configuring HAProxy binding inside containers"
msgstr "Настройка привязки HAProxy внутри контейнеров"

msgid "Configuring domain-based endpoints (recommended)"
msgstr "Настройка точек доступа на основе домена (рекомендуется)"

msgid "Configuring network interfaces"
msgstr "Настройка сетевых интерфейсов"

msgid "Configuring path-based endpoints"
msgstr "Настройка точек доступа на основе пути"

msgid "Considerations when proxying TLS traffic"
msgstr "Важные моменты при проксировании TLS трафика"

msgid "Content Security Policy (CSP)"
msgstr "Content Security Policy (CSP)"

msgid ""
"Copy your SSL certificate, key, and CA certificate files to the deployment "
"host."
msgstr ""
"Скопируйте ваш SSL сертификат, ключ и промежуточные сертификаты на хост "
"развертывания."

msgid "Create containers for Zookeeper:"
msgstr "Создайте контейнеры для Zookeeper:"

msgid "Creating containers"
msgstr "Создание контейнеров"

msgid "Custom Groups"
msgstr "Пользовательские группы"

msgid ""
"Custom inventory groups can be created to assist in segmenting hosts beyond "
"the built-in groups provided by OpenStack-Ansible."
msgstr ""
"Пользовательские группы в inventory могут быть созданы для помощи в "
"сегментации хостов над встроенными группами, создаваемыми OpenStack-Ansible."

msgid ""
"Declare Ceph Rados Gateway as object-store in your ceilometer.conf file by "
"adding this to your user_variables.yml file:"
msgstr ""
"Объявите Ceph Rados Gateway как объектное хранилище в файле ceilometer.conf, "
"добавив следующее в ваш файл user_variables.yml:"

msgid "Define 6 keepalived instances: 3 for public and 3 for internal VIPs"
msgstr ""
"Определение 6 инстансов keepalived: 3 для публичных и 3 для внутренних VIP-"
"адресов"

msgid ""
"Define Internal API FQDN through /etc/hosts overrides, which are unique per "
"Availability Zone"
msgstr ""
"Определение FQDN внутреннего API с помощью переопределений /etc/hosts, "
"которые являются уникальными для каждой зоны доступности"

msgid "Define ``ansible_remote_tmp: /tmp`` in user_variables.yml"
msgstr "Задайте ``ansible_remote_tmp: /tmp`` в user_variables.yml"

msgid "Define ``ansible_user: <USER>`` in user_variables.yml"
msgstr "Определите ``ansible_user: <USER>`` в user_variables.yml"

msgid ""
"Define the contents of ``security.txt`` in the variable "
"``haproxy_security_txt_content`` in the ``/etc/openstack_deploy/"
"user_variables.yml`` file:"
msgstr ""
"Определите содержимое ``security.txt`` в переменной "
"``haproxy_security_txt_content`` в файле ``/etc/openstack_deploy/"
"user_variables.yml``:"

msgid "Define the following environment variable:"
msgstr "Определите следующую переменную окружения:"

msgid ""
"Define the group and its members in a corresponding file in ``/etc/"
"openstack_deploy/conf.d/``. The following is an example of a group named "
"``custom2_hosts`` defined in ``/etc/openstack_deploy/conf.d/custom2_hosts."
"yml`` consisting of a single member, ``compute2``:"
msgstr ""
"Определите группу и ее участников в соответствующем файле внутри ``/etc/"
"openstack_deploy/conf.d/``. Следующий пример содержит группу с названием "
"``custom2_hosts``, определенную в ``/etc/openstack_deploy/conf.d/"
"custom2_hosts.yml`` и содержащую единственного участника - ``compute2``:"

msgid ""
"Define the user that will be used for for connections from the deploy host "
"to the ansible target hosts. In case the user is the same for all hosts in "
"your deployment, you can do it in one of following ways:"
msgstr ""
"Определите пользователя, который будет использоваться для подключений от "
"хоста развертывания к целевым хостам ansible. Если пользователь один и тот "
"же для всех хостов в вашем развертывании, вы можете сделать это одним из "
"следующих способов:"

msgid "Defining container networking"
msgstr "Настройка сети контейнера"

msgid "Defining host networking"
msgstr "Настройка сети хоста"

msgid ""
"Deployed files in ``/etc/openstack_deploy/env.d`` allow the customization of "
"Ansible groups."
msgstr ""
"Развернутые файлы в ``/etc/openstack_deploy/env.d`` позволяют настраивать "
"группы Ansible."

msgid ""
"Deployers can configure the script to source Ansible from an alternate Git "
"repository by setting the environment variable ``ANSIBLE_GIT_REPO``. Also, "
"during initial bootstrap you might need to define a custom URL for upper-"
"constraints file that is part of `openstack/requirements` repository, using "
"the TOX_CONSTRAINTS_FILE environment variable."
msgstr ""
"Операторы могут настроить скрипт на получение Ansible из альтернативного "
"репозитория Git, установив переменную окружения ``ANSIBLE_GIT_REPO``. Кроме "
"того, во время начальной загрузки вам может потребоваться определить "
"пользовательский URL для файла upper-constraints, который является частью "
"репозитория `openstack/requirements`, используя переменную окружения "
"TOX_CONSTRAINTS_FILE."

msgid ""
"Deployers can configure the script to source Ansible role dependencies from "
"alternate locations by providing a custom role requirements file and "
"specifying the path to that file using the environment variable "
"``ANSIBLE_ROLE_FILE``."
msgstr ""
"Операторы могут настроить скрипт для получения зависимостей ролей Ansible из "
"альтернативных расположений, предоставив файл требований к пользовательской "
"роли и указав путь к этому файлу с помощью переменной среды "
"``ANSIBLE_ROLE_FILE``."

msgid ""
"Deployers do not have to use ``root`` user accounts on deploy or target "
"hosts. This approach works out of the box by leveraging `Ansible privilege "
"escalation`_."
msgstr ""
"Операторам не нужно использовать учетные записи пользователя ``root`` на "
"хостах развертывания или целевых хостах. Этот подход работает из коробки, "
"используя `Ansible privilege escalation`_."

msgid ""
"Deploying ceph cluster as part of OpenStack-Ansible is not recommended since "
"ceph-ansible upgrade path is not tested or supported. This option is mainly "
"used for CI and AIO deployments to test and demonstrate a sample integration "
"of the software stack."
msgstr ""
"Развертывание кластера ceph как части OpenStack-Ansible не рекомендуется, "
"поскольку путь обновления ceph-ansible не тестировался и не поддерживается. "
"Этот вариант в основном используется для развертываний CI и AIO для "
"тестирования и демонстрации примера интеграции программного стека."

msgid "Deployment configuration"
msgstr "Настройка развертывания"

msgid "Deployment host proxy configuration for bootstrapping Ansible"
msgstr "Настройка прокси на хосте развертывания для подготовки Ansible"

msgid "Deployment hosts"
msgstr "Хосты развертывания"

msgid ""
"Deployment of certificates using Let's Encrypt has been validated for "
"OpenStack-Ansible using Ubuntu 22.04 (Jammy Jellyfish). Other distributions "
"should work but are not tested."
msgstr ""
"Развертывание сертификатов с использованием Let's Encrypt было проверено для "
"OpenStack-Ansible с использованием Ubuntu 22.04 (Jammy Jellyfish). Другие "
"дистрибутивы должны работать, но не тестировались."

msgid ""
"Deployments consisting entirely of x86_64 or aarch64 nodes do not need any "
"special consideration and will work according to the normal OpenStack-"
"Ansible documentation."
msgstr ""
"Окружения, которые полностью состоят из x86_64 или aarch64 серверов не "
"нуждаются в дополнительных настройках и будут работать согласно стандартной "
"документации OpenStack-Ansible."

msgid ""
"Deployments may encounter limited external connectivity for a number of "
"reasons:"
msgstr ""
"Установки могут сталкиваться с ограниченным внешним соединением по ряду "
"причин:"

msgid "Destination hosts"
msgstr "Хосты назначения"

msgid ""
"Differences in network interface names may be the result of a difference in "
"drivers and/or PCI slot locations."
msgstr ""
"Различие в именах сетевых интерфейсов может быть результатом в использовании "
"различных драйверов и/или слотов PCI."

msgid "Disable QEMU Emulation."
msgstr "Отключите эмуляцию QEMU."

msgid "Distribution specific packages"
msgstr "Специфичные для дистрибутивов пакеты"

msgid ""
"Domain-based endpoints do separate direct requests to specific services "
"based on FQDNs. Usually for this purpose subdomains are used. For example, "
"Keystone endpoint may look like ``https://identity.domain.com`` while Nova "
"endpoint can be like ``https://compute.domain.com``."
msgstr ""
"Доменные точки доступа выполняют отдельные прямые запросы к определенным "
"службам на основе полных доменных имен. Обычно для этой цели используются "
"поддомены. Например, точка доступа Keystone может выглядеть как ``https://"
"identity.domain.com``, а конечная точка Nova может выглядеть как ``https://"
"compute.domain.com``."

msgid ""
"Each host does require the correct network bridges to be implemented. In "
"this example, we leverage the ``systemd_networkd`` role that performs "
"configuration for us during ``openstack_hosts`` execution. It creates all "
"required vlans and bridges. The only pre-requirement is to have a connection "
"to the host via SSH available for Ansible to manage the host."
msgstr ""
"Для каждого хоста требуется реализация правильных сетевых мостов. В этом "
"примере мы используем роль ``systemd_networkd``, которая выполняет настройку "
"для нас во время выполнения ``openstack_hosts``. Она создает все необходимые "
"vlan и мосты. Единственное предварительное требование — иметь подключение к "
"хосту через SSH, доступное для Ansible для управления хостом."

msgid ""
"Each host will require the correct network bridges to be implemented. The "
"following is the ``/etc/network/interfaces`` file for ``infra1`` using a "
"single bond."
msgstr ""
"На каждом хосте потребуется настроить корректные сетевые мосты. Ниже "
"представлено содержимое файла ``/etc/network/interfaces`` для ``infra1`` с "
"использованием одного агрегированного интерфейса."

msgid ""
"Each host will require the correct network bridges to be implemented. The "
"following is the ``/etc/network/interfaces`` file for ``infra1`` using "
"multiple bonded interfaces."
msgstr ""
"На каждом хосте потребуется настроить корректные сетевые мосты. Ниже "
"представлено содержимое файла ``/etc/network/interfaces`` для ``infra1`` с "
"использованием нескольких агрегированных интерфейсов."

msgid ""
"Each host will require the correct network bridges to be implemented. The "
"following is the ``/etc/network/interfaces`` file for ``infra1``."
msgstr ""
"На каждом сервере должны быть настроены корректные сетевые мосты. Ниже мы "
"приводим файл ``/etc/network/interfaces`` для ``infra1``."

msgid ""
"Eight compute hosts, 2 compute hosts in each Availability Zone. First "
"Availability Zone has two extra compute hosts for pinned CPU aggregate."
msgstr ""
"Восемь вычислительных хостов, 2 вычислительных хоста в каждой зоне "
"доступности. Первая зона доступности имеет два дополнительных вычислительных "
"хоста для привязки CPU."

msgid ""
"Enabling TLS on the internal VIP for existing deployments will cause some "
"downtime, this is because HAProxy only listens on a single well known port "
"for each OpenStack service and OpenStack services are configured to use http "
"or https. This means once HAProxy is updated to only accept HTTPS "
"connections, the OpenStack services will stop working until they are updated "
"to use HTTPS."
msgstr ""
"Включение TLS на внутреннем VIP для существующих развертываний приведет к "
"некоторому простою, это связано с тем, что HAProxy прослушивает только один "
"известный порт для каждой службы OpenStack, а службы OpenStack настроены на "
"использование http или https. Это означает, что после обновления HAProxy для "
"приема только HTTPS-соединений службы OpenStack перестанут работать, пока "
"они не будут обновлены для использования HTTPS."

msgid "Enabling security.txt"
msgstr "Включение security.txt"

msgid ""
"Ensure HAProxy to prioritize a backend from own Availability Zone over "
"\"remote\" ones"
msgstr ""
"Проверка того, что HAProxy отдает приоритет бекэнду из собственной зоны "
"доступности над \"удалёнными\""

msgid ""
"Ensure a host of each compute architecture is present in ``repo-"
"infra_hosts`` in ``openstack_user_config.yml``."
msgstr ""
"Убедитесь, что как минимум один хост каждой архитектуры присутвует в группе "
"``repo-infra_hosts`` в ``openstack_user_config.yml``."

msgid "Environment customizations"
msgstr "Индивидуальная настройка окружения"

msgid "Environment layout"
msgstr "Настройка окружения"

msgid "Example"
msgstr "Пример"

msgid "Example - adding ``aarch64`` nodes to an ``x86_64`` deployment"
msgstr "Пример - добавление ``aarch64`` серверов в ``x86_64`` окружение"

msgid ""
"Example assumes that default gateway is set through ``bond0`` interface, "
"which aggregates ``eth0`` and ``eth1`` links. If your environment does not "
"have ``eth0``, but instead has ``p1p1`` or some other interface name, ensure "
"that references to ``eth0`` are replaced with the appropriate name. The same "
"applies to additional network interfaces"
msgstr ""
"В примере предполагается, что шлюз по умолчанию установлен через интерфейс "
"``bond0``, который объединяет ссылки ``eth0`` и ``eth1``. Если в вашей среде "
"нет ``eth0``, но вместо этого есть ``p1p1`` или какое-либо другое имя "
"интерфейса, убедитесь, что ссылки на ``eth0`` заменены соответствующим "
"именем. То же самое относится к дополнительным сетевым интерфейсам"

msgid "Example bellow shows a possible content in ``user_variables.yml``:"
msgstr "В примере ниже показано возможное содержимое ``user_variables.yml``:"

msgid ""
"Example below does not represent a correct approach on how to configure path-"
"based endpoint for most services"
msgstr ""
"Пример ниже не отображает правильный подход к настройке точки доступа на "
"основе пути для большинства служб"

msgid "Example internet dependencies"
msgstr "Примеры зависимостей"

msgid "Example of multi-AZ environment configuration"
msgstr "Пример конфигурации среды с несколькими зонами AZ"

msgid "Example repositories to mirror (Ubuntu target hosts):"
msgstr "Пример репозиториев для зеркалирования (Ubuntu на целевых хостах):"

msgid "Execute the following commands and scripts as the root user."
msgstr "Выполните следующие команды от имени root пользователя."

msgid "External connectivity required to be via HTTP or SOCKS proxies"
msgstr "Внешнее соединение осуществляется через HTTP или SOCKS прокси"

msgid "External provider networks for Floating IPs and instances"
msgstr "Внешние сети провайдера для плавающих IP и инстансов"

msgid "Federated Login"
msgstr "Федеративный вход"

msgid "File (default)"
msgstr "Файл (по умолчанию)"

msgid "Finally, run the playbooks by executing:"
msgstr "Наконец, запустите плейбуки выполнив:"

msgid ""
"Finally, you can also opt to disable SSL certificate configuration during "
"initial deployment or opt to use an external certificate authority for "
"signing, such as Let's Encrypt. Both topics are outside the scope of this "
"document."
msgstr ""
"Наконец, вы также можете отключить конфигурацию сертификата SSL во время "
"первоначального развертывания или использовать внешний центр сертификации "
"для подписи, например Let's Encrypt. Обе темы выходят за рамки этого "
"документа."

msgid "Firewall rules which block external connectivity"
msgstr "Правила брандмауэра, которые блокируют внешнее соединение"

msgid ""
"First, there is only a single controller in any given Availability Zone, "
"while multiple copies of ``cinder_volume`` needs to be run for each storage "
"provider for High Availability. As ``cinder_volume`` needs access to storage "
"network, one of the best places for it are ``ceph-mon`` hosts."
msgstr ""
"Во-первых, в любой зоне доступности есть только один контроллер, в то время "
"как для высокой доступности необходимо запустить несколько копий "
"``cinder_volume`` для каждого провайдера хранилища. Поскольку "
"``cinder_volume`` нужен доступ к сети хранения, одним из лучших мест для "
"него являются хосты ``ceph-mon``."

msgid ""
"For a ceph environment, you can run the ``cinder-volume`` in a container. To "
"do this you will need to create a ``/etc/openstack_deploy/env.d/cinder.yml`` "
"file with the following content:"
msgstr ""
"Для ceph окружения, вы можете запускать ``cinder-volume`` в контейнере. Что "
"бы сделать это, вам нужно создать файл ``/etc/openstack_deploy/env.d/cinder."
"yml`` со следующим содержанием:"

msgid ""
"For added trust in highly secure environments, you can provide your own SSL "
"certificates, keys, and CA certificates. Acquiring certificates from a "
"trusted certificate authority is outside the scope of this document, but the "
"`Certificate Management`_  section of the Linux Documentation Project "
"explains how to create your own certificate authority and sign certificates."
msgstr ""
"Для большего доверия в высоконадежных окружениях, вы можете предоставить "
"собственный SSL сертификат, ключи и промежуточные сертификаты. Получение "
"сертификатов из доверенного центра сертификации находится за пределами "
"данного документа, но раздел `Управление Сертификатами`_ Linux Documentation "
"Project объясняет как создать свой собственный центр сертификации и "
"подписывать сертификаты."

msgid ""
"For each AZ, a group will need to be defined containing all hosts within "
"that AZ."
msgstr ""
"Для каждой AZ необходимо будет определить группу, содержащую все хосты в "
"этой AZ."

msgid ""
"For each pod, a group will need to be defined containing all hosts within "
"that pod."
msgstr ""
"Для каждого блока должна быть задана группа, содержащая все хосты для "
"данного блока."

msgid "For example to install ansible version 2.5.0:"
msgstr "Например, для установки версии ansible 2.5.0:"

msgid ""
"For example, Keystone can be configured as ``https://domain.com/identity/"
"v3`` while Nova as ``https://domain.com/compute/v2.1``"
msgstr ""
"Например, Keystone можно настроить как ``https://domain.com/identity/v3``, а "
"Nova как ``https://domain.com/compute/v2.1``"

msgid ""
"For example, if you want to override ``glance`` repository with your own, "
"you need to define the following:"
msgstr ""
"Например, если вы хотите переопределить репозиторий ``glance`` своим "
"собственным, вам необходимо определить следующее:"

msgid ""
"For in-depth technical information, see the :dev_docs:`OpenStack-Ansible "
"Reference <reference/index.html>`."
msgstr ""
"Для более глубокой технической информации, см. :dev_docs:`Примечания по "
"OpenStack-Ansible <reference/index.html>`."

msgid ""
"For information on how to contribute, extend or develop OpenStack-Ansible, "
"see the :dev_docs:`Contributors Guide <contributor/index.html>`."
msgstr ""
"Для информации, как поучаствовать в развитии проекта или стать разработчиком "
"OpenStack-Ansible, см. :dev_docs:`Руководство разработчика <contributor/"
"index.html>`."

msgid ""
"For information on how to deploy your OpenStack-Ansible cloud, refer to the :"
"deploy_guide:`Deployment Guide <index.html>` for step-by-step instructions "
"on how to deploy the OpenStack packages and dependencies on your cloud using "
"OpenStack-Ansible."
msgstr ""
"Для информации по развертыванию Вашего облака OpenStack-Ansible, см. :"
"deploy_guide:`Руководство по развертыванию <index.html>` для пошаговых "
"инструкций по развертыванию пакетов OpenStack и зависимостей для вашего "
"облака, использующего OpenStack-Ansible."

msgid ""
"For information on how to manage and operate OpenStack-Ansible, see the see "
"the :dev_docs:`Operations Guide <admin/index.html>`."
msgstr ""
"Для информации по управлению и обслуживанию OpenStack-Ansible, см. :dev_docs:"
"`Руководство оператора <admin/index.html>`."

msgid ""
"For larger or complex environments a dedicated deployment host allows the "
"most suitable proxy configuration to be applied to both deployment and "
"target hosts."
msgstr ""
"Для больших или сложных окружений, выделенный хост развертывания позволит "
"применить наиболее подходящую настройку прокси как для хоста развертывания, "
"так и для целевых хостов."

msgid ""
"For more ideas how to tune your Gnocchi stack, take a look at these "
"presentations:"
msgstr ""
"Для лучшего понимания тонкой настройки стека Gnocchi, просмотрите данные "
"презентации:"

msgid ""
"For more information about the security configurations, see the `security "
"hardening role`_ documentation."
msgstr ""
"Дополнительную информацию о конфигурациях безопасности см. в документации "
"`Роль усиления безопасности`_."

msgid ""
"For more information on how to properly configure network interface files "
"and OpenStack-Ansible configuration files for different deployment "
"scenarios, please refer to the following:"
msgstr ""
"Больше информации как правильно настроить сетевые интерфейсы и файлы "
"конфигурации OpenStack-Ansible для различных сценариев развертывания вы "
"можете найти по ссылкам:"

msgid ""
"For network agent and container networking toplogies, please refer to the "
"following:"
msgstr "Для сетевого агента и сетевой топологии контейнеров, пожалуйста, см.:"

msgid ""
"For other services applying ``api-paste.ini`` can be done with variables, "
"but each service have quite a unique content there, so approach can't be "
"easily generalized. Below you can find overrides made for some services as "
"an example:"
msgstr ""
"Для других служб применение ``api-paste.ini`` можно сделать с переменными, "
"но у каждой службы там довольно уникальный контент, поэтому подход нельзя "
"легко обобщить. Ниже вы можете найти переопределения, сделанные для "
"некоторых служб в качестве примера:"

msgid ""
"For that create ``/etc/openstack_deploy/env.d/pod.yml`` with the following "
"content:"
msgstr ""
"Для этого создайте файл ``/etc/openstack_deploy/env.d/pod.yml`` со следующим "
"содержанием:"

msgid ""
"For that we need to do the following series of changes in the "
"``openstack_user_config.yml`` file."
msgstr ""
"Для этого нам необходимо выполнить следующие изменения в файле "
"``openstack_user_config.yml``."

msgid ""
"For that, create a file ``/etc/openstack_deploy/env.d/ceph.yml`` with the "
"following content:"
msgstr ""
"Для этого создайте файл ``/etc/openstack_deploy/env.d/ceph.yml`` с следующим "
"содержанием:"

msgid ""
"For the default AIO scenario, the AIO configuration preparation is completed "
"by executing:"
msgstr ""
"Для стандартного сценария AIO, начальная подготовка выполняется при помощи "
"команды:"

msgid ""
"For the example below, let's name our bridge ``br-public-api`` and public "
"vlan with ID ``40``. In your ``user_variables.yml`` define the following "
"variables:"
msgstr ""
"Для примера ниже давайте назовем наш мост ``br-public-api`` и публичный vlan "
"с идентификатором ``40``. В вашем ``user_variables.yml`` определите "
"следующие переменные:"

msgid ""
"For this environment you do not need the ``/etc/openstack_deploy/env.d`` "
"folder as the defaults set by OpenStack-Ansible are suitable."
msgstr ""
"Для данного окружения вам не понадобится директория ``/etc/openstack_deploy/"
"env.d`` так как стандартные параметры OpenStack-Ansible подходят."

msgid ""
"For this environment, if you want to use the same IP address for the "
"internal and external endpoints, you will need to ensure that the internal "
"and public OpenStack endpoints are served with the same protocol. This is "
"done with the following content:"
msgstr ""
"Если вы хотите использовать один и тот же IP адрес для внутренних и "
"публичных точек доступа в данном окружении, вам необходимо убедиться, что "
"внутренние и внешние точки доступа OpenStack обслуживаются по одному и тому "
"же протоколу. Для этого разместите следующие параметры:"

msgid ""
"For this environment, implement the load balancer on the infrastructure "
"hosts. Ensure that keepalived is also configured with HAProxy in ``/etc/"
"openstack_deploy/user_variables.yml`` with the following content."
msgstr ""
"В данном окружении распределитель нагрузки размещен на инфраструктурных "
"хостах. Убедитесь, что keepalived также настроен совместно с HAProxy, "
"разместив следующее содержание в файле ``/etc/openstack_deploy/"
"user_variables.yml``."

msgid ""
"For this environment, the ``cinder-volume`` runs in a container on the "
"infrastructure hosts. To achieve this, implement ``/etc/openstack_deploy/env."
"d/cinder.yml`` with the following content:"
msgstr ""
"Для данного окружения,  ``cinder-volume`` работает в контейнере на "
"инфраструктурных хостах. Что бы сделать это, создайте файл ``/etc/"
"openstack_deploy/env.d/cinder.yml`` со следующим содержанием:"

msgid ""
"For this example environment, we configure a HA load balancer. We implement "
"the load balancer (HAProxy) with an HA layer (Keepalived) on the "
"infrastructure hosts. Your ``/etc/openstack_deploy/user_variables.yml`` must "
"have the following content to configure HAProxy, Keepalived and Ceph:"
msgstr ""
"Для этого примера среды мы настраиваем балансировщик нагрузки HA. Мы "
"реализуем балансировщик нагрузки (HAProxy) с уровнем HA (Keepalived) на "
"хостах инфраструктуры. Ваш ``/etc/openstack_deploy/user_variables.yml`` "
"должен иметь следующее содержимое для настройки HAProxy, Keepalived и Ceph:"

msgid "For understanding security design, please see :ref:`security-design`."
msgstr ""
"Для понимания принципов безопасности обратитесь к :ref:`security-design`."

msgid ""
"Full compute kit with the Telemetry service (ceilometer) included, with Ceph "
"configured as a storage back end for the Image (glance), and Block Storage "
"(cinder) services"
msgstr ""
"Полный набор вычислительных служб с сервисом Telemetry (ceilometer), с "
"настроенным Ceph, как хранилище для службы образов (glance) и блочного "
"хранилища (cinder)"

msgid ""
"Full compute kit with the Telemetry service (ceilometer) included, with NFS "
"configured as a storage back end for the Image (glance), and Block Storage "
"(cinder) services"
msgstr ""
"Полный вычислительный набор с сервисом телеметрии (ceilometer), с "
"настроенным NFS в качестве хранилища данных для сервисов образов (glance) и "
"блочного хранилища (cinder)"

msgid ""
"Full compute kit with the Telemetry service (ceilometer) included, with NFS "
"configured as a storage backend for the Image (glance), and Block Storage "
"(cinder) services"
msgstr ""
"Полный набор вычислительных служб с сервисом Telemetry (ceilometer), с "
"настроенным NFS как хранилищем для службы образов (glance), так и блочным "
"хранилищем (cinder)"

msgid "GPG keys for package validation"
msgstr "GPG ключи для валидации пакетов"

msgid "Generate the certificate with the following command:"
msgstr "Сгенерируйте сертификат с помощью следующей команды:"

msgid "Generating and regenerating self-signed certificate authorities"
msgstr "Создание и восстановление самоподписанных центров сертификации"

msgid "Generating and regenerating self-signed certificates"
msgstr "Генерация и регенерация самоподписанных сертификатов"

msgid "Generating and regenerating self-signed user certificates"
msgstr ""
"Генерация и повторная генерация самоподписанных сертификатов пользователей"

msgid "Generic design"
msgstr "Общая схема"

msgid ""
"Good example of exceptions which do not support path-based endpoints at the "
"moment are VNC consoles for VMs (to be implemented with `blueprint <https://"
"blueprints.launchpad.net/nova/+spec/novnc-base-url-respect-extra-params>`_), "
"Magnum (`bug report <https://launchpad.net/bugs/2083168>`) and Ceph Rados "
"Gateway."
msgstr ""
"Хорошим примером исключений, которые в данный момент не поддерживают точки "
"доступа на основе путей, являются консоли VNC для виртуальных машин (будут "
"реализованы с помощью `blueprint <https://blueprints.launchpad.net/nova/"
"+spec/novnc-base-url-respect-extra-params>`_), Magnum (`отчет об ошибке "
"<https://launchpad.net/bugs/2083168>`) и Ceph Rados Gateway."

msgid "HAProxy and Keepalived in LXC containers"
msgstr "HAProxy и Keepalived внутри LXC контейнеров"

msgid "HAProxy configuration"
msgstr "Конфигурация HAProxy"

msgid "HAProxy example"
msgstr "Пример HAProxy"

msgid "HTTP Strict Transport Security"
msgstr "HTTP Strict Transport Security"

msgid ""
"HW_ARCH_X86_64    for x86_64 Intel and AMD CPUs HW_ARCH_AARCH64   for "
"aarch64 architecure CPUs"
msgstr ""
"HW_ARCH_X86_64  для процессоров архитектуры x86_64 Intel и AMD, "
"HW_ARCH_AARCH64 для процессоров архитектуры aarch64"

msgid ""
"Here is a basic diagram that attempts to illustrate what the resulting AIO "
"deployment looks like."
msgstr ""
"Ниже представлена базовая диаграмма, которая примерно иллюстрирует, как "
"выглядит установленный AIO."

msgid ""
"Here is an example test environment for a working OpenStack-Ansible (OSA) "
"deployment with a small number of servers."
msgstr ""
"Ниже приведен пример тестового окружения для рабочего развертывания "
"OpenStack-Ansible (OSA) с небольшим количеством серверов."

msgid "High security environments where no external connectivity is permitted"
msgstr "Высокозащищенные окружения, где внешнее соединение не разрешено"

msgid "Host name"
msgstr "Имя сервера"

msgid "Host network configuration"
msgstr "Настройка сети сервера"

msgid ""
"Hosts in the ``network_hosts`` group will map ``physnet1`` to the ``ens1f0`` "
"interface, while hosts in the ``compute_hosts`` group will map ``physnet1`` "
"to the ``ens2f0`` interface. Additional provider mappings can be established "
"using the same format in a separate definition."
msgstr ""
"Хосты в группе ``network_hosts`` соотносят интерфейс ``physnet1`` к "
"``ens1f0``, в то время как хосты в группе ``compute_hosts`` соотносят "
"интерфейс ``physnet1`` к ``ens2f0``. Дополнительные сопоставления могут быть "
"заданы в том же формате в отдельном параметре."

msgid ""
"However, there is another important part of the configuration required per "
"service which is not a case for domain-based setup. All services assume that "
"they've been served on root path (i.e. `/`) while in path-based approach we "
"use a unique path for each service."
msgstr ""
"Однако есть еще одна важная часть конфигурации, требуемая для каждой службы, "
"которая не является случаем для настройки на основе домена. Все службы "
"предполагают, что они обслуживаются по корневому пути (т. е. `/`), тогда как "
"в подходе на основе пути мы используем уникальный путь для каждой службы."

msgid "IP assignments"
msgstr "Назначения IP"

msgid ""
"Ideally the ``hw_architecture`` property is set for all uploaded images. It "
"is mandatory to set this property for all architectures that do not match "
"``image_properties_default_architecture``"
msgstr ""
"В идеале свойство ``hw_architecture`` задается для всех загруженных образов. "
"Это свойство обязательно должно быть установлено для всех архитектур, "
"которые не соответствуют ``image_properties_default_architecture``"

msgid ""
"If no domain will be matched HAProxy will proceed with path-based endpoints."
msgstr ""
"Если ни один домен не будет совпадать, HAProxy продолжит работу с точками "
"доступа на основе пути."

msgid ""
"If the AIO was deployed in a cloud VM, you may need to configure security "
"groups or firewall rules to allow access to the HTTP(S) ports. For example, "
"if the AIO was deployed in an OpenStack VM, you can create and apply a "
"suitable security group for interacting with Horizon like so:"
msgstr ""
"Если AIO был развернут в облачной виртуальной машине, вам может "
"потребоваться настроить группы безопасности или правила брандмауэра, чтобы "
"разрешить доступ к портам HTTP(S). Например, если AIO был развернут в "
"виртуальной машине OpenStack, вы можете создать и применить подходящую "
"группу безопасности для взаимодействия с Horizon следующим образом:"

msgid ""
"If the AIO was deployed in a cloud VM, you may need to configure security "
"groups or firewall rules to allow access to the various sevice ports. For "
"example, if the AIO was deployed in an OpenStack VM, you can create and "
"apply a suitable security group for interacting the core services like so:"
msgstr ""
"Если AIO был развернут в облачной виртуальной машине, вам может "
"потребоваться настроить группы безопасности или правила брандмауэра, чтобы "
"разрешить доступ к различным портам служб. Например, если AIO был развернут "
"в виртуальной машине OpenStack, вы можете создать и применить подходящую "
"группу безопасности для взаимодействия основных служб следующим образом:"

msgid ""
"If the full QEMU suite is installed on a compute host, that host will offer "
"to run all architectures supported by the available ``qemu-system-*`` "
"binaries. In this situation images without the ``hw_architecture`` property "
"could be scheduled to a non native architecture host and emulated."
msgstr ""
"Если полный набор QEMU установлен на вычислительном хосте, этот хост "
"предложит запустить все архитектуры, поддерживаемые доступными бинарными "
"файлами ``qemu-system-*``. В этой ситуации образы без свойства "
"``hw_architecture`` могут быть распределены на хост неродной архитектуры и "
"эмулированы."

msgid ""
"If the user differs from host to host, you can leverage group_vars or "
"host_vars. More information on how to use that can be found in the :doc:"
"`overrides guide </reference/configuration/using-overrides>`"
msgstr ""
"Если пользователь отличается от хоста к хосту, вы можете использовать "
"group_vars или host_vars. Более подробную информацию о том, как это "
"использовать, можно найти в :doc:`Руководстве по переопределениям </"
"reference/configuration/using-overrides>`"

msgid ""
"If this fails to get the database cluster back into a running state, then "
"please make use of the `Galera Cluster Recovery </admin/maintenance-tasks."
"html#galera-cluster-recovery>`_ section in the operations guide."
msgstr ""
"Если это не поможет вернуть кластер базы данных в рабочее состояние, "
"воспользуйтесь разделом `Galera Cluster Recovery </admin/maintenance-tasks."
"html#galera-cluster-recovery>`_ в руководстве по эксплуатации."

msgid ""
"If this is the case you can specify an alternate path which does not have "
"this mount option set:"
msgstr ""
"В этом случае вы можете указать другой путь, для которого не указан данный "
"флаг монтирования:"

msgid ""
"If you are installing with limited connectivity, or you don't have default "
"route set, you will need to define interface for outgoing connections "
"manually"
msgstr ""
"Если вы производите установку с ограниченным соединение или маршрут по "
"умолчанию отсутствует, вам будет нужно задать интерфейс для исходящих "
"соединений вручную"

msgid ""
"If you are installing with limited connectivity, please review :ref:"
"`Installing with limited connectivity <limited-connectivity>` before "
"proceeding."
msgstr ""
"Если вы производите установку с ограниченным доступом к сети, пожалуйста "
"посмотрите :ref:`Установка с ограниченным подключением <limited-"
"connectivity>` перед тем, как продолжить."

msgid ""
"If you are to use uWSGI rewrites like shown above, you will result in "
"response like that:"
msgstr ""
"Если вы используете rewrite uWSGI, как показано выше, вы получите такой "
"ответ:"

msgid ""
"If you have enabled SSL certificate configuration (default), all services "
"will use self-signed certificates. While the host is configured to trust "
"these certificates, this is not the case for other hosts. This will result "
"in HTTPS errors when attempting to interact with the cloud. To resolve this "
"issue, you will need to manually configure certificates on other hosts or "
"ignore SSL issues. To use the self-signed certificate, first copy it to the "
"other hosts. The name and location of the generated certificate are "
"configured by the ``pki_authorities`` and ``pki_trust_store_location`` "
"variables respectively, which are used by the ``pki`` role provided by "
"`ansible-role-pki`__. On an Ubuntu 22.04 host, these will default to "
"``ExampleCorpRoot`` and ``/usr/local/share/ca-certificates``, respectively. "
"For example:"
msgstr ""
"Если вы включили настройку сертификата SSL (по умолчанию), все службы будут "
"использовать самоподписанные сертификаты. Хотя хост сконфигурирован доверять "
"этим сертификатам, для других хостов это не так. Это приведет к ошибкам "
"HTTPS при попытке взаимодействия с облаком. Чтобы решить эту проблему, вам "
"нужно будет вручную настроить сертификаты на других хостах или игнорировать "
"проблемы SSL. Чтобы использовать самоподписанный сертификат, сначала "
"скопируйте его на другие хосты. Имя и местоположение сгенерированного "
"сертификата настраиваются переменными ``pki_authorities`` и "
"``pki_trust_store_location`` соответственно, которые используются ролью "
"``pki``, предоставляемой `ansible-role-pki`__. На хосте Ubuntu 22.04 они "
"будут по умолчанию ``ExampleCorpRoot`` и ``/usr/local/share/ca-"
"certificates`` соответственно. Например:"

msgid ""
"If you need to run some pre/post hooks for interfaces, you will need to "
"configure a systemd service for that. It can be done using variable "
"``openstack_hosts_systemd_services``, like that:"
msgstr ""
"Если вам нужно запустить некоторые pre/post хуки для интерфейсов, вам нужно "
"будет настроить для этого службу systemd. Это можно сделать с помощью "
"переменной ``openstack_hosts_systemd_services``, например:"

msgid ""
"If you want to delegate management of network bridges and interfaces to "
"OpenStack-Ansible, you can define variables "
"``openstack_hosts_systemd_networkd_devices`` and "
"``openstack_hosts_systemd_networkd_networks`` in `group_vars/lxc_hosts`, for "
"example:"
msgstr ""
"Если вы хотите делегировать управление сетевыми мостами и интерфейсами "
"OpenStack-Ansible, вы можете определить переменные "
"``openstack_hosts_systemd_networkd_devices`` и "
"``openstack_hosts_systemd_networkd_networks`` в `group_vars/lxc_hosts`, "
"например:"

msgid ""
"If you want to keep basic ansible logging, you need either to create ``/"
"openstack/log/ansible-logging/`` directory and allow user to write there, or "
"define the following environment variable:"
msgstr ""
"Если вы хотите сохранить базовое ведение журнала ansible, вам нужно либо "
"создать каталог ``/openstack/log/ansible-logging/`` и разрешить пользователю "
"писать в него, либо определить следующую переменную среды:"

msgid ""
"If you wish to access the AIO deployment from another host - perhaps your "
"local workstation - you will need either an ``openrc`` file or ``clouds."
"yaml`` file. You can download an ``openrc`` file from Horizon: simply click "
"the User dropdown in the top-right corner and select ``OpenStack RC File``."
msgstr ""
"Если вы хотите получить доступ к развертыванию AIO с другого хоста — "
"возможно, с вашей локальной рабочей станции — вам понадобится файл "
"``openrc`` или файл ``clouds.yaml``. Вы можете загрузить файл ``openrc`` из "
"Horizon: просто нажмите  раскрывающийся список пользователя в правом верхнем "
"углу и выберите ``OpenStack RC-файл``."

msgid ""
"If you would like to reduce disk usage, an additional policy can be applied "
"via OpenStack-Ansible as shown below:"
msgstr ""
"Если вы хотите сократить использование диска, можно применить дополнительную "
"политику через OpenStack-Ansible, как показано ниже:"

msgid ""
"If you would like your domain included in the HSTS preload list, which is "
"built into browsers, before submitting your request to be added to the HSTS "
"preload list you must add the ``preload`` token to your response header. The "
"``preload`` token indicates to the maintainers of HSTS preload list that you "
"are happy to have your site included."
msgstr ""
"Если вы хотите, чтобы ваш домен был включен в список предварительной "
"загрузки HSTS, встроенный в браузеры, перед отправкой запроса на добавление "
"в список предварительной загрузки HSTS вы должны добавить токен ``preload`` "
"в заголовок ответа. Токен ``preload`` указывает тем, кто поддерживает список "
"предварительной загрузки HSTS, что вы согласны включить туда свой сайт."

msgid ""
"If your environment does not have ``eth0``, but instead has ``p1p1`` or some "
"other interface name, ensure that all references to ``eth0`` in all "
"configuration files are replaced with the appropriate name. The same applies "
"to additional network interfaces."
msgstr ""
"Если в вашем окружении нет интерфейса ``eth0``, но вместо него используется "
"``p1p1``, либо же какое-нибудь другое имя интерфейса, убедитесь, что все "
"отсылки к ``eth0`` в конфигурационных файлах заменены на подходящее имя. Это "
"же применимо ко всем дополнительным сетевым интерфейсам."

msgid ""
"Implementing CSP could lead to broken content if a browser is blocked from "
"accessing certain resources, therefore it is recommended that when testing "
"CSP you use the ``Content-Security-Policy-Report-Only`` header, instead of "
"``Content-Security-Policy``, this reports CSP violations to the browser "
"console, but does not enforce the policy."
msgstr ""
"Реализация CSP может привести к повреждению контента, если браузеру будет "
"заблокирован доступ к определенным ресурсам, поэтому при тестировании CSP "
"рекомендуется использовать заголовок ``Content-Security-Policy-Report-Only`` "
"вместо ``Content-Security-Policy``. Это сообщает о нарушениях CSP в консоль "
"браузера, но не обеспечивает соблюдение политики."

msgid ""
"In OpenStack-Ansible TLS to HAProxy is configured in HAProxy, TLS from "
"HAProxy to noVNC is not currently enabled and TLS from nVNC to Compute nodes "
"is enabled by default."
msgstr ""
"В OpenStack-Ansible TLS для HAProxy настроен в HAProxy, TLS от HAProxy до "
"noVNC в настоящее время не включен, а TLS от nVNC до вычислительных узлов "
"включен по умолчанию."

msgid ""
"In OpenStack-Ansible, ``security.txt`` is implemented in HAProxy as all "
"public endpoints reside behind it. It defaults to directing any request "
"paths that end with ``/security.txt`` to the text file using an ACL rule in "
"HAProxy."
msgstr ""
"В OpenStack-Ansible ``security.txt`` реализован в HAProxy, поскольку все "
"публичные точки доступа находятся за ним. По умолчанию он направляет любые "
"пути запросов, которые заканчиваются на ``/security.txt``, в текстовый файл "
"с использованием правила ACL в HAProxy."

msgid ""
"In OpenStack-Ansible, security headers are implemented in HAProxy as all the "
"public endpoints reside behind it."
msgstr ""
"В OpenStack-Ansible заголовки безопасности реализованы в HAProxy, поскольку "
"все публичные точки доступа находятся за ним."

msgid ""
"In ``cidr_networks`` add a network which should be used as \"public\" "
"network for accessing APIs. For example we will be using `203.0.113.128/28`:"
msgstr ""
"В ``cidr_networks`` добавьте сеть, которая должна использоваться как "
"\"публичная\" сеть для доступа к API. Например, мы будем использовать "
"`203.0.113.128/28`:"

msgid ""
"In ``provider_networks`` you need to define a new container network and "
"assign it to HAProxy group."
msgstr ""
"В ``provider_networks`` необходимо определить новую сеть контейнеров и "
"назначить ее группе HAProxy."

msgid ""
"In ``used_ips`` you need to reserve IP address for your gateway and "
"``haproxy_keepalived_external_vip_cidr``/``external_lb_vip_address``"
msgstr ""
"В ``used_ips`` вам необходимо зарезервировать IP-адрес для вашего шлюза и "
"``haproxy_keepalived_external_vip_cidr``/``external_lb_vip_address``"

msgid ""
"In addition to this basic configuration, there are other network clients on "
"the target hosts which may be configured to connect via a proxy. For example:"
msgstr ""
"В дополнение к базовой конфигурации имеются другие сетевые клиенты на "
"целевых хостах, которые могут быть настроены для соединения через прокси. "
"Например:"

msgid ""
"In addition, it is necessary to configure easy_install to use an alternative "
"index. easy_install is used instead of pip to install anything listed under "
"setup_requires in setup.py during wheel builds. See https://pip.pypa.io/en/"
"latest/reference/pip_install/#controlling-setup-requires"
msgstr ""
"Кроме того, необходимо настроить easy_install для использования "
"альтернативного индекса. easy_install используется вместо pip для установки "
"всего, что указано в setup_requires в setup.py во время сборки wheel. См. "
"https://pip.pypa.io/en/latest/reference/pip_install/#controlling-setup-"
"requires"

msgid ""
"In case of any changes to ``haproxy_base_service_overrides`` variable you "
"need to re-run ``openstack-ansible openstack.osa.haproxy --tags haproxy-"
"service-config``."
msgstr ""
"В случае каких-либо изменений в переменной "
"``haproxy_base_service_overrides`` необходимо повторно запустить ``openstack-"
"ansible openstack.osa.haproxy --tags haproxy-service-config``."

msgid ""
"In case of deploying HAProxy inside LXC you need to ensure connectivity with "
"a public network and that ``haproxy_bind_external_lb_vip_address`` will be "
"present inside the container as well as ``external_lb_vip_address`` is "
"reachable."
msgstr ""
"В случае развертывания HAProxy внутри LXC необходимо обеспечить подключение "
"к публичной сети и то, что ``haproxy_bind_external_lb_vip_address`` будет "
"присутствовать внутри контейнера, а ``external_lb_vip_address`` будет "
"доступен."

msgid ""
"In case you do need to have a Ceph RGW or want to combine domain-based with "
"path-based approach - you can do that by defining two map files:"
msgstr ""
"Если вам действительно нужен Ceph RGW или вы хотите объединить подходы на "
"основе домена и пути, вы можете сделать это, определив два файла карт:"

msgid ""
"In order for HAProxy to pass specific FQDN to it's own backend we will "
"leverage `map files <https://www.haproxy.com/documentation/haproxy-"
"configuration-tutorials/core-concepts/map-files/>`_ functionality."
msgstr ""
"Для того чтобы HAProxy передавал определенное полное доменное имя в свой "
"собственный бекэнд, мы воспользуемся функциональностью `файлов карты "
"<https://www.haproxy.com/documentation/haproxy-configuration-tutorials/core-"
"concepts/map-files/>`_."

msgid ""
"In order for all the services to run, the host must be prepared with the "
"appropriate disks partitioning, packages, network configuration and "
"configurations for the OpenStack Deployment."
msgstr ""
"Для того, что бы все сервисы успешно запустились, сервер должен быть "
"подготовлен с использованием соответствующей разметки дисков, настроек сети "
"и настроек развертывания OpenStack."

msgid ""
"In order to add support for multiple compute tiers (in with CPU overcommit "
"and pinned CPUs) you need to create a file ``/etc/openstack_deploy/"
"group_vars/pinned_compute_hosts`` with content:"
msgstr ""
"Чтобы добавить поддержку нескольких вычислительных уровней (с CPU overcommit "
"и привязанным CPU), необходимо создать файл ``/etc/openstack_deploy/"
"group_vars/pinned_compute_hosts`` со следующим содержимым:"

msgid ""
"In order to be able to execute a playbook only against hosts in a single "
"Availability Zone, as well as be able to set AZ-specific variables, we need "
"to define groups definitions. For that, create a file ``/etc/"
"openstack_deploy/env.d/az.yml`` with the following content:"
msgstr ""
"Чтобы иметь возможность выполнять плейбук только для хостов в одной зоне "
"доступности, а также иметь возможность устанавливать переменные, специфичные "
"для AZ, нам нужно определить определения групп. Для этого создайте файл ``/"
"etc/openstack_deploy/env.d/az.yml`` со следующим содержимым:"

msgid ""
"In order to configure the deployment to use an alternative index, create the "
"file `/etc/pip.conf` with the following content and ensure that it resides "
"on all hosts in the environment."
msgstr ""
"Что бы настроить развертывание на использование альтернативного источника "
"при сборке, создайте файл `/etc/pip.conf` со следующим содержанием и "
"убедитесь, что он имеется на всех хостах в окружении."

msgid ""
"In order to make a public network available, you need to ensure having a "
"corresponsive bridge on your hosts to which HAProxy containers will be "
"plugged in with one side of a veth pair. The bridge should also contain a "
"VLAN interface providing \"public\" connectivity."
msgstr ""
"Чтобы сделать публичную сеть доступной, вам необходимо обеспечить наличие "
"соответствующего моста на ваших хостах, к которому будут подключены "
"контейнеры HAProxy с одной стороны пары veth. Мост также должен содержать "
"интерфейс VLAN, обеспечивающий «публичное» подключение."

msgid ""
"In order to properly configure Availability Zones, we need to leverage "
"``group_vars`` and define Availability Zone name used for each AZ there. For "
"this, create files:"
msgstr ""
"Чтобы правильно настроить зоны доступности, нам нужно использовать `` "
"group_vars`` и определить имя зоны доступности, используемое там для каждой "
"AZ. Для этого создайте файлы:"

msgid ""
"In order to tell dynamic_inventory to generate a set of containers for "
"HAProxy, you need to create a file ``/etc/openstack_deploy/env.d/haproxy."
"yml`` with the following content:"
msgstr ""
"Чтобы указать dynamic_inventory сгенерировать набор контейнеров для HAProxy, "
"необходимо создать файл ``/etc/openstack_deploy/env.d/haproxy.yml`` со "
"следующим содержимым:"

msgid ""
"In order to work around such limitations, starting from 2023.1 (Antelope) "
"release, it is possible to have domain-based or path-based endpoints instead."
msgstr ""
"Чтобы обойти эти ограничения, начиная с версии 2023.1 (Antelope), можно "
"использовать точки доступа на основе домена или пути."

msgid ""
"In particular, the ``ceph-rgw-install.yml`` playbook (which includes ``ceph-"
"rgw-keystone-setup.yml``) will deploy radosgw to any ``ceph-rgw`` hosts, and "
"create a corresponding Keystone ``object-store`` service catalog entry. The "
"service endpoints do contain the ``AUTH_%(tenant_id)s`` prefix just like in "
"native Swift, so public read ACLs and temp URLs will work just like they do "
"in Swift."
msgstr ""
"В частности, плейбук ``ceph-rgw-install.yml`` (который включает в себя "
"``ceph-rgw-keystone-setup.yml``) произведет развертывание radosgw на каждый "
"``ceph-rgw`` хост, и создаст соответствующую ``object-store`` запись в "
"каталог сервисов Keystone. Точки входа сервиса будут содержать префикс "
"``AUTH_%(tenant_id)s``, как и в стандартном Swift, так что ACL для "
"публичного чтения и временные URL будут работать точно также, как они "
"работали и со Swift."

msgid ""
"In some cases you may need to change the HAProxy ACL used to redirect "
"requests to the ``security.txt`` file, such as adding extra domains."
msgstr ""
"В некоторых случаях вам может потребоваться изменить ACL HAProxy, "
"используемый для перенаправления запросов в файл ``security.txt``, например, "
"добавить дополнительные домены."

msgid ""
"In the scenario below only Network node is connected to external network and "
"computes do not have external connectivity, so routers are needed for "
"external connectivity:"
msgstr ""
"В приведенном ниже сценарии к внешней сети подключен только сетевой узел, а "
"вычислительные устройства не имеют внешнего подключения, поэтому для "
"внешнего подключения необходимы маршрутизаторы:"

msgid ""
"In this example environment, infrastructure/network nodes hosting L2/L3/DHCP "
"agents will utilize an interface named ``ens1f0`` for the provider network "
"``physnet1``. Compute nodes, on the other hand, will utilize an interface "
"named ``ens2f0`` for the same ``physnet1`` provider network."
msgstr ""
"В данном примере инфраструктурные/сетевые ноды, на которых размещены L2/L3/"
"DHCP агенты будут использовать интерфейс ``ens1f0``, а для сети провайдера "
"интерфейс ``physnet1``. Вычислительные ноды, с другой стороны, будут "
"использовать  интерфейс ``ens2f0`` для той же сети провайдера ``physnet1``."

msgid ""
"In this section, you will find user stories and examples relevant to "
"deploying OpenStack-Ansible."
msgstr ""
"В данном разделе вы найдете пользовательские примеры использования, а также "
"примеры, относящиеся к развертыванию OpenStack-Ansible."

msgid ""
"Initial bootstrap of OpenStack-Ansible using ./scripts/bootstrap-ansible.sh "
"script still should be done either as the ``root`` user or escalate "
"privileges using ``sudo`` or ``su``."
msgstr ""
"Первоначальную загрузку OpenStack-Ansible с использованием скрипта ./scripts/"
"bootstrap-ansible.sh по-прежнему следует выполнять либо от имени "
"пользователя ``root``, либо повысить привилегии с помощью ``sudo`` или "
"``su``."

msgid ""
"Initial host deployment is outside the scope of OpenStack-Ansible and the "
"deployer must ensure a minimum set of proxy configuration is in place, in "
"particular for the system package manager."
msgstr ""
"Начальное развертывание хоста выходит за рамки OpenStack-Ansible, и оператор "
"должен обеспечить наличие минимального набора конфигураций прокси-сервера, в "
"частности для системного менеджера пакетов."

msgid "Install the operating system onto all the new compute nodes."
msgstr "Установите операционную систему на все новые вычислительные серверы."

msgid ""
"Installing directly from git is also supported. For example, from the tip of "
"Ansible development branch:"
msgstr ""
"Установка непосредственно из git также поддерживается. Например, для "
"установки последней версии с ветки для разработки:"

msgid "Installing with limited connectivity"
msgstr "Установка с ограниченным соединением"

msgid ""
"Instead, the usual overrides mechanism can take place, and you can define "
"these 3 variables in a ``user_*.yml`` file. See also the :ref:`user-"
"overrides` page."
msgstr ""
"Вместо этого можно использовать обычный механизм переопределений, и можете "
"определить эти 3 переменные в файле ``user_*.yml``. Просмотрите также "
"страницу :ref:`user-overrides`."

msgid "Integrate radosgw into your Telemetry"
msgstr "Интеграция radosgw с Telemetry"

msgid "Integration with Ceph"
msgstr "Интеграция с Ceph"

msgid "Interacting with an AIO"
msgstr "Взаимодействие с AIO"

msgid ""
"Internet access via the router address 172.29.236.1 on the Management Network"
msgstr ""
"Доступ в Интернет через адрес маршрутизатора 172.29.236.1 в сети управления"

msgid "Inventory overrides"
msgstr "Определение inventory"

msgid ""
"It is `possible` to perform AIO builds within a virtual machine for "
"demonstration and evaluation, but your virtual machines will perform poorly "
"unless nested virtualization is available. For production workloads, "
"multiple nodes for specific roles are recommended."
msgstr ""
"Имеется `возможность` выполнить развертывание AIO на виртуальном сервере для "
"обзора и оценки, но ваши виртуальные сервера будут иметь низкую "
"производительность, особенно, если вложенная виртуализация недоступна. Для "
"рабочих окружений рекомендуется использовать несколько нод для отдельных "
"ролей."

msgid "It is also possible to set specific security headers for Skyline."
msgstr "Также можно установить специальные заголовки безопасности для Skyline."

msgid ""
"It is also possible to use non-root user for Ansible authentication on "
"destination hosts. However, this user must be able to escalate privileges "
"using `Ansible privilege escalation`_."
msgstr ""
"Также возможно использовать пользователя без прав root для аутентификации "
"Ansible на хостах назначения. Однако, этот пользователь должен иметь "
"возможность повышать привилегии с помощью `Ansible privilege escalation`_."

msgid ""
"It is important to note that the proxy server should only be used to access "
"external resources, and communication between the internal components of the "
"OpenStack deployment should be direct and not through the proxy. The "
"``no_proxy`` environment variable is used to specify hosts that should be "
"reached directly without going through the proxy. These often are the hosts "
"in the management network."
msgstr ""
"Важно отметить, что прокси сервер должен использоваться только для доступа "
"ко внешним ресурсам, а связь между внутренними компонентами OpenStack должна "
"быть прямая и без использования прокси. Переменная окружения ``no_proxy`` "
"используется для определения хостов, доступ к которым должен быть "
"осуществлён напрямую, без использования прокси. Обычно, это хосты из "
"управляющей сети."

msgid ""
"It is not possible to have a mixed state of some compute nodes using SSH and "
"some using TLS for live migrations, as this would prevent live migrations "
"between the compute nodes."
msgstr ""
"Невозможно иметь смешанное состояние, когда некоторые вычислительные узлы "
"используют SSH, а некоторые — TLS для живых миграций, поскольку это помешает "
"живым миграциям между вычислительными узлами."

msgid ""
"It is possible to also do this (and change other defaults) during the "
"bootstrap script initial execution by changing the SCENARIO environment "
"variable before running the script. The key word 'aio' will ensure that a "
"basic set of OpenStack services (cinder, glance, horizon, neutron, nova) "
"will be deployed. The key words 'lxc' can be used to set the container back-"
"end, while the key word 'metal' will deploy all services without containers. "
"In order to implement any other services, add the name of the conf.d file "
"name without the `.yml.aio` extension into the SCENARIO environment "
"variable. Each key word should be delimited by an underscore. For example, "
"the following will implement an AIO with barbican, cinder, glance, horizon, "
"neutron, and nova. It will set the cinder storage back-end to ceph and will "
"make use of LXC as the container back-end."
msgstr ""
"Это также можно сделать (и изменить другие значения по умолчанию) во время "
"начального выполнения скрипта, изменив переменную среды SCENARIO перед "
"запуском скрипта. Ключевое слово 'aio' гарантирует, что будет развернут "
"базовый набор служб OpenStack (cinder, glance, horizon, neutron, nova). "
"Ключевые слова 'lxc' можно использовать для установки бекэнда с "
"контейнерами, в то время как ключевое слово 'metal' развернет все службы без "
"контейнеров. Чтобы реализовать любые другие службы, добавьте имя файла conf."
"d без расширения `.yml.aio` в переменную среды SCENARIO. Каждое ключевое "
"слово должно быть разделено нижним подчеркиванием. Например, следующий код "
"реализует AIO с barbican, cinder, glance, horizon, neutron и nova. Он "
"установит хранилище cinder на ceph и будет использовать LXC контейнеры в "
"качестве бекэнда."

msgid ""
"It is recommended that you monitor attempted CSP violations in production, "
"this is achieved by setting the ``report-uri`` and ``report-to`` tokens."
msgstr ""
"Рекомендуется отслеживать попытки нарушения CSP в рабочей среде. Это "
"достигается путем установки токенов ``report-uri`` и ``report-to``."

msgid ""
"It is recommended to set the property ``hw_firmware_type='uefi'`` for any "
"images which require UEFI boot, even when this implicit with the ``aarch64`` "
"architecture. This is to avoid issues with NVRAM files in libvirt when "
"deleting an instance."
msgstr ""
"Рекомендуется задать свойство ``hw_firmware_type='uefi'`` для любых образов, "
"требующих загрузки UEFI, даже если это подразумевается архитектурой "
"``aarch64``. Это необходимо для избежания проблем с файлами NVRAM в libvirt "
"при удалении инстанса."

msgid ""
"It will be an extended and more specific version of :ref:`pod-environment-"
"config` so it is expected that you are aware of the concepts and approaches "
"defined there."
msgstr ""
"Это будет расширенная и более конкретная версия статьи про :ref:`pod-"
"environment-config`, поэтому ожидается, что вы знакомы с определенными там "
"концепциями и подходами."

msgid "LXC container images"
msgstr "Образы LXC контейнеров"

msgid ""
"Last, but not the least complication is Nova scheduling when "
"``cross_az_attach`` is disabled. As Nova will not add an Availability Zone "
"to instances ``request_specs`` when an instance is created from a volume "
"directly, on the contrary to creating volume manually in advance and "
"supplying volume UUID to the instance create API call. The problem with that "
"behavior, is that Nova will attempt to Live Migrate or re-schedule instances "
"without an Availability Zone in ``request_specs`` to other AZs, which will "
"result in failure, as ``cross_az_attach`` is disabled. You can read more "
"about this in a Nova `bug report <https://bugs.launchpad.net/nova/"
"+bug/2047182>`_ In order to work around this Bug you need to set a "
"``default_schedule_zone`` for Nova and Cinder, which will ensure AZ always "
"being defined in ``request_specs``. You can also go further and define an "
"actual Availability Zone as ``default_schedule_zone``, making each "
"controller to have its own default. As Load Balancer will attempt to send "
"requests only to \"local\" backends first, this approach does work to "
"distribute new VMs across all AZs when user does not supply AZ explicitly. "
"Otherwise, the \"default\" AZ will be accepting significantly more new "
"signups."
msgstr ""
"Последняя, ​​но не самая маленькая сложность — планирование Nova, когда "
"``cross_az_attach`` отключен. Так как Nova не будет добавлять зону "
"доступности к инстансам ``request_specs``, когда инстанс создается из диска "
"напрямую, в отличие от создания диска вручную заранее и предоставления UUID "
"диска в вызове API создания инстанса. Проблема с таким поведением "
"заключается в том, что Nova попытается выполнить живую миграцию или "
"перепланировать инстансы без зоны доступности в ``request_specs`` в другие "
"AZ, что приведет к сбою, так как ``cross_az_attach`` отключен. Подробнее об "
"этом можно прочитать в отчете об ошибке Nova <https://bugs.launchpad.net/"
"nova/+bug/2047182>`_ Чтобы обойти эту ошибку, вам нужно установить "
"``default_schedule_zone`` для Nova и Cinder, что гарантирует, что AZ всегда "
"будет определена в ``request_specs``. Вы также можете пойти дальше и "
"определить фактическую зону доступности как ``default_schedule_zone``, "
"сделав каждый контроллер своим собственным значением по умолчанию. Поскольку "
"балансировщик нагрузки сначала попытается отправлять запросы только на "
"\"локальные\" бекэнды, этот подход работает для распределения новых "
"виртуальных машин по всем AZ, когда пользователь явно не указывает AZ. В "
"противном случае AZ \"по умолчанию\" будет принимать значительно больше "
"новых регистраций."

msgid "Leverage DNS Round Robin (an A/AAAA record per AZ) for Public API"
msgstr ""
"Использование DNS Round Robin (запись A/AAAA на каждую зону доступности) для "
"публичного API"

msgid ""
"Live migration of VM's using SSH is deprecated and the `OpenStack Nova "
"Docs`_ recommends using the more secure native TLS method supported by QEMU. "
"The default live migration method used by OpenStack-Ansible has been updated "
"to use TLS migrations."
msgstr ""
"Живая миграция виртуальных машин с использованием SSH устарела, и `OpenStack "
"Nova Docs`_ рекомендует использовать более безопасный собственный метод TLS, "
"поддерживаемый QEMU. Метод живой миграции по умолчанию, используемый "
"OpenStack-Ansible, был обновлен для использования миграций TLS."

msgid "Load Balancing"
msgstr "Балансировка нагрузки"

msgid "Management IP"
msgstr "Управляющий IP"

msgid "Management Network"
msgstr "Управляющая сеть"

msgid "Managing RabbitMQ stream policy"
msgstr "Управление политикой потока RabbitMQ"

msgid ""
"Many network configuration examples assume a homogenous environment, where "
"each server is configured identically and consistent network interfaces and "
"interface names can be assumed across all hosts."
msgstr ""
"Много примеров сетевых конфигураций предполагают однородное окружение, где "
"каждый сервер настроен идентично и постоянные сетевые интерфейсы и сетевые "
"имена могут быть использованы на всех хостах."

msgid ""
"Many packages used to run OpenStack are installed using `pip`. We advise "
"mirroring the PyPi package index used by `pip`. A deployer can choose to "
"actively mirror the entire upstream PyPi repository, but this may require a "
"significant amount of storage. Alternatively, a caching pip proxy can be "
"used to retain local copies of only those packages which are required."
msgstr ""
"Много пакетов, используемых для запуска OpenStack, устанавливаются при "
"помощи `pip`. Мы рекомендуем зеркалировать список пакетов из PyPi, которые "
"используются pip. Оператор может предпочесть активно зеркалировать весь "
"верхний репозиторий PyPi, но это может потребовать значительный объем "
"дискового пространства. Как вариант, можно использовать кэширующий pip "
"прокси для получения локальных копий только требуемых пакетов."

msgid ""
"Many playbooks and roles in OpenStack-Ansible retrieve dependencies from the "
"public Internet by default. The example configurations assume that the "
"deployer provides a good quality Internet connection via a router on the "
"OpenStack management network."
msgstr ""
"Многие плейбуки и роли в OpenStack-Ansible по умолчанию извлекают "
"зависимости из Интернета. Примеры конфигураций предполагают, что оператор "
"имеет качественное подключение к Интернету через маршрутизатор в сети "
"управления OpenStack."

msgid ""
"Many software packages are installed on Ubuntu hosts using `.deb` packages. "
"Similar packaging mechanisms exist for other Linux distributions. We advise "
"mirroring the repositories that host these packages."
msgstr ""
"Много программных пакетов установлено на Ubuntu при помощи `.deb` пакетов. "
"Схожие механизмы пакетов существуют и для других дистрибутивов Linux. Мы "
"советуем зеркалировать репозитории, которые содержат данные пакеты."

msgid ""
"Mentioned below overrides are default ones and will be applied to `ceph-rgw` "
"group"
msgstr ""
"Упомянутые ниже переопределения это значения по умолчанию, которые будут "
"применены к группе `ceph-rgw`"

msgid "Messaging configuration"
msgstr "Конфигурация обмена сообщениями"

msgid "Messaging transport"
msgstr "Транспорт для обмена сообщениями"

msgid "Mixed CPU architectures for compute nodes"
msgstr "Смешанные архитектуры процессора для вычислительных узлов"

msgid ""
"More information about SSL certificate configuration can be found in the :"
"doc:`security guide </user/security/ssl-certificates>`."
msgstr ""
"Более подробную информацию о настройке SSL-сертификата можно найти в :doc:"
"`security guide </user/security/ssl-certificates>`."

msgid "Most Python network modules"
msgstr "Большинство Python модулей"

msgid "Multi-Architecture Deployments"
msgstr "Развертывания с различными архитектурами"

msgid ""
"Multiple Network Interface Cards (NIC) configured as bonded pairs for each "
"host"
msgstr ""
"Несколько сетевых карт (NIC), настроенных как агрегированные для каждого "
"хоста"

msgid ""
"Multiple Network Interface Cards (NIC) used as provider network interfaces "
"that vary between hosts"
msgstr ""
"Несколько сетевых карт (NIC) используются как интерфейс сети провайдера, "
"которая отличается между хостами"

msgid "Multiple interfaces or bonds"
msgstr "Несколько интерфейсов или агрегаций"

msgid "NFS Storage"
msgstr "Хранилище NFS"

msgid "Network"
msgstr "Сеть"

msgid "Network CIDR/VLAN assignments"
msgstr "Распределение сетевых CIDR/VLAN"

msgid "Network Interface Layout - Multiple Bonds"
msgstr "Схема сетевых интерфейсов - несколько агрегаций"

msgid "Network Interface Layout - Multiple Interfaces"
msgstr "Схема сетевых интерфейсов - несколько интерфейсов"

msgid "Network Interface Layout - Single Bond"
msgstr "Схема сетевых интерфейсов - одна агрегация"

msgid "Network Interface Layout - Single Interface"
msgstr "Схема сетевых интерфейсов - один интерфейс"

msgid "Network Interface Layout OVN - Gateway Nodes"
msgstr "Схема сетевого интерфейса OVN - узлы шлюза"

msgid "Network architectures"
msgstr "Сетевые архитектуры"

msgid "Network configuration"
msgstr "Настройка сети"

msgid "Network interfaces"
msgstr "Сетевые интерфейсы"

msgid ""
"Next switch the applicable branch/tag to be deployed from. Note that "
"deploying from the head of a branch may result in an unstable build due to "
"changes in flight and upstream OpenStack changes. For a test (for example, "
"not a development) build it is usually best to checkout the latest tagged "
"version."
msgstr ""
"Далее переключитесь на желаемую ветку/тег с которого будет произведена "
"установка. Учтите, что развертывание с определенной ветки может привести к "
"нестабильной сборке из-за изменений, которые находятся в процессе, а также "
"изменений в OpenStack. Для теста (не для разработки), обычно, наилучшим "
"выбором будет переход на последнюю тегированную версию."

msgid ""
"Next, we need to ensure a HAProxy configuration for each service does "
"contain HAProxy map population with a respective condition, for example:"
msgstr ""
"Далее нам необходимо убедиться, что конфигурация HAProxy для каждой службы "
"содержит наполнение карты HAProxy с соответствующим условием, например:"

msgid ""
"Next, we want to secure HAProxy pointing always to the backend which is "
"considered as \"local\" to the HAProxy. For that we switch balancing "
"algorithm to ``first`` and order re-backends so that the one from current "
"Availability Zone appears to be the first in the list. This can be done by "
"creating file ``/etc/openstack_deploy/group_vars/haproxy/backend_overrides."
"yml`` with content:"
msgstr ""
"Далее мы хотим обеспечить, чтобы HAProxy всегда указывал на бэкенд, который "
"считается \"локальным\" для HAProxy. Для этого мы переключаем алгоритм "
"балансировки на ``первый`` и упорядочиваем ре-бэкенды так, чтобы первым в "
"списке оказался тот, который находится в текущей зоне доступности. Это можно "
"сделать, создав файл ``/etc/openstack_deploy/group_vars/haproxy/"
"backend_overrides.yml`` с содержимым:"

msgid ""
"Note however, that this policy will only apply if it is in place before any "
"stream queues are created. If these already exist, they will need to be "
"manually deleted and re-created by the relevant OpenStack service."
msgstr ""
"Однако следует отметить, что эта политика будет применяться только в том "
"случае, если она установлена ​​до создания очередей потоков. Если они уже "
"существуют, их необходимо вручную удалить и заново создать с помощью "
"соответствующей службы OpenStack."

msgid ""
"Note that the image metadata prefilter and ImagePropertiesFilter are "
"different and unrelated steps in the process Nova scheduler uses to "
"determine candidate compute hosts. This section explains how to use them "
"together."
msgstr ""
"Обратите внимание, что image_metadata_prefilter и ImagePropertiesFilter — "
"это разные и не связанные между собой шаги в процессе, который планировщик "
"Nova использует для определения потенциальных вычислительных хостов. В этом "
"разделе объясняется, как использовать их вместе."

msgid "Notifications"
msgstr "Уведомления"

msgid ""
"Notify communications are an asynchronous exchange from notifier to "
"listener. The messages transferred typically correspond to information "
"updates or event occurrences that are published by an OpenStack service. The "
"listener need not be present when the notification is sent as notify "
"communications are temporally decoupled. This decoupling between notifier "
"and listener requires that the messaging backend deployed for notifications "
"provide message persistence such as a broker queue or log store. It is "
"noteworthy that the message transfer is unidirectional from notifier to "
"listener and there is no message flow back to the notifier."
msgstr ""
"Уведомления это асинхронный обмен сообщениями от уведомителя к получателю. "
"Передаваемые сообщения обычно содержат информацию об обновлениях или "
"возникновении событий, которые публикуются сервисом OpenStack. Получатель не "
"должен присутствовать, когда сообщение отправляется так как сообщения "
"уведомлений временно отделены. Такое отделение между уведомителем и "
"получателем требует от сервиса обмена хранения сообщений, такого как очередь "
"брокера или хранилище логов. Стоит упомянуть, что передача сообщения от "
"уведомителя получателю однонаправленная и направление сообщений обратно к "
"уведомителю отсутствует."

msgid ""
"Nova has the capability to allow emulation of one CPU architecture on a host "
"with a different native CPU architecure, see https://docs.openstack.org/nova/"
"latest/admin/hw-emulation-architecture.html for more details."
msgstr ""
"Nova позволяет эмулировать одну процессорную архитектуру на хосте с другой "
"собственной процессорной архитектурой. Более подробную информацию см.  "
"https://docs.openstack.org/nova/latest/admin/hw-emulation-architecture.html"

msgid "Now you can set up Zookeeper as coordination backend for Gnocchi:"
msgstr ""
"Теперь вы можете установить Zookeeper как координирующий сервис для Gnocchi:"

msgid ""
"On this page, we will provide an example configuration that can be used in "
"production environments with multiple Availability Zones."
msgstr ""
"На этой странице мы предоставим пример конфигурации, которую можно "
"использовать в рабочих окружениях с несколькими зонами доступности."

msgid ""
"Once all steps above are accomplished, it's time to create our new HAProxy "
"containers. For that run the following command:"
msgstr ""
"После того, как все шаги выше выполнены, пришло время создать наши новые "
"контейнеры HAProxy. Для этого выполните следующую команду:"

msgid ""
"Once an AIO has been deployed, you most likely want to interact with it. You "
"can do this via the web interface or one of the many clients or libraries "
"that exist for OpenStack."
msgstr ""
"Как только AIO будет развернут, вы наверняка захотите взаимодействовать с "
"ним. Вы всегда можете сделать это с помощью веб интерфейса или одного из "
"доступных клиентов или библиотек, которые существуют для OpenStack."

msgid ""
"Once groups are defined, you can proceed with configuring `Ceph-Ansible "
"specific vars <https://github.com/ceph/ceph-ansible/blob/master/group_vars/"
"all.yml.sample>`_ in the OpenStack-Ansible ``user_variables.yml`` file."
msgstr ""
"После определения групп можно приступить к настройке `специфичных для Ceph-"
"Ansible переменных <https://github.com/ceph/ceph-ansible/blob/master/"
"group_vars/all.yml.sample>`_ в файле OpenStack-Ansible ``user_variables."
"yml``."

msgid ""
"Once one of these files have been created, you can use it to interact with "
"your deployment using most standard clients and libraries. For example, to "
"list available projects using *openstackclient*:"
msgstr ""
"После создания одного из этих файлов вы можете использовать его для "
"взаимодействия с вашим развертыванием с использованием большинства "
"стандартных клиентов и библиотек. Например, чтобы вывести список доступных "
"проектов с помощью *openstackclient*:"

msgid ""
"Once the number of hosts/containers in a deployment reaches a certain size, "
"the length of ``no_proxy`` will exceed 1024 characters at which point it is "
"mandatory to use the transient proxy settings which only requires a subset "
"of the management network IP addresses to be present in ``no_proxy`` at "
"deployment time."
msgstr ""
"Как только количество хостов/контейнеров в окружении достигнет определенного "
"размера и длина ``no_proxy`` превысит 1024 символа, в этот момент будет "
"необходимо использовать сквозной прокси, настройки которого требуют только "
"наличия ряда IP адресов управляющей сети в ``no_proxy`` во время "
"развертывания."

msgid ""
"Once the playbooks have fully executed, it is possible to experiment with "
"various settings changes in ``/etc/openstack_deploy/user_variables.yml`` and "
"only run individual playbooks. For example, to run the playbook for the "
"Keystone service, execute:"
msgstr ""
"Как только выполнение плейбуков завершилось, вы можете экспериментировать с "
"изменением различных настроек в ``/etc/openstack_deploy/user_variables.yml`` "
"и запускать только отдельные плейбуки. Например, для запуска плейбука для "
"сервиса Keystone выполните:"

msgid ""
"Once this is done, configure the ``cacert`` value in the the definition for "
"your cloud in ``clouds.yaml``. For example:"
msgstr ""
"После этого настройте значение ``cacert``  для вашего облака в ``clouds."
"yaml``. Например:"

msgid "One NFS storage device"
msgstr "Одно NFS устройство для данных"

msgid "One Network Interface Card (NIC) for each host"
msgstr "Одна сетевая карта (NIC) для каждого хоста"

msgid "One compute host (8 vCPU, 8 GB RAM, 60 GB HDD)"
msgstr "Один вычислительный хост (8 vCPU, 8 ГБ оперативной памяти, 60 ГБ HDD)"

msgid "One infrastructure (control plane) host (8 vCPU, 8 GB RAM, 60 GB HDD)"
msgstr ""
"Один инфраструктурный (управляющий) хост (8 vCPU, 8 ГБ оперативной памяти, "
"60 ГБ HDD)"

msgid "One log aggregation host"
msgstr "Один хост для сбора логов"

msgid ""
"One solution to possible performance problems is to use an incoming measure "
"storage for your gnocchi installation. The `supported storage systems`_ are:"
msgstr ""
"Одним из решений возможных проблем с производительностью, является "
"использование хранилища входящих метрик для gnocchi. `Поддерживаемые системы "
"хранилищ`_:"

msgid "Open Virtual Network (OVN)"
msgstr "Open Virtual Network (OVN)"

msgid "Open vSwitch and Linux Bridge"
msgstr "Open vSwitch и Linux Bridge"

msgid "OpenStack Swift"
msgstr "OpenStack Swift"

msgid ""
"OpenStack-Ansible allows `Ceph storage <https://ceph.io>`_ cluster "
"integration in three ways:"
msgstr ""
"OpenStack-Ansible позволяет интегрировать кластер `Ceph <https://ceph.io>`_  "
"3-мя различными способами:"

msgid ""
"OpenStack-Ansible builds LXC images using debootstrap or dnf depending on "
"the distribution. In order to override the package  repository you might "
"need to adjust some variables, like ``lxc_apt_mirror`` or completely "
"override build command with ``lxc_hosts_container_build_command`` Consult "
"the ``openstack-ansible-lxc_hosts`` role for details on configuration "
"overrides for this scenario."
msgstr ""
"OpenStack-Ansible собирает образы LXC с помощью debootstrap или dnf в "
"зависимости от дистрибутива. Чтобы переопределить репозиторий пакетов, вам "
"может потребоваться настроить некоторые переменные, например "
"``lxc_apt_mirror`` или полностью переопределить команду сборки с помощью "
"``lxc_hosts_container_build_command``. Ознакомьтесь с ролью ``openstack-"
"ansible-lxc_hosts`` для получения подробной информации о переопределении "
"конфигурации для этого сценария."

msgid ""
"OpenStack-Ansible does not mandate any specific method of configuring "
"network interfaces on the host. You may choose any tool, such as ifupdown, "
"netplan, systemd-networkd, networkmanager or another operating-system "
"specific tool. The only requirement is that a set of functioning network "
"bridges and interfaces are created which match those expected by OpenStack-"
"Ansible, plus any that you choose to specify for neutron physical interfaces."
msgstr ""
"OpenStack-Ansible не предписывает какой-либо конкретный метод настройки "
"сетевых интерфейсов на хосте. Вы можете выбрать любой инструмент, например "
"ifupdown, netplan, systemd-networkd, networkmanager или другой инструмент, "
"специфичный для операционной системы. Единственное требование — создание "
"набора функционирующих сетевых мостов и интерфейсов, соответствующих "
"ожидаемым OpenStack-Ansible, а также любых, которые вы укажете для "
"физических интерфейсов neutron."

msgid ""
"OpenStack-Ansible gives you the option of deploying radosgw as a drop-in "
"replacement for native OpenStack Swift."
msgstr ""
"OpenStack-Ansible дает вам возможность развертывания radosgw как замены "
"стандартного OpenStack Swift."

msgid ""
"OpenStack-Ansible provides the ``openstack_openrc`` role for creating these "
"configuration files as well as a number of utilities such as "
"*openstackclient*. If the AIO deployment using the ``lxc`` scenario (the "
"default), these will be availably in the utility container."
msgstr ""
"OpenStack-Ansible предоставляет роль ``openstack_openrc`` для создания таких "
"конфигурационных файлов для различных утилит, таких как *openstackclient*. "
"Если AIO развертывание использует ``lxc`` сценарий (по умолчанию), они будут "
"доступны в utility контейнере."

msgid ""
"OpenStack-Ansible provides two distinct mechanisms for configuring proxy "
"server settings:"
msgstr ""
"OpenStack-Ansible предоставляет два различных механизма для настройки прокси "
"сервера:"

msgid ""
"OpenStack-Ansible releases including 2023.1 and later will only install the "
"native architecture `qemu-system-*`` binary so this step should not be "
"required on newer releases."
msgstr ""
"Выпуски OpenStack-Ansible, включая 2023.1 и более поздние, устанавливают "
"только бинарный файл собственной архитектуры `qemu-system-*``, поэтому этот "
"шаг не требуется в более новых выпусках."

msgid ""
"OpenStack-Ansible relies upon Ansible Galaxy to download Ansible roles when "
"bootstrapping a deployment host. Deployers may wish to mirror the "
"dependencies that are downloaded by the ``bootstrap-ansible.sh`` script."
msgstr ""
"OpenStack-Ansible использует Ansible Galaxy для загрузки ролей Ansible при "
"начальной подготовке хоста развертывания. Операторы могут зеркалировать "
"зависимости, которые загружаются при помощи скрипта ``bootstrap-ansible.sh``."

msgid ""
"OpenStack-Ansible requires several other repositories to install specific "
"components such as Galera and Ceph."
msgstr ""
"OpenStack-Ansible требует несколько дополнительных репозиториев для "
"установки специфичных компонентов, таких как Galera и Ceph."

msgid ""
"OpenStack-Ansible supports a number of different network architectures, and "
"can be deployed using a single network interface for non-production "
"workloads or using multiple network interfaces or bonded interfaces for "
"production workloads."
msgstr ""
"OpenStack-Ansible поддерживает несколько различных сетевых архитектур и "
"может произвести развертывание используя один сетевой интерфейс для тестовых "
"окружений, или использовать несколько сетевых интерфейсов, или "
"агрегированные интерфейсы для рабочих окружений."

msgid ""
"OpenStack-Ansible supports deployments where either the control plane or "
"compute nodes may comprise of several different CPU architectures."
msgstr ""
"OpenStack-Ansible поддерживает развертывания, в которых либо узлы "
"управления, либо вычислительные узлы могут состоять из нескольких различных "
"архитектур процессора."

msgid ""
"OpenStack-Ansible supports having compute nodes of multiple architectures "
"deployed in the same environment."
msgstr ""
"OpenStack-Ansible поддерживает наличие вычислительных серверов различных "
"архитектур в одном окружении."

msgid ""
"OpenStack-Ansible supports the use of a multiple interfaces or sets of "
"bonded interfaces that carry traffic for OpenStack services and instances."
msgstr ""
"OpenStack-Ansible поддерживает использование как нескольких интерфейсов так "
"и набора агрегированных интерфейсов для обслуживания трафика сервисов "
"OpenStack  и инстансов."

msgid ""
"OpenStack-Ansible supports the use of a single interface or set of bonded "
"interfaces that carry traffic for OpenStack services as well as instances."
msgstr ""
"OpenStack-Ansible поддерживает использование как и одиночных интерфейсов так "
"и набора агрегированных интерфейсов для обслуживания трафика сервисов "
"OpenStack также как и инстансов."

msgid ""
"OpenStack-Ansible uses an ansible role `ansible_role_pki`_ as a general tool "
"to manage and install self-signed and user provided certificates."
msgstr ""
"OpenStack-Ansible использует роль ansible `ansible_role_pki`_ в качестве "
"общего инструмента для управления и установки самоподписанных и "
"предоставленных пользователями сертификатов."

msgid "Other OpenStack services"
msgstr "Другие сервисы OpenStack"

msgid "Other proxy configuration"
msgstr "Другие настройки прокси"

msgid "Overlay Network"
msgstr "Overlay сеть"

msgid ""
"Override Ansible temporary path if LXC containers are used. The ansible "
"connection from the physical host to the LXC container passes environment "
"variables from the host. This means that Ansible attempts to use the same "
"temporary folder in the LXC container as it would on the host, relative to "
"the non-root user ${HOME} directory. This will not exist inside the "
"container and another path must be used instead."
msgstr ""
"Переопределите временный путь Ansible, если используются контейнеры LXC. "
"Соединение Ansible от физического хоста к контейнеру LXC передает переменные "
"среды с хоста. Это означает, что Ansible пытается использовать ту же "
"временную папку в контейнере LXC, что и на хосте, относительно каталога "
"пользователя без прав root ${HOME}. Он не будет существовать внутри "
"контейнера, и вместо него должен быть использован другой путь."

msgid "Overriding Ansible version"
msgstr "Переопределение версии Ansible"

msgid ""
"Overriding ceph_mons is required only when you are using external cluster "
"which does not present in the OpenStack-Ansible's inventory (ie group "
"``mon_group_name`` is not defined)."
msgstr ""
"Переопределение ceph_mons требуется только в том случае, если вы используете "
"внешний кластер, которого нет в inventory OpenStack-Ansible (т. е. группа "
"``mon_group_name`` не определена)."

msgid "Overriding other upstream projects source code"
msgstr "Переопределение других источников исходного кода проектов"

msgid ""
"Overriding the default Ansible version is not recommended, as each branch of "
"OpenStack-Ansible has been built with the a specific Ansible version in "
"mind, and many Ansible changes are neither backwards nor forward compatible."
msgstr ""
"Переопределение версии Ansible не рекомендуется, так как каждая ветка "
"OpenStack-Ansible создавалась под конкретную версию Ansible, и многие "
"изменения Ansible не имеют ни обратной, ни восходящей совместимости."

msgid ""
"Overriding the role file has been explained in the reference guide, on the :"
"ref:`extend_osa_roles` section."
msgstr ""
"Переопределение файла ролей было описано в руководстве по применению, в "
"секции :ref:`extend_osa_roles`."

msgid "Overriding the roles"
msgstr "Переопределение ролей"

msgid "Overview"
msgstr "Обзор"

msgid "POD 1 Management Network"
msgstr "Управляющая сеть блока 1"

msgid "POD 1 Storage Network"
msgstr "Сеть хранилища данных блока 1"

msgid "POD 1 Tunnel (VXLAN) Network"
msgstr "Туннелированная (VXLAN) сеть блока 1"

msgid "POD 2 Management Network"
msgstr "Управляющая сеть блока 2"

msgid "POD 2 Storage Network"
msgstr "Сеть хранилища данных блока 2"

msgid "POD 2 Tunnel (VXLAN) Network"
msgstr "Туннелированная (VXLAN) сеть блока 2"

msgid "POD 3 Management Network"
msgstr "Управляющая сеть блока 3"

msgid "POD 3 Storage Network"
msgstr "Сеть хранилища данных блока 3"

msgid "POD 3 Tunnel (VXLAN) Network"
msgstr "Туннелированная (VXLAN) сеть блока 3"

msgid "POD 4 Management Network"
msgstr "Управляющая сеть блока 4"

msgid "POD 4 Storage Network"
msgstr "Сеть хранилища данных блока 4"

msgid "POD 4 Tunnel (VXLAN) Network"
msgstr "Туннелированная (VXLAN) сеть блока 4"

msgid ""
"Path-based endpoints imply serving services on the same FQDN but "
"differentiating them based on URI."
msgstr ""
"Точки доступа на основе пути подразумевают обслуживание служб на одном и том "
"же полном доменном имени, но дифференциацию их на основе URI."

msgid ""
"Perform all SSL certificate configuration in ``/etc/openstack_deploy/"
"user_variables.yml`` file. Do not edit the playbooks or roles themselves."
msgstr ""
"Выполните все настройки SSL сертификатов в файле ``/etc/openstack_deploy/"
"user_variables.yml``. Не редактируйте роли или плейбуки самостоятельно для "
"этого."

msgid "Performance Tests for Gnocchi"
msgstr "Тесты производительности для Gnocchi"

msgid "Permission Policy"
msgstr "Политика предоставления разрешений"

msgid ""
"Please mention, that Internal FQDNs are still going to be covered with self-"
"signed certificates as in most use-cases Let's Encrypt should not be able to "
"verify domain ownership for internal VIPs, unless dns-01 auth is used."
msgstr ""
"Обратите внимание, что внутренние полные доменные имена по-прежнему будут "
"защищены самоподписанными сертификатами, поскольку в большинстве случаев "
"Let's Encrypt не сможет проверить право собственности на домен для "
"внутренних VIP-адресов, если только не используется аутентификация dns-01."

msgid ""
"Please mention, that RGW installation should be performed after deployment "
"of Keystone service."
msgstr ""
"Обратите внимание, что установку RGW следует выполнять после развертывания "
"сервиса Keystone."

msgid ""
"Please note, for this glance example, that you do not need to edit the "
"``inventory/group_vars/glance_all/source_git.yml`` file."
msgstr ""
"Обратите внимание, что для этого примера Glance, вам не нужно редактировать "
"файл ``inventory/group_vars/glance_all/source_git.yml``."

msgid ""
"Please note, that Horizon does utilize `/identity` for its Keystone panel, "
"so if you're serving Horizon on `/` (default) and using `/identity` to "
"forward traffic to Keystone backend, management of users, roles, projects "
"inside the Horizon will be broken due to a conflict."
msgstr ""
"Обратите внимание, что Horizon использует `/identity` для своей панели "
"Keystone, поэтому, если вы обслуживаете Horizon на `/` (по умолчанию) и "
"используете `/identity` для пересылки трафика на бекэнд Keystone, управление "
"пользователями, ролями и проектами внутри Horizon будет нарушено из-за "
"конфликта."

msgid ""
"Populate a \"base\" map file with search patterns per service backend. As "
"each service is going to use its own FQDN we need to inform HAProxy which "
"backend should be used when request is coming to the FQDN."
msgstr ""
"Заполните файл \"базового\" сопоставления шаблонов поиска для каждого "
"бэкенда служб. Поскольку каждый сервис будет использовать свой собственный "
"FQDN, нам нужно сообщить HAProxy, какой бэкенд следует использовать, когда "
"запрос поступает на FQDN."

msgid "Practice A: Mirror internet resources locally"
msgstr "Вариант А: создание локальных зеркал интернет-ресурсов"

msgid "Practice B: Proxy access to internet resources"
msgstr "Вариант Б: доступ к интернет-ресурсам при помощи прокси"

msgid "Prepare the host"
msgstr "Подготовка сервера"

msgid ""
"Prevent creation of a front-end per service. As we are now expecting traffic "
"to come only on default `80` and `443` ports there is no need to have a "
"separate frontend per service. A HAProxy map file is attached to a \"base\" "
"frontend which is deployed with the ``haproxy_server`` role and is "
"independent of any service definitions. The map file can be used to direct "
"incoming requests to specific backends by using rules defined in the map "
"file to match against host request headers."
msgstr ""
"Предотвратить создание фронтенда на службу. Поскольку теперь мы ожидаем, что "
"трафик будет поступать только на порты по умолчанию `80` и `443`, нет "
"необходимости иметь отдельный фронтенд на службу. Файл карты HAProxy "
"прикреплен к \"базовому\" фронтенду, который развернут с ролью "
"``haproxy_server`` и не зависит от каких-либо служб. Файл карты можно "
"использовать для направления входящих запросов на определенные бэкенды с "
"помощью правил, определенных в файле карты, для сопоставления с заголовками "
"запросов хоста."

msgid "Production environment"
msgstr "Рабочее окружение"

msgid "Production environment host layout"
msgstr "Схема серверов для рабочего окружения"

msgid ""
"Provide ``--become`` flag each time your run a playbook or ad-hoc command. "
"Alternatively, you can define the following environment variable:"
msgstr ""
"Предоставляйте флаг ``--become`` каждый раз, когда вы запускаете playbook "
"или ad-hoc команду. В качестве альтернативы вы можете определить следующую "
"переменную окружения:"

msgid "Provider network groups"
msgstr "Сетевые группы провайдера"

msgid ""
"Proxying TLS traffic often interferes with the clients ability to perform "
"successful validation of the certificate chain. Various configuration "
"variables exist within the OpenStack-Ansible playbooks and roles that allow "
"a deployer to ignore these validation failures. Disable certificate chain "
"validation on a case by case basis and only after encountering failures that "
"are known to only be caused by the proxy server(s)."
msgstr ""
"Проксирование трафика TLS часто мешает клиентам успешно выполнять проверку "
"цепочки сертификатов. В плейбуках и ролях OpenStack-Ansible существуют "
"различные переменные конфигурации, которые позволяют оператору игнорировать "
"эти сбои проверки. Отключайте проверку цепочки сертификатов в каждом "
"конкретном случае и только после обнаружения сбоев, которые, как известно, "
"вызваны только прокси-сервером(ами)."

msgid "Public API VIPs"
msgstr "VIP публичного API"

msgid ""
"Public API, OpenStack external and management networks are represented as "
"stretched L2 networks between Availability Zones."
msgstr ""
"Публичный API, внешние сети OpenStack и сети управления представлены в виде "
"растянутых сетей L2 между зонами доступности."

msgid "Python package repositories"
msgstr "Репозитории Python пакетов"

msgid "Python packages"
msgstr "Python пакеты"

msgid ""
"QEMU-native TLS requires all compute hosts to accept TCP connections on port "
"16514 and port range 49152 to 49261."
msgstr ""
"Для использования нативного протокола TLS в QEMU требуется, чтобы все "
"вычислительные хосты принимали TCP-подключения на порту 16514 и в диапазоне "
"портов 49152–49261."

msgid "Quickstart: AIO"
msgstr "Быстрое начало: AIO"

msgid "RPC"
msgstr "RPC"

msgid "RabbitMQ example"
msgstr "Пример RabbitMQ"

msgid "Rebooting an AIO"
msgstr "Перезагрузка AIO"

msgid "Rebuilding an AIO"
msgstr "Переустановка AIO"

msgid ""
"Recent changes to OpenStack-Ansible (OSA) enables deployers to define "
"provider networks that apply to particular inventory groups and allows for a "
"heterogeneous network configuration within a cloud environment. New groups "
"can be created or existing inventory groups, such as ``network_hosts`` or "
"``compute_hosts``, can be used to ensure certain configurations are applied "
"only to hosts that meet the given parameters."
msgstr ""
"Недавние изменения в OpenStack-Ansible (OSA) позволяют операторам определять "
"сети провайдера, которые применимы к конкретной группе в inventory и "
"позволяют производить неоднородные сетевые настройки в окружении облака. "
"Новые группы могут быть созданы или уже существующие, такие как "
"``network_hosts`` или ``compute_hosts``, могут быть использованы для "
"применения определенной конфигурации только к хостам, которые удовлетворяют "
"предоставленным параметрам."

msgid "Recommended server resources:"
msgstr "Рекомендуемые серверные ресурсы:"

msgid "Redis"
msgstr "Redis"

msgid "Redis as measure storage"
msgstr "Redis как хранилище метрик"

msgid "Reduce amount of cross-AZ traffic"
msgstr "Уменьшение объема трафика между зонами AZ"

msgid ""
"Refer to `global_environment_variables:` and "
"`deployment_environment_variables:` in the example `user_variables.yml` for "
"details of configuring persistent and transient proxy environment variables."
msgstr ""
"См. `global_environment_variables:` и `deployment_environment_variables:` в "
"типовом `user_variables.yml` для получения деталей о настройке переменных "
"окружения для постоянного и временного прокси."

msgid "Reference Diagram for an AIO Build"
msgstr "Справочная схема по развертыванию AIO"

msgid "Referrer Policy"
msgstr "Referrer политика"

msgid "Report Only"
msgstr "Report Only"

msgid "Reporting Violations"
msgstr "Сообщение о нарушениях"

msgid ""
"Rest of variables can be defined in ``/etc/openstack_deploy/user_variables."
"yml`` but a lot of them will be referencing ``az_name`` variable, so it's "
"presence (along with corresponding groups) are vital for this scenario."
msgstr ""
"Остальные переменные можно определить в ``/etc/openstack_deploy/"
"user_variables.yml``, но многие из них будут ссылаться на переменную "
"``az_name``, поэтому ее наличие (вместе с соответствующими группами) "
"жизненно важно для этого сценария."

msgid ""
"Review the `bootstrap-host role defaults`_ file to see various configuration "
"options. Deployers have the option to change how the host is bootstrapped. "
"This is useful when you wish the AIO to make use of a secondary data disk, "
"or when using this role to bootstrap a multi-node development environment."
msgstr ""
"Просмотрите файл `bootstrap-host role defaults`_ - в нем содержатся "
"различные настройки развертывания. Оператор имеет возможность настроить, "
"каким образом сервер будет подготовлен. Это может быть полезно, когда вы "
"хотите, что бы AIO использовал второй диск для данных, либо же использовать "
"данную роль для подготовки развертывания окружения на несколько серверов."

msgid "Routed environment example"
msgstr "Пример маршрутизируемого окружения"

msgid "Run all playbooks to configure HAProxy and OpenStack services."
msgstr "Запустите все сценарии для настройки служб HAProxy и OpenStack."

msgid "Run playbooks"
msgstr "Запуск плейбуков"

msgid "Run the OpenStack-Ansible playbooks to deploy the required services."
msgstr ""
"Запустите плейбуки OpenStack-Ansible для развертывание требуемых сервисов."

msgid "Run the following to bootstrap Ansible and the required roles:"
msgstr "Выполните следующие команды для подготовки Ansible и требуемых ролей:"

msgid "Run the playbook for that service."
msgstr "Запустите плейбуки для этого сервиса."

msgid "Running as non-root user"
msgstr "Запуск от имени пользователя без прав root"

msgid "Sample configuration for Keystone and Nova will look like this:"
msgstr ""
"Пример конфигурации для Keystone и Nova будет выглядеть следующим образом:"

msgid "Securing services with SSL certificates"
msgstr "Защита сервисов при помощи SSL сертификатов"

msgid "Security Headers"
msgstr "Заголовки безопасности"

msgid ""
"Security headers are HTTP headers that can be used to increase the security "
"of a web application by restricting what modern browsers are able to run."
msgstr ""
"Заголовки безопасности — это HTTP-заголовки, которые можно использовать для "
"повышения безопасности веб-приложения путем ограничения того, что "
"современные браузеры могут запускать."

msgid "Security settings"
msgstr "Настройки безопасности"

msgid ""
"See `Setting up apt-get to use a http-proxy <https://help.ubuntu.com/"
"community/AptGet/Howto#Setting_up_apt-get_to_use_a_http-proxy>`_"
msgstr ""
"См. `Настройка apt-get для использования http-прокси <https://help.ubuntu."
"com/community/AptGet/Howto#Setting_up_apt-get_to_use_a_http-proxy>`_"

msgid ""
"See the :deploy_guide:`Deployment Guide <index.html>` for a more detailed "
"break down of how to implement your own configuration rather than to use the "
"AIO bootstrap."
msgstr ""
"Ознакомьтесь с :deploy_guide:`Deployment Guide <index.html>`, где более "
"подробно описаны способы применения собственной конфигурации, вместо "
"использования начальной подготовки AIO."

msgid "Self-service project/tenant networks for instances"
msgstr "Собственные сети проектов/тенантов для инстансов"

msgid "Self-signed certificates"
msgstr "Самоподписанные сертификаты"

msgid ""
"Self-signed certificates are generated for each service during the first run "
"of the playbook."
msgstr ""
"Самоподписанные сертификаты генерируются для каждого сервиса во время "
"первого запуска плейбука."

msgid ""
"Self-signed certificates can play an important role in securing internal "
"services within the OpenStack-Ansible deployment, as they can only be issued "
"by the private CA associated with the deployment. Using mutual TLS between "
"backend services such as RabbitMQ and MariaDB with self-signed certificates "
"and a robust CA setup can ensure that only correctly authenticated clients "
"can connect to these internal services."
msgstr ""
"Самоподписанные сертификаты могут играть важную роль в обеспечении "
"безопасности внутренних служб в рамках развертывания OpenStack-Ansible, "
"поскольку они могут быть выпущены только частным CA, связанным с "
"развертыванием. Использование взаимного TLS между внутренними службами, "
"такими как RabbitMQ и MariaDB, с самоподписанными сертификатами и надежной "
"настройкой CA может гарантировать, что только правильно аутентифицированные "
"клиенты смогут подключаться к этим внутренним службам."

msgid ""
"Self-signed certificates enable you to start quickly and encrypt data in "
"transit. However, they do not provide a high level of trust for public "
"endpoints in highly secure environments. By default, self-signed "
"certificates are used in OpenStack-Ansible. When self-signed certificates "
"are used, certificate verification is automatically disabled."
msgstr ""
"Самоподписанные сертификаты позволяют быстро начать работу и шифровать "
"данные при передаче. Однако, они не обеспечивают высокий уровень доверия для "
"публичных точек доступа в высокозащищенных средах. По умолчанию в OpenStack-"
"Ansible используются самоподписанные сертификаты. При использовании "
"самоподписанных сертификатов проверка сертификатов автоматически отключается."

msgid ""
"Self-signed user certificates are generated but not installed for services "
"outside of OpenStack-Ansible. These user certificates are signed by the same "
"self-signed certificate authority as is used by OpenStack services but are "
"intended to be used by user applications."
msgstr ""
"Самоподписанные сертификаты пользователя генерируются, но не устанавливаются "
"для служб за пределами OpenStack-Ansible. Эти сертификаты пользователя "
"подписаны тем же самоподписанным центром сертификации, который используется "
"службами OpenStack, но предназначены для использования пользовательскими "
"приложениями."

msgid "Service configuration"
msgstr "Конфигурация службы"

msgid ""
"Should an existing AIO environment need to be reinstalled, the most "
"efficient method is to destroy the host operating system and start over. For "
"this reason, AIOs are best run inside of some form of virtual machine or "
"cloud guest."
msgstr ""
"Если необходимо переустановить окружение AIO, самый эффективный способ это "
"переустановить операционную систему на сервере и начать с начала. По этой "
"причине лучше всего запускать AIO в виртуальной машине или гостевом облаке."

msgid ""
"Similar to domain-based endpoints we rely on HAProxy maps functionality. But "
"instead of ``map_dom`` we will be using ``map_reg``."
msgstr ""
"Подобно доменным точкам доступа мы полагаемся на функциональность карт "
"HAProxy. Но вместо ``map_dom`` мы будем использовать ``map_reg``."

msgid ""
"Similar to the domain-based endpoints we need to override endpoints "
"definition for each service. Endpoints are usually defined with following "
"variables:"
msgstr ""
"Подобно доменным точкам доступа нам нужно переопределить значение точек "
"доступа для каждой службы. Точки доступа обычно определяются со следующими "
"переменными:"

msgid "Single interface or bond"
msgstr "Одиночный интерфейс или агрегация"

msgid ""
"So even if you only want to override the ``_git_install_branch`` for a "
"repository, you should also define the ``_git_repo`` variable in your user "
"variables."
msgstr ""
"Таким образом, даже если вы хотите переопределить ``_git_install_branch`` "
"для репозитория, вам необходимо также определить и переменную ``_git_repo`` "
"среди пользовательских переменных."

msgid ""
"So first of all setup a redis server/cluster, e.g. with this `ansible "
"role`_. Next, you have to configure Gnocchi with OpenStack-Ansible to use "
"the Redis Cluster as incoming storage:"
msgstr ""
"Сначала произведите установку сервера/кластера redis, например при помощи "
"данной `ansible роли`_. Далее вам необходимо настроить Gnocchi с openStack-"
"Ansible на использования кластера Redis в качестве хранилища для входящих "
"метрик:"

msgid ""
"So we need to define a map file to be used and a way to parse it. For that "
"we need to apply an override for the `base` service."
msgstr ""
"Итак, нам нужно определить файл карты, который будет использоваться, и "
"способ его анализа. Для этого нам нужно применить переопределение для службы "
"`base`."

msgid ""
"So we now need to make service respect the path and respond correctly on it. "
"One way of doing that could be using rewrite mechanism in uWSGI, for example:"
msgstr ""
"Итак, теперь нам нужно заставить службу уважать путь и правильно реагировать "
"на него. Одним из способов сделать это может быть использование rewrite "
"механизма в uWSGI, например:"

msgid "So your Let's Encrypt configuration may look like this:"
msgstr ""
"Итак, ваша конфигурация Let's Encrypt может выглядеть следующим образом:"

msgid ""
"Some networks have no routed access to the Internet, or require certain "
"traffic to use application specific gateways such as HTTP or SOCKS proxy "
"servers."
msgstr ""
"Некоторые сети не имеют маршрутизируемого доступа в Интернет, или требуют "
"для определенного трафика использовать специфичные шлюзы, такие как HTTP или "
"SOCKS прокси серверы."

msgid ""
"Some services, like keystone, have a configuration options which may control "
"how `href` is being defined. For instance, keystone does have `[DEFAULT]/"
"public_endpoint` option, but this approach is not consistent across "
"services. Moreover, keystone will return provided `public_endpoint` for all "
"endpoints, including admin and internal."
msgstr ""
"Некоторые службы, такие как keystone, имеют параметры конфигурации, которые "
"могут контролировать, как определяется `href`. Например, keystone имеет "
"параметр `[DEFAULT]/public_endpoint`, но этот подход не является "
"единообразным для всех служб. Более того, keystone вернет предоставленный "
"`public_endpoint` для всех точек доступа, включая административную и "
"внутреннюю."

msgid ""
"Sometimes it may be useful to destroy all the containers and rebuild the "
"AIO. While it is preferred that the AIO is entirely destroyed and rebuilt, "
"this isn't always practical. As such the following may be executed instead:"
msgstr ""
"Иногда может быть полезным удаление всех контейнеров и переустановка AIO. "
"Хоть и рекомендуется полное удаление AIO и переустановка с нуля, это не "
"всегда практично. Потому, можно выполнить следующее, вместо полной "
"переустановки:"

msgid "Source code repositories"
msgstr "Репозитории с исходным кодом"

msgid "Source overriding examples"
msgstr "Пример переопределения источников"

msgid ""
"Specify the path to your SSL certificate, key, and CA certificate in the ``/"
"etc/openstack_deploy/user_variables.yml`` file."
msgstr ""
"Укажите путь к вашему SSL сертификату, ключу и промежуточным сертификатам в "
"файле ``/etc/openstack_deploy/user_variables.yml``."

msgid "Spread load across Availability Zones"
msgstr "Распределение нагрузки по зонам доступности"

msgid "Standard deployment of RabbitMQ server"
msgstr "Стандартная установка RabbitMQ сервера"

msgid ""
"Start by cloning the OpenStack-Ansible repository and changing into the "
"repository root directory:"
msgstr ""
"Начните с клонирования репозитория OpenStack-Ansible и перехода в его "
"корневую директорию:"

msgid ""
"Static routes are added to allow communication between the Management, "
"Tunnel, and Storage Networks of each pod. The gateway address is the first "
"usable address within each network's subnet."
msgstr ""
"Добавлены статические маршруты для связи между управляющей сетью, "
"туннелированной сетью и сетью хранилища данных для каждого блока. Адрес "
"шлюза это первый используемый адрес в каждой подсети."

msgid ""
"Static routes are added to allow communication of provider networks between "
"pods."
msgstr ""
"Статические маршруты добавлены для коммуникации сетей провайдера между "
"блоками."

msgid "Storage IP"
msgstr "IP хранилища данных"

msgid "Storage Network"
msgstr "Сеть хранилища данных"

msgid "Storage design complications"
msgstr "Сложности проектирования систем хранения"

msgid "Switch port configuration"
msgstr "Настройка порта сетевого коммутатора"

msgid "Switch port configuration example"
msgstr "Пример настройки портов сетевых коммутаторов"

msgid "Systems with traditional hard disks: ~ 90-120 minutes"
msgstr "Системы с традиционными жесткими дисками: ~90-120 минут"

msgid "TLS for HAProxy Backends"
msgstr "TLS для бекэндов HAProxy"

msgid "TLS for HAProxy Internal VIP"
msgstr "TLS для внутреннего VIP HAProxy"

msgid "TLS for Live Migrations"
msgstr "TLS для живых миграций"

msgid "TLS for VNC"
msgstr "TLS для VNC"

msgid ""
"Take particular care not to regenerate Root or Intermediate certificate "
"authorities in a way that may invalidate existing server certificates in the "
"deployment. It may be preferable to create new Intermediate CA certificates "
"rather than regenerate existing ones in order to maintain existing chains of "
"trust."
msgstr ""
"Будьте особенно осторожны, чтобы не перегенерировать корневые или "
"промежуточные центры сертификации таким образом, что это может сделать "
"недействительными существующие сертификаты сервера в развертывании. Может "
"быть предпочтительнее создать новые промежуточные сертификаты CA, чем "
"перегенерировать существующие, чтобы сохранить существующие цепочки доверия."

msgid ""
"Target and deployment hosts can be configured to reach public internet "
"resources via HTTP or SOCKS proxy server(s). OpenStack-Ansible may be used "
"to configure target hosts to use the proxy server(s). OpenStack-Ansible does "
"not provide automation for creating the proxy server(s)."
msgstr ""
"Настройка может быть применена к целевым серверам и хосту развертывания для "
"получения доступа к публичным интернет ресурсам через HTTP или SOCKS прокси "
"сервер(ы). OpenStack-Ansible может быть использован для настройки целевых "
"хостов использовать прокси сервер(ы). OpenStack-Ansible не предоставляет "
"автоматизацию по созданию прокси сервера(ов)."

msgid "Telemetry with Gnocchi, Ceph and Redis example"
msgstr "Пример Telemetry с Gnocchi, Ceph и Redis"

msgid "Test environment example"
msgstr "Пример тестового окружения"

msgid "Test environment host layout"
msgstr "Схема хоста тестовой среды"

msgid ""
"The CIDRs and VLANs listed for each network are examples and may be "
"different in your environment."
msgstr ""
"Указанные для каждой сети CIDR и VLAN приведены в качестве примера и могут "
"отличаться в вашем окружении."

msgid ""
"The HAProxy ACL is updated by overriding the variable "
"``haproxy_map_entries`` inside ``haproxy_security_txt_service``."
msgstr ""
"Список контроля доступа HAProxy обновляется путем переопределения переменной "
"``haproxy_map_entries`` внутри ``haproxy_security_txt_service``."

msgid ""
"The HAProxy ansible role supports using certbot to automatically deploy "
"trusted SSL certificates for the public endpoint. Each HAProxy server will "
"individually request a SSL certificate using certbot."
msgstr ""
"Роль HAProxy ansible поддерживает использование certbot для автоматического "
"развертывания доверенных сертификатов SSL для публичной точки доступа. "
"Каждый сервер HAProxy будет индивидуально запрашивать сертификат SSL с "
"помощью certbot."

msgid ""
"The Horizon web interface provides a graphical interface for interacting "
"with the AIO deployment. By default, the Horizon API is available on port "
"443 of the host (or port 80, if SSL certificate configuration was disabled). "
"As such, to interact with Horizon, simply browse to the IP of the host."
msgstr ""
"Веб-интерфейс Horizon предоставляет графический интерфейс для взаимодействия "
"с развертыванием AIO. По умолчанию API Horizon доступен на порту 443 хоста "
"(или порту 80, если конфигурация сертификата SSL отключена). Таким образом, "
"для взаимодействия с Horizon просто перейдите на IP-адрес хоста."

msgid ""
"The OpenStack-Ansible example configurations are designed to be minimal "
"examples and in test or development use-cases will set "
"``external_lb_vip_address`` to the IP address of the HAProxy external "
"endpoint. For a production deployment it is advised to set "
"``external_lb_vip_address`` to be the FQDN which resolves via DNS to the IP "
"of the external endpoint."
msgstr ""
"Примеры конфигураций OpenStack-Ansible разработаны как минимальные примеры и "
"в тестовых или разрабатываемых сценариях использования установят "
"``external_lb_vip_address`` на IP-адрес внешней точки доступа HAProxy. Для "
"рабочего развертывания рекомендуется установить ``external_lb_vip_address`` "
"на полное доменное имя, которое разрешается через DNS в IP внешней точки "
"доступа."

msgid ""
"The OpenStack-Ansible reference architecture segments traffic using VLANs "
"across multiple network interfaces or bonds. Common networks used in an "
"OpenStack-Ansible deployment can be observed in the following table:"
msgstr ""
"Эталонная архитектура OpenStack-Ansible разделяет трафик используя VLAN-ы на "
"нескольких сетевых интерфейсах или агрегациях. Стандартные сети, "
"используемые при развертывании OpenStack-Ansible описаны в следующей таблице:"

msgid ""
"The RPC is intended as a synchronous exchange between a client and server "
"that is temporally bracketed. The information transferred typically "
"corresponds to a request-response pattern for service command invocation. If "
"the server is not present at the time the command is invoked, the call "
"should fail. The temporal coupling requires that the messaging backend "
"deployed support the bi-directional transfer of the request from caller to "
"server and the associated reply sent from the server back to the caller. "
"This requirement can be satisfied by a broker queue or a direct messaging "
"backend server."
msgstr ""
"RPC предназначался для синхронного обмена между клиентом и сервером, который "
"временно ограничен. Передаваемая информация обычно отвечает паттерну запроса-"
"ответа для вызова команд сервиса. Если сервер отсутствует в момент "
"выполнения команды, вызов должен завершиться ошибкой. Временная связь "
"требует, что бы сервер обмена сообщениями имел поддержку двунаправленной "
"передачи запроса от вызывающего к серверу и связного ответа от сервера "
"обратно к вызывающему. Это требование может быть удовлетворено очередью "
"брокера или прямым обменом сообщениями сервера."

msgid ""
"The `OpenStack Security Guide`_ recommends providing secure communication "
"between various services in an OpenStack deployment. The OpenStack-Ansible "
"project currently offers the ability to configure SSL certificates for "
"secure communication between services:"
msgstr ""
"`Инструкция по безопасности OpenStack`_ рекомендует использовать защищенное "
"соединение между различными сервисами в окружении OpenStack. Проект "
"OpenStack-Ansible в данный момент предоставляет возможность настройки SSL "
"сертификатов для безопасного взаимодействия между сервисами:"

msgid ""
"The `OpenStack TLS Security Guide`_ recommends that all production "
"deployments use HTTP strict transport security (HSTS)."
msgstr ""
"` Гид по безопасности OpenStack TLS`_ советует всем окружениям в "
"промышленном использовании использовать HTTP Strict Transport Security "
"(HSTS)."

msgid ""
"The ``/etc/openstack_deploy/openstack_user_config.yml`` file defines the "
"environment layout."
msgstr ""
"Файл ``/etc/openstack_deploy/openstack_user_config.yml`` определяет, как "
"будет выглядеть окружение."

msgid ""
"The ``/etc/openstack_deploy/user_variables.yml`` file defines the global "
"overrides for the default variables."
msgstr ""
"В файле ``/etc/openstack_deploy/user_variables.yml`` расположены глобальные "
"переопределения стандартных переменных."

msgid ""
"The ``Content-Security-Policy`` header allows you to control what resources "
"a browser is allowed to load for a given page, which helps to mitigate the "
"risks from Cross-Site Scripting (XSS) and data injection attacks."
msgstr ""
"Заголовок ``Content-Security-Policy`` позволяет контролировать, какие "
"ресурсы браузеру разрешено загружать для определенной страницы, что помогает "
"снизить риски, связанные с межсайтовым скриптингом (XSS) и атаками с "
"внедрением данных."

msgid ""
"The ``Management Network``, also referred to as the ``container network``, "
"provides management of and communication between the infrastructure and "
"OpenStack services running in containers or on metal. The ``management "
"network`` uses a dedicated VLAN typically connected to the ``br-mgmt`` "
"bridge, and may also be used as the primary interface used to interact with "
"the server via SSH."
msgstr ""
"``Сеть управления``, также упоминающаяся как ``сеть контейнеров`` служит для "
"управления и общения между инфраструктурой и сервисами OpenStack, которые "
"запущены как в контейнерах так и без них. ``Сеть управления`` использует "
"выделенный VLAN, обычно подключенный к мосту ``br-mgmt`` и может быть "
"использован как основной интерфейс для взаимодействия с сервером по SSH."

msgid ""
"The ``Overlay Network``, also referred to as the ``tunnel network``, "
"provides connectivity between hosts for the purpose of tunnelling "
"encapsulated traffic using VXLAN, Geneve, or other protocols. The ``overlay "
"network`` uses a dedicated VLAN typically connected to the ``br-vxlan`` "
"bridge."
msgstr ""
"``Overlay сеть``, также называемая ``туннелированная сеть``, обеспечивает "
"связь между хостами с целью туннелирования инкапсулированного трафика с "
"использованием VXLAN, Geneve или других протоколов. ``Overlay сеть`` "
"использует выделенный VLAN, обычно подключенный к мосту ``br-vxlan``."

msgid ""
"The ``Permissions-Policy`` header allows you to selectively enable, disable "
"or modify the use of browser features and APIs, previously known as Feature "
"Policy."
msgstr ""
"Заголовок ``Permissions-Policy`` позволяет выборочно включать, отключать или "
"изменять использование функций браузера и API, ранее известный как Feature "
"Policy."

msgid ""
"The ``Referrer-Policy`` header controls how much referrer information is "
"sent with requests. It defaults to ``same-origin``, which does not send the "
"origin path for cross-origin requests."
msgstr ""
"Заголовок ``Referrer-Policy`` контролирует, сколько информации о реферере "
"отправляется с запросами. По умолчанию он равен ``same-origin``, что не "
"отправляет путь источника для запросов кросс-источника."

msgid ""
"The ``Storage Network`` provides segregated access to Block Storage from "
"OpenStack services such as Cinder and Glance. The ``storage network`` uses a "
"dedicated VLAN typically connected to the ``br-storage`` bridge."
msgstr ""
"``Сеть хранилища данных`` предоставляет разделенный доступ к блочному "
"хранилищу с таких сервисов OpenStack, как Cinder и Glance. ``Сеть хранилища "
"данных`` использует выделенный VLAN, обычно подключенный к мосту ``br-"
"storage``."

msgid "The ``X-Content-Type-Options`` header prevents MIME type sniffing."
msgstr "Заголовок ``X-Content-Type-Options`` предотвращает перехват типа MIME."

msgid ""
"The ``ansible-hardening`` role is applicable to physical hosts within an "
"OpenStack-Ansible deployment that are operating as any type of node, "
"infrastructure or compute. By default, the role is enabled. You can disable "
"it by changing the value of the ``apply_security_hardening`` variable in the "
"``user_variables.yml`` file to ``false``:"
msgstr ""
"Роль ``ansible-hardening`` применима к физическим хостам любого типа внутри "
"развертывания OpenStack-Ansible - как инфраструктурного, так и "
"вычислительного. По умолчанию роль включена. Вы можете выключить ее "
"установив значение переменной ``apply_security_hardening`` в файле "
"``user_variables.yml`` в ``false``:"

msgid ""
"The ``bootstrap-ansible.sh`` script installs Ansible, and uses a variable "
"``ANSIBLE_PACKAGE`` to describe which version to install."
msgstr ""
"Скрипт ``bootstrap-ansible.sh`` производит установку Ansible и использует "
"переменную ``ANSIBLE_PACKAGE`` для описания версии для установки."

msgid ""
"The ``container_interface`` parameter is only necessary when Neutron agents "
"are run in containers, and can be excluded in many cases. The "
"``container_bridge`` and ``container_type`` parameters also relate to "
"infrastructure containers, but should remain defined for legacy purposes."
msgstr ""
"Параметр ``container_interface`` необходим только когда агенты Neutron "
"запущены в контейнерах и может не указываться в многих случаях. Параметры "
"``container_bridge`` и ``container_type`` также относятся к инфраструктуре "
"контейнеров, но должны оставаться определенными для обратной совместимости."

msgid ""
"The ``image_metadata_prefilter`` only looks at the HW_ARCH_XXX traits on "
"compute hosts and finds hardware that matches the required architecture. "
"This only happens when the ``hw_architecture`` property is present on an "
"image, and only if the required traits are manually added to compute hosts."
msgstr ""
"``image_metadata_prefilter`` просматривает только признаки HW_ARCH_XXX на "
"вычислительных хостах и ​​находит оборудование, которое соответствует "
"требуемой архитектуре. Это происходит только тогда, когда свойство "
"``hw_architecture`` присутствует на изображении, и только если требуемые "
"признаки вручную добавлены на вычислительные хосты."

msgid ""
"The ``image_metadata_prefilter`` setting forces the Nova scheduler to match "
"the ``hw_architecture`` property on Glance images with the corresponding "
"HW_ARCH_XXX trait on compute host resource providers. This ensures that "
"images explicitly tagged with a target architecture get scheduled hosts with "
"a matching architecture."
msgstr ""
"Настройка ``image_metadata_prefilter`` заставляет планировщик Nova "
"сопоставлять ``hw_architecture`` параметр в образах Glance  с "
"соответствующей HW_ARCH_XXX спецификацией для вычислительного хоста в списке "
"провайдеров ресурсов. Это удостоверяет, что образы которые были маркированы "
"целевой архитектурой будут созданы на серверах с совпадающей архитектурой."

msgid ""
"The ``image_properties_default_architecture`` is used by the "
"ImagePropertiesFilter which examines all the architectures supported by QEMU "
"on each compute host; this includes software emulations of non-native "
"architectures."
msgstr ""
"``image_properties_default_architecture`` используется "
"ImagePropertiesFilter, который проверяет все архитектуры, поддерживаемые "
"QEMU на каждом вычислительном хосте; это включает программные эмуляции "
"неродных архитектур."

msgid ""
"The ``image_properties_default_architecture`` setting would apply in an "
"existing ``x86_64`` architecture cloud where previously ``hw_architecture`` "
"was not set on all Glance images. This avoids the need to retrospectively "
"apply the property for all existing images which may be difficult as users "
"may have their own tooling to create and upload images without applying the "
"required property."
msgstr ""
"Настройка ``image_properties_default_architecture`` применит существующую "
"``x86_64`` архитектуру ко всем образам Glance, где архитектура ранее не была "
"задана. Это предотвратит необходимость ретроспективно применять параметры ко "
"всем существующим образам, что может быть трудозатратно для пользователей "
"которые имеют различные инструменты автоматизации без применения данного "
"параметра."

msgid ""
"The ``py_pkgs lookup`` will ignore all _git_ variables unless the "
"``_git_repo`` variable is present."
msgstr ""
"``py_pkgs lookup`` будет игнорировать все переменные _git_ до тех пор, пока "
"переменная ``_git_repo`` присутствует."

msgid ""
"The bootstrap script is pre-set to pass the environment variable "
"``BOOTSTRAP_OPTS`` as an additional option to the bootstrap process. For "
"example, if you wish to set the bootstrap to re-partition a specific "
"secondary storage device (``/dev/sdb``), which will erase all of the data on "
"the device, then execute:"
msgstr ""
"Скрипт начальной подготовки настроен на передачу переменной окружения "
"``BOOTSTRAP_OPTS`` как дополнительного параметра для процесса подготовки. "
"Например, если вы хотите, задать второй диск  (``/dev/sdb``) для "
"переразметки при подготовке, которая удалит все данные на данном устройстве, "
"выполните:"

msgid ""
"The custom group can then be specifed when creating a provider network, as "
"shown here:"
msgstr ""
"Пользовательская группа может быть позже определена при создании сети "
"провайдера, как показано ниже:"

msgid ""
"The default OpenStack-Ansible installation configures gnocchi to use a file "
"as storage backend. When you already have a pre-installed ceph, you can use "
"this as backend for gnocchi. This documentation will guide you how to set up "
"gnocchi to use your ceph as storage backend."
msgstr ""
"Установка OpenStack-Ansible по умолчанию настраивает gnocchi на "
"использование файла в качестве бекэнда хранилища. Если у вас уже есть "
"предустановленный ceph, вы можете использовать его в качестве бекэнда для "
"gnocchi. Эта документация поможет вам настроить gnocchi для использования "
"ceph в качестве бекэнда хранилища."

msgid ""
"The deployer must decide which of these approaches is more suitable for the "
"target hosts, taking into account the following guidance:"
msgstr ""
"Оператор должен решить какой из данных подходов больше подходит для целевых "
"хостов, учитывая следующие рекомендации:"

msgid ""
"The example also deploys HAProxy with Keepalived in their own LXC containers "
"on the contrary to a more conventional bare metal deployment. You can check "
"a :ref:`haproxy-in-lxc` for more details on how to do that."
msgstr ""
"В примере также развертывается HAProxy с Keepalived в их собственных "
"контейнерах LXC в отличие от более традиционного развертывания на bare "
"metal. Вы можете проверить :ref:`haproxy-in-lxc` для получения более "
"подробной информации о том, как это сделать."

msgid "The following CIDR and VLAN assignments are used for this environment."
msgstr "Следующие CIDR и VLAN назначения используются для данного окружения."

msgid "The following CIDR assignments are used for this environment."
msgstr "Следующие CIDR назначения используются для данного окружения."

msgid "The following configuration describes the layout for this environment."
msgstr "Следующая настройка описывает устройство данного окружения."

msgid "The following design decisions were made in the example below:"
msgstr "В приведенном ниже примере были приняты следующие проектные решения:"

msgid ""
"The following diagram demonstates how a custom group can be used to further "
"segment hosts:"
msgstr ""
"Следующая диаграмма демонстрирует как пользовательская группа может быть "
"использована для дальнейшего разделения хостов:"

msgid ""
"The following diagram demonstates servers with different network interface "
"names:"
msgstr ""
"Следующая диаграмма демонстрирует серверы с различными именами сетевых "
"интерфейсов:"

msgid ""
"The following diagram demonstrates a compute node serving as an OVN gatway. "
"It is connected to the public network, which enables to connect VMs to "
"public networks not only through routers, but also directly:"
msgstr ""
"На следующей схеме показан вычислительный узел, выполняющий функции шлюза "
"OVN. Он подключен к публичной сети, что позволяет подключать виртуальные "
"машины к публичным сетям не только через маршрутизаторы, но и напрямую:"

msgid "The following diagram demonstrates hosts using a single bond:"
msgstr ""
"Данная диаграмма демонстрирует использование хостами одного агрегированного "
"интерфейса:"

msgid ""
"The following diagram demonstrates hosts using a single interface for OVS "
"and LinuxBridge Scenario:"
msgstr ""
"Данная диаграмма демонстрирует использование хостами одиночного интерфейса "
"для сценариев OVS и Linux Bridge:"

msgid "The following diagram demonstrates hosts using multiple bonds:"
msgstr ""
"Данная диаграмма демонстрирует использование хостами нескольких агрегаций:"

msgid ""
"The following diagram demonstrates hosts using multiple interfaces for OVS "
"and LinuxBridge Scenario:"
msgstr ""
"Данная диаграмма демонстрирует использование хостами нескольких интерфейсов "
"для сценариев OVS и Linux Bridge:"

msgid "The following diagrams demonstrate hosts using a single bond with OVN."
msgstr ""
"Данная диаграмма демонстрирует использование хостами одиночного интерфейса с "
"OVN:"

msgid "The following diagrams demonstrate hosts using multiple bonds with OVN."
msgstr ""
"Данная диаграмма демонстрирует использование хостами нескольких "
"агрегированных интерфейсов с OVN:"

msgid ""
"The following example provides a good reference for switch configuration and "
"cab layout. This example may be more that what is required for basic setups "
"however it can be adjusted to just about any configuration. Additionally you "
"will need to adjust the VLANS noted within this example to match your "
"environment."
msgstr ""
"Следующий пример предоставляет хороший шаблон для настройки коммутатора и "
"разводки кабелей. Данный пример может быть несколько избыточным для "
"стандартных установок, но он может быть адаптирован для практически любой "
"конфигурации. Дополнительно вам необходимо будет изменить используемые в "
"данном примере VLAN-ы для соответствия вашему окружению."

msgid ""
"The following headers are enabled by default on all the HAProxy interfaces "
"that implement TLS, but only for the Horizon service. The security headers "
"can be implemented on other HAProxy services, but only services used by "
"browsers will make use of the headers."
msgstr ""
"Следующие заголовки включены по умолчанию на всех интерфейсах HAProxy, "
"которые реализуют TLS, но только для службы Horizon. Заголовки безопасности "
"могут быть реализованы на других службах HAProxy, но только службы, "
"используемые браузерами, будут использовать заголовки."

msgid ""
"The following host name and IP address assignments are used for this "
"environment."
msgstr "Следующие имена хостов и IP адреса используются для данного окружения."

msgid ""
"The groups ``network_hosts`` and ``compute_hosts`` are pre-defined groups in "
"an OpenStack-Ansible deployment."
msgstr ""
"Группы ``network_hosts`` и ``compute_hosts`` предустановленны в "
"развертываниях OpenStack-Ansible."

msgid ""
"The http-01 type challenge is used by certbot to deploy certificates so it "
"is required that the public endpoint is accessible directly by the "
"Certificate Authority."
msgstr ""
"Запрос типа http-01 используется certbot для развертывания сертификатов, "
"поэтому необходимо, чтобы публичная точка доступа была доступна напрямую "
"центру сертификации."

msgid ""
"The installation process will take a while to complete, but here are some "
"general estimates:"
msgstr ""
"Процесс установки займет некоторое время, но продолжительность, примерно, "
"следующая:"

msgid ""
"The next step is to bootstrap Ansible and the Ansible roles for the "
"development environment."
msgstr ""
"Следующий шаг это выполнение подготовки Ansible и Ansible ролей для среды "
"разработки."

msgid ""
"The only way to use a different TLS certificates on the internal and "
"external VIP is to use certbot."
msgstr ""
"Единственный способ использовать разные сертификаты TLS на внутреннем и "
"внешнем VIP — это использовать certbot."

msgid ""
"The optionally deployed files in ``/etc/openstack_deploy/env.d`` allow the "
"customization of Ansible groups. This allows the deployer to set whether the "
"services will run in a container (the default), or on the host (on metal)."
msgstr ""
"Опционально размещаемые файлы в ``/etc/openstack_deploy/env.d`` позволяют "
"модифицировать группы Ansible. Это позволяет оператору задать, будут ли "
"сервисы запущены в контейнере (по умолчанию), либо же на сервере (без "
"контейнера)."

msgid ""
"The options below are not mutually exclusive and may be combined if desired."
msgstr ""
"Нижеприведенные параметры не исключают друг друга, и могут быть совмещены "
"при необходимости."

msgid ""
"The oslo.messaging drivers provide the transport integration for the "
"selected protocol and backend server. The following table summarizes the "
"supported oslo.messaging drivers and the communication services they support."
msgstr ""
"Драйверы oslo.messaging предоставляют интеграцию транспорта для выбранного "
"протокола и сервера. Следующая таблица резюмирует поддерживаемые драйверы "
"oslo.messaging и сервисы взаимодействия, которые они поддерживают."

msgid ""
"The oslo.messaging library is part of the OpenStack Oslo project that "
"provides intra-service messaging capabilities. The library supports two "
"communication patterns (RPC and Notify) and provides an abstraction that "
"hides the details of the messaging bus operation from the OpenStack services."
msgstr ""
"Библиотека oslo.messaging является частью проекта OpenStack Oslo, который "
"предоставляет возможности обмена сообщениями между сервисами. Библиотека "
"поддерживает два паттерна взаимодействия (RPC и уведомления) и предоставляет "
"абстракцию, которая прячет детали процесса обмена сообщениями от сервисов "
"OpenStack."

msgid ""
"The oslo.messaging library supports a messaging `transport plugin`_ "
"capability such that RPC and Notify communications can be separated and "
"different messaging backend servers can be deployed."
msgstr ""
"Библиотека oslo.messaging поддерживает возможность `transport plugin`_, так "
"что RPC и уведомления могут быть разъединены и для них могут быть развернуты "
"различные серверы для обмена сообщениями."

msgid ""
"The playbook deploys your user-provided SSL certificate, key, and CA "
"certificate to each RabbitMQ container."
msgstr ""
"Плейбук установит предоставленный вами SSL сертификат, ключ и промежуточные "
"сертификаты на каждый контейнер RabbitMQ."

msgid ""
"The process is identical for the other services. Replace `rabbitmq` in the "
"preceding configuration variables with `horizon`, `haproxy`, or `keystone`, "
"and then run the playbook for that service to deploy user-provided "
"certificates to those services."
msgstr ""
"Процесс идентичен для остальных сервисов. Замените префикс `rabbitmq` в "
"переменной на `horizon`, `haproxy` или `keystone`, а после запустите плейбук "
"для данного сервиса для разливки предоставленного сертификата на данные "
"сервисы."

msgid ""
"The reason of this failure might be resulting from a noexec mount flag used "
"for the filesystem associated with /tmp which you can check by running the "
"following command:"
msgstr ""
"Причина данной ошибки может быть следствием установленного флага noexec, "
"использованного при монтировании файловой системы для /tmp, который вы "
"можете проверить при помощи следующей команды:"

msgid ""
"The required changes are described in the documentation of Ceilometer. This "
"is just a sum up. In your ceph.conf add:"
msgstr ""
"Данные изменения описаны в документации к Ceilometer. Мы приводим это только "
"чтобы подвести итог. В вашем ceph.conf добавьте:"

msgid "The required user and credentials is created by this command:"
msgstr "Требуемый пользователь и данные доступа создаются следующей командой:"

msgid ""
"The telemetry (and in consequence accounting) for radosgw as object-storage "
"will not work out of the box. You need to change different parts of your "
"OpenStack and Ceph setup to get it up and running."
msgstr ""
"Telemetry (и, как следствие, учет) для radosgw как объектного хранилища не "
"работает сразу после установки. Необходимо отредактировать некоторые части "
"вашей установки OpenStack и Ceph для включения поддержки сбора данных."

msgid ""
"The trait set command replaces all existing traits with the set provided, so "
"you must specify all existing traits as well as the new trait."
msgstr ""
"Команда установки спецификаций замещает все существующие в базе спецификации "
"переданным в команду значением, соответсвенно вам необходимо передать все "
"уже существующие спецификации вместе с новыми."

msgid ""
"The variables to set which provide the path on the deployment node to the "
"certificates for HAProxy configuration are:"
msgstr ""
"Переменные к определению, которые содержат путь к сертификатам на ноде "
"развертывания для настройки HAProxy:"

msgid ""
"The |current_release_formal_name| release is only compatible with Debian 12 "
"(bookworm), Ubuntu 22.04 (Jammy Jellyfish), Ubuntu 24.04 (Noble Numbat), "
"CentOS 9 Stream, and derivitives of CentOS Stream/RHEL such as Rocky Linux."
msgstr ""
"Текущий релиз |current_release_formal_name| совместим только со следующими "
"опреационными системами:  Debian 12 (bookworm), Ubuntu 22.04 (Jammy "
"Jellyfish), Ubuntu 24.04 (Noble Numbat), CentOS 9 Stream и производными "
"CentOS Stream/RHEL, такими как Rocky Linux."

msgid ""
"Then, in `/etc/openstack_deploy/user_variables.yml`, configure the "
"deployment to copy these files from the host into the container cache image."
msgstr ""
"После, в `/etc/openstack_deploy/user_variables.yml`, настройте развертывание "
"для копирования данных файлов с хоста в кэш образа контейнера."

msgid "Then, run the playbook to apply the certificates:"
msgstr "Потом запустите плейбук для применения сертификатов:"

msgid ""
"There are a variety of clients and libraries available for interacting with "
"an OpenStack deployment, including as `openstackclient`__, `openstacksdk`__, "
"or `gophercloud`__. These are typically configured using either environment "
"variables sourced from an ``openrc`` file or the newer ``clouds.yaml`` file."
msgstr ""
"Существует множество клиентов и библиотек, доступных для взаимодействия с "
"развертыванием OpenStack, включая `openstackclient`__, `openstacksdk`__ или "
"`gophercloud`__. Обычно они настраиваются с использованием переменных среды, "
"полученных из файла ``openrc`` или более нового файла ``clouds.yaml``."

msgid ""
"There are also couple of additional things which you might want to consider:"
msgstr ""
"Есть еще несколько дополнительных вещей, которые вам, возможно, стоит учесть:"

msgid ""
"There are multiple complications related to organizing storage where the "
"storage is not stretched between Availability Zones."
msgstr ""
"Существует множество сложностей, связанных с организацией хранения, когда "
"хранилище не распределено между зонами доступности."

msgid ""
"There are no issues enabling TLS live migration during an OpenStack upgrade, "
"as long as you do not need to live migrate instances during the upgrade. If "
"you you need to live migrate instances during an upgrade, enable TLS live "
"migrations before or after the upgrade."
msgstr ""
"Нет проблем с включением живой миграции TLS во время обновления OpenStack, "
"пока вам не нужно выполнять ee для инстансов во время обновления. Если же "
"вам нужно ее выполнить во время обновления, включите живую миграцию TLS  до "
"или после обновления."

msgid ""
"There are situations where a deployer want to override sources with its own "
"fork."
msgstr ""
"Бывают ситуации, когда оператор хочет переопределить источники своей "
"собственной копией."

msgid ""
"There are three steps to running an AIO build, with an optional first step "
"should you need to customize your build:"
msgstr ""
"Имеется три необходимых шага для запуска установки AIO, с опциональным "
"первым шагом, если вам нужно настроить развертывание:"

msgid ""
"There can be a usecase where you might want to run HAProxy and Keepalived "
"inside LXC containers. For instance, running these services on bare metal "
"assumes that a default route for hosts should be set towards a public "
"network. This scenario might be un-preferable for some deployments, "
"especially in cases where you do not have standalone Load-Balancing hosts, "
"but they're co-located with other infra services instead."
msgstr ""
"Может быть вариант использования, когда вы захотите запустить HAProxy и "
"Keepalived внутри контейнеров LXC. Например, запуск этих служб на физических "
"серверах предполагает, что маршрут по умолчанию для хостов должен быть "
"установлен в направлении публичной сети. Этот сценарий может быть "
"непредпочтительным для некоторых развертываний, особенно в случаях, когда у "
"вас нет отдельных балансировщиков нагрузки, но они размещены вместе с "
"другими инфраструктурными службами."

msgid "There is also an option to enable it only for individual services:"
msgstr "Также есть возможность включить его только для отдельных служб:"

msgid ""
"These lists are intentionally not exhaustive and equivalents will be "
"required for other Linux distributions. Consult the OpenStack-Ansible "
"playbooks and role documentation for further repositories and the variables "
"that may be used to override the repository location."
msgstr ""
"Эти списки намеренно не являются исчерпывающими, и для других дистрибутивов "
"Linux потребуются эквиваленты. Ознакомьтесь с плейбуками OpenStack-Ansible и "
"документацией по ролям для получения дополнительных репозиториев и "
"переменных, которые могут использоваться для переопределения "
"месторасположения репозитория."

msgid ""
"These tools and their underlying libraries are used by Ansible itself and "
"the OpenStack-Ansible playbooks, so there must be a proxy configuration in "
"place for the playbooks to successfully access external resources."
msgstr ""
"Эти инструменты и положенные в их  основу библиотеки используются как "
"непосредственно Ansible-ом, так и плейбуками OpenStack-Ansible. Потому для "
"успешного доступа плейбуков к внешним ресурсам должна быть произведена "
"настройка прокси."

msgid ""
"These variables behave a little differently than standard ansible "
"precedence, because they are also consumed by a custom lookup plugin."
msgstr ""
"Данные переменные ведут себя немного иначе, чем стандартные переменные "
"ansible, так как они также используются нестандартным lookup плагином."

msgid ""
"This OpenStack-Ansible documentation currently assumes that a deployer "
"wishes to run images on a compute host with a native CPU architecure, and "
"does not give an example configuration involving emulation."
msgstr ""
"В данной документации OpenStack-Ansible в настоящее время предполагается, "
"что оператор желает запускать образы на вычислительном хосте с собственной "
"архитектурой процессора, и не приводится пример конфигурации, включающий "
"эмуляцию."

msgid ""
"This chapter contains information to configure specific security settings "
"for your OpenStack-Ansible cloud."
msgstr ""
"Данный раздел содержит информацию о настройке определенных параметров "
"безопасности вашего облака OpenStack-Ansible."

msgid ""
"This chapter gives case-by-case examples on how to override the default "
"sources."
msgstr ""
"Данный раздел предоставляет ситуативные примеры переопределения стандартных "
"источников."

msgid ""
"This diagram is not to scale and is not even 100% accurate, this diagram was "
"built for informational purposes only and should **ONLY** be used as such."
msgstr ""
"Данная диаграмма не масштабируется и даже не точна на 100%, она была создана "
"в ознакомительных целях и должна использоваться **ТОЛЬКО** для них."

msgid "This example environment has the following characteristics:"
msgstr "Данное иллюстративное окружение имеет следующие характеристики:"

msgid ""
"This example will focus on the deployment of both OpenStack-Ansible and its "
"Ceph cluster."
msgstr ""
"Данный пример фокусируется на развертывании как OpenStack-Ansible, так и его "
"Ceph кластера."

msgid ""
"This functionality can be changed by overriding the list of headers in "
"``haproxy_security_headers`` variable in the ``/etc/openstack_deploy/"
"user_variables.yml`` file."
msgstr ""
"Эту функциональность можно изменить, переопределив список заголовков в "
"переменной ``haproxy_security_headers`` в файле ``/etc/openstack_deploy/"
"user_variables.yml``."

msgid ""
"This host will build python wheels for it's own architecture which will "
"speed up the deployment of many hosts. If you do not make a repository "
"server for each architecture, ensure that measures are taken not to overload "
"the opendev.org git servers, such as using local mirrors of all OpenStack "
"service repos."
msgstr ""
"Этот хост будет использован для сборки python wheels для собственной "
"архитектуры, которые в дальнейшем ускорят развертывание остальных хостов. "
"Если вы не создаете сервер репозитория для каждой архитектуры, убедитесь, "
"что приняты меры против перегрузки серверов git opendev.org. Например, "
"используя локальные зеркала для репозиториев всех служб OpenStack."

msgid ""
"This is an example production environment for a working OpenStack-Ansible "
"(OSA) deployment with high availability services."
msgstr ""
"Это пример рабочего окружения для развертывания OpenStack-Ansible (OSA) с "
"сервисами высокой доступности."

msgid "This is done by executing the following:"
msgstr "Это можно сделать выполнив:"

msgid "This issue is being tracked in an `oslo.messaging bug`_."
msgstr "Эта проблема отслеживается в `ошибке oslo.messaging`_."

msgid ""
"This method only requires a very small amount of configuration in "
"``user_variables.yml`` to point to the external ceph cluster monitors. The "
"whole configuration for ceph-ansible would live outside the OpenStack-"
"Ansible deployment and there is no duplication. The ``ceph_mons`` variable "
"expects a list of IP addresses for the Ceph Monitor servers in the external "
"ceph deployment:"
msgstr ""
"Этот метод требует лишь очень небольшого количества настроек в "
"``user_variables.yml`` для указания на внешние мониторы кластера ceph. Вся "
"конфигурация для ceph-ansible будет находиться вне развертывания OpenStack-"
"Ansible, и не будет никакого дублирования. Переменная ``ceph_mons`` ожидает "
"список IP-адресов для мониторов ceph во внешнем развертывании:"

msgid ""
"This section describes an example production environment for a working "
"OpenStack-Ansible (OSA) deployment with high availability services and using "
"the Ceph backend for images, volumes, and instances."
msgstr ""
"В данной секции описывается пример готового к эксплуатации окружения для "
"рабочего развертывания OpenStack-Ansible (OSA) с высокодоступными сервисами "
"и использованием Ceph хранилища для образов, дисков и инстансов."

msgid ""
"This section describes an example production environment for a working "
"OpenStack-Ansible (OSA) deployment with high availability services where "
"provider networks and connectivity between physical machines are routed "
"(layer 3)."
msgstr ""
"В данной секции описывается пример готового к эксплуатации окружения для "
"рабочего развертывания OpenStack-Ansible (OSA) с высокодоступными сервисами, "
"где сети провайдера и соединение между физическими серверами "
"маршрутизируются (layer 3)."

msgid ""
"This section provides an overview of hybrid messaging deployment concepts "
"and describes the necessary steps for a working OpenStack-Ansible (OSA) "
"deployment where RPC and Notify communications are separated and integrated "
"with different messaging server backends."
msgstr ""
"В этом разделе представлен обзор концепций развертывания гибридных сообщений "
"и описаны необходимые шаги для рабочего развертывания OpenStack-Ansible "
"(OSA), в котором RPC-коммуникации и сообщения Notify разделены и "
"интегрированы с различными серверными частями обмена сообщениями."

msgid ""
"This step applies particularly to existing ``x86_64`` environments when new "
"``aarch64`` compute nodes are added and it cannot be assumed that the "
"``hw_architecure`` property is applied to all Glance images as the operator "
"may not be in control of all image uploads."
msgstr ""
"Этот шаг особенно актуален для существующих сред ``x86_64``, когда "
"добавляются новые вычислительные узлы ``aarch64``, и нельзя предполагать, "
"что свойство ``hw_architecure`` применяется ко всем образам Glance, "
"поскольку оператор может не контролировать все загрузки образов."

msgid ""
"This will present a login page. By default, OpenStack-Ansible create a user "
"called ``admin``. The password will be the value of the "
"``keystone_auth_admin_password`` variable. If you did not configure this "
"variable, OpenStack-Ansible auto-generates one. You can view the configured "
"password in the ``/etc/openstack_deploy/user_secrets.yml`` file."
msgstr ""
"Это представит страницу входа. По умолчанию OpenStack-Ansible создает "
"пользователя с именем ``admin``. Паролем будет значение переменной "
"``keystone_auth_admin_password``. Если вы не настроили эту переменную, "
"OpenStack-Ansible сгенерирует ее автоматически. Вы можете просмотреть "
"настроенный пароль в файле ``/etc/openstack_deploy/user_secrets.yml``."

msgid "Three Availability Zones (AZs)"
msgstr "Три зоны доступности (AZ)"

msgid "Three Ceph OSD storage hosts"
msgstr "Три хоста под хранилище Ceph OSD"

msgid "Three Ceph storage clusters provisioned with Ceph Ansible."
msgstr "Три кластера хранения Ceph, подготовленные с помощью Ceph Ansible."

msgid "Three infrastructure (control plane) hosts"
msgstr "Три инфраструктурных (управляющих) хоста"

msgid "Three infrastructure (control plane) hosts with ceph-mon containers"
msgstr "Три инфраструктурных (управляющих) хоста с контейнерами ceph-mon"

msgid ""
"Three infrastructure (control plane) hosts, each host is placed in a "
"different Availability Zone"
msgstr ""
"Три инфраструктурных (управляющих) хоста, каждый хост размещен в отдельной "
"зоне доступности"

msgid ""
"To add OpenStack Services over and above the bootstrap-aio default services "
"for the applicable scenario, copy the ``conf.d`` files with the ``.aio`` "
"file extension into ``/etc/openstack_deploy`` and rename then to ``.yml`` "
"files. For example, in order to enable the OpenStack Telemetry services, "
"execute the following:"
msgstr ""
"Чтобы добавить сервисы OpenStack в дополнение к сервисам настраивающимся AIO "
"по умолчанию в рамках сценария, скопируйте файлы из директории ``conf.d`` с "
"расширением ``.aio`` в ``/etc/openstack_deploy`` и смените их расширение на "
"``.yml``. Например, для того, что бы подключить сервисы Telemetry OpenStack, "
"выполните следующее:"

msgid ""
"To add any global overrides, over and above the defaults for the applicable "
"scenario, edit ``/etc/openstack_deploy/user_variables.yml``. In order to "
"understand the various ways that you can override the default behaviour set "
"out in the roles, playbook and group variables, see :ref:`user-overrides`."
msgstr ""
"Для того, что бы глобально переопределить значения по умолчанию для "
"сценария, отредактируйте ``/etc/openstack_deploy/user_variables.yml``. Для "
"понимания различных способов переопределения стандартного поведения, "
"заданного в ролях, плейбуках и переменных групп, ознакомьтесь с :ref:`user-"
"overrides`."

msgid ""
"To address these challenges, the following changes to the basic design were "
"made:"
msgstr ""
"Для решения этих проблем были внесены следующие изменения в базовую "
"конструкцию:"

msgid ""
"To avoid downtime, it is recommended to enable "
"``openstack_service_accept_both_protocols`` until all services are "
"configured correctly. It allows HAProxy frontends to listen on both HTTP and "
"HTTPS."
msgstr ""
"Чтобы избежать простоя, рекомендуется включить "
"``openstack_service_accept_both_protocols``, пока все службы не будут "
"настроены правильно. Это позволяет фронтендам HAProxy прослушивать как HTTP, "
"так и HTTPS."

msgid ""
"To avoid unwanted QEMU emulation of non native architectures it is necessary "
"to ensure that only the native ``qemu-system-*`` binary is present on all "
"compute nodes. The simplest way to do this for existing deployments is to "
"use the system package manager to ensure that the unwanted binaries are "
"removed."
msgstr ""
"Чтобы избежать нежелательной эмуляции QEMU неродных архитектур, необходимо "
"убедиться, что на всех вычислительных узлах присутствует только родной "
"бинарный файл ``qemu-system-*``. Самый простой способ сделать это для "
"существующих развертываний — использовать системный менеджер пакетов, чтобы "
"убедиться, что нежелательные бинарные файлы удалены."

msgid ""
"To better understand why some configuration options were applied in examples "
"it is also recommended to look through :ref:`configuring-inventory`"
msgstr ""
"Чтобы лучше понять, почему некоторые параметры конфигурации были применены в "
"примерах, рекомендуется также просмотреть :ref:`configuring-inventory`"

msgid ""
"To change the default max age to 1 day, override the variable "
"``haproxy_security_headers_max_age`` in the ``/etc/openstack_deploy/"
"user_variables.yml`` file:"
msgstr ""
"Чтобы изменить максимальный возраст по умолчанию на 1 день, переопределите "
"переменную ``haproxy_security_headers_max_age`` в файле ``/etc/"
"openstack_deploy/user_variables.yml``:"

msgid ""
"To configure easy_install to use an alternative index, create the file `/"
"root/.pydistutils.cfg` with the following content."
msgstr ""
"Для настройки easy_install используйте альтернативный индекс, создайте файл "
"`/root/.pydistutils.cfg` со следующим содержанием."

msgid ""
"To deploy HAProxy in container we need to create a file ``/etc/"
"openstack_deploy/env.d/haproxy.yml`` with the following content:"
msgstr ""
"Для развертывания HAProxy в контейнере нам необходимо создать файл ``/etc/"
"openstack_deploy/env.d/haproxy.yml`` со следующим содержимым:"

msgid ""
"To deploy certificates with certbot, add the following to ``/etc/"
"openstack_deploy/user_variables.yml`` to enable the certbot function in the "
"HAProxy ansible role, and to create a new backend service called ``certbot`` "
"to service http-01 challenge requests."
msgstr ""
"Чтобы развернуть сертификаты с помощью certbot, добавьте следующее в ``/etc/"
"openstack_deploy/user_variables.yml``, чтобы включить функцию certbot в роли "
"HAProxy ansible, а также создать новую внутреннюю службу с именем "
"``certbot`` для обслуживания запросов http-01."

msgid ""
"To deploy user-provided certificates for RabbitMQ, copy the certificates to "
"the deployment host, edit the ``/etc/openstack_deploy/user_variables.yml`` "
"file and set the following three variables:"
msgstr ""
"Для установки определенных пользователем сертификатов на RabbitMQ, "
"скопируйте сертификаты на хост развертывания, отредактируйте файл ``/etc/"
"openstack_deploy/user_variables.yml`` и задайте следующие переменные:"

msgid ""
"To force a self-signed certificate to regenerate with every playbook run, "
"set the ``user_pki_regen_cert`` variable to ``true`` in the ``/etc/"
"openstack_deploy/user_variables.yml`` file:"
msgstr ""
"Чтобы принудительно регенерировать самоподписанный сертификат при каждом "
"запуске сценария, установите для переменной ``user_pki_regen_cert`` значение "
"``true`` в файле ``/etc/openstack_deploy/user_variables.yml``:"

msgid ""
"To force a self-signed certificate to regenerate with every playbook run, "
"set the appropriate regeneration option to ``true``.  For example, if you "
"have already run the ``haproxy`` playbook, but you want to regenerate the "
"self-signed certificate, set the ``haproxy_pki_regen_cert`` variable to "
"``true`` in the ``/etc/openstack_deploy/user_variables.yml`` file:"
msgstr ""
"Чтобы заставить самоподписанный сертификат регенерироваться при каждом "
"запуске playbook, установите соответствующий параметр регенерации в "
"``true``. Например, если вы уже запустили playbook ``haproxy``, но хотите "
"регенерировать самоподписанный сертификат, установите переменную "
"``haproxy_pki_regen_cert`` в ``true`` в файле ``/etc/openstack_deploy/"
"user_variables.yml``:"

msgid ""
"To force a self-signed certificate to regenerate, you can pass the variable "
"to ``openstack-ansible`` on the command line:"
msgstr ""
"Для принудительного обновления самоподписанного сертификата, вы можете "
"передать переменную ``openstack-ansible`` в командной строке:"

msgid ""
"To force the use of SSH instead of TLS for live migrations you must set the "
"``nova_libvirtd_listen_tls`` variable to ``0`` in the ``/etc/"
"openstack_deploy/user_variables.yml`` file:"
msgstr ""
"Чтобы принудительно использовать SSH вместо TLS для живых миграций, "
"необходимо установить переменную ``nova_libvirtd_listen_tls`` в ``0`` в "
"файле ``/etc/openstack_deploy/user_variables.yml``:"

msgid ""
"To generate user certificates, define a variable with the prefix "
"``user_pki_certificates_`` in the ``/etc/openstack_deploy/user_variables."
"yml`` file."
msgstr ""
"Для генерации пользовательских сертификатов определите переменную с "
"префиксом ``user_pki_certificates_`` в файле ``/etc/openstack_deploy/"
"user_variables.yml``."

msgid "To get your credentials, execute:"
msgstr "Для того, что бы получить данные доступа, выполните:"

msgid ""
"To help with the transition from unencrypted VNC to VeNCrypt, initially "
"noVNC proxy auth scheme allows for both encrypted and unencrypted sessions "
"using the variable `nova_vencrypt_auth_scheme`. This will be restricted to "
"VeNCrypt only in future versions of OpenStack-Ansible."
msgstr ""
"Чтобы помочь с переходом от незашифрованного VNC к VeNCrypt, изначально "
"схема аутентификации прокси noVNC допускает как зашифрованные, так и "
"незашифрованные сеансы с использованием переменной "
"`nova_vencrypt_auth_scheme`. Это будет ограничено VeNCrypt только в будущих "
"версиях OpenStack-Ansible."

msgid ""
"To not encrypt data from noVNC proxy to Compute nodes you must set the "
"``nova_qemu_vnc_tls`` variable to ``0`` in the ``/etc/openstack_deploy/"
"user_variables.yml`` file:"
msgstr ""
"Чтобы не шифровать данные из прокси-сервера noVNC на вычислительные узлы, "
"необходимо установить переменную ``nova_qemu_vnc_tls`` в ``0`` в файле ``/"
"etc/openstack_deploy/user_variables.yml``:"

msgid ""
"To regenerate a new self-signed certificate for a service, you must set the "
"``<servicename>_pki_regen_cert`` variable to true in one of the following "
"ways:"
msgstr ""
"Чтобы повторно создать новый самоподписанный сертификат для службы, "
"необходимо установить переменную ``<servicename>_pki_regen_cert`` в значение "
"true одним из следующих способов:"

msgid ""
"To regenerate a new self-signed certificate for a service, you must set the "
"``user_pki_regen_cert`` variable to true in one of the following ways:"
msgstr ""
"Чтобы повторно создать новый самоподписанный сертификат для службы, "
"необходимо установить переменную ``user_pki_regen_cert`` в значение true "
"одним из следующих способов:"

msgid ""
"To regenerate the certificate authority you must set the "
"``openstack_pki_regen_ca`` variable to either the name of the root CA or "
"intermediate CA you wish or regenerate, or to ``true`` to regenerate all "
"self-signed certificate authorities."
msgstr ""
"Чтобы повторно сгенерировать центр сертификации, необходимо установить "
"переменную ``openstack_pki_regen_ca``либо на имя корневого центра "
"сертификации или промежуточного центра сертификации, который вы хотите "
"повторно сгенерировать, либо на ``true``, чтобы повторно сгенерировать все "
"самоподписанные центры сертификации."

msgid ""
"To set the CSP policy to report only by overriding the "
"``haproxy_security_headers_csp_report_only`` variable to ``True`` in the ``/"
"etc/openstack_deploy/user_variables.yml`` file:"
msgstr ""
"Чтобы настроить политику CSP на создание отчетов только путем "
"переопределения переменной ``haproxy_security_headers_csp_report_only`` на "
"``True`` в файле ``/etc/openstack_deploy/user_variables.yml``:"

msgid "Tunnel (Geneve) IP"
msgstr "IP туннеля (Geneve)"

msgid "Tunnel (VXLAN) IP"
msgstr "Туннелированный (VXLAN) IP"

msgid "Tunnel (VXLAN) Network"
msgstr "Туннелированная (VXLAN) сеть"

msgid "Tunnel networks which are reachable between Availability Zones"
msgstr "Туннелированные сети, доступные между зонами доступности"

msgid ""
"Two additional settings in /etc/nova/nova.conf in all Nova API instances:"
msgstr ""
"Две дополнительные настройки в /etc/nova/nova.conf для всех Nova API "
"сервисов:"

msgid "Two compute hosts"
msgstr "Два хоста под вычислительные ресурсы"

msgid ""
"Typically these tools read environment variables containing proxy server "
"settings. These environment variables can be configured in ``/etc/"
"environment`` if required."
msgstr ""
"Обычно эти инструменты считывают переменные окружения, содержащие настройки "
"прокси сервера. Эти переменные окружения, при необходимости, можно задать в "
"``/etc/environment``."

msgid "Undocumented Behaviour Alert!"
msgstr "Предупреждение о недокументированом поведении!"

msgid "Unreliable or low bandwidth external connectivity"
msgstr "Ненадежное или медленное внешнее соединение"

msgid "Update HAProxy"
msgstr "Обновите HAProxy"

msgid "Upload images to Glance."
msgstr "Загрузите образы в Glance."

msgid "Upstream Ubuntu repositories to mirror for Ubuntu 22.04 LTS:"
msgstr "Репозитории Ubuntu для зеркалирования на примере Ubuntu 22.04 LTS:"

msgid ""
"Use custom path for ``/etc/openstack_deploy`` directory. You can place "
"OpenStack-Ansible configuration directory inside user home directory. For "
"that you will need to define the following environment variable:"
msgstr ""
"Используйте произвольный путь для каталога ``/etc/openstack_deploy``. Вы "
"можете разместить каталог конфигурации OpenStack-Ansible внутри домашнего "
"каталога пользователя. Для этого вам нужно будет определить следующую "
"переменную среды:"

msgid ""
"Use the following process to add a ``security.txt`` file to your deployment "
"using OpenStack-Ansible:"
msgstr ""
"Используйте следующий процесс для добавления файла ``security.txt`` в ваше "
"развертывание с помощью OpenStack-Ansible:"

msgid ""
"Use the following process to deploy user-provided SSL certificates in "
"OpenStack-Ansible:"
msgstr ""
"Используйте следующий подход для установки собственных SSL сертификатов в "
"OpenStack-Ansible:"

msgid "User Guide"
msgstr "Руководство пользователя"

msgid "User variables"
msgstr "Пользовательские переменные"

msgid "User-provided certificates"
msgstr "Сертификаты, предоставленные пользователем"

msgid "Using Let's Encrypt"
msgstr "Использование Let's Encrypt"

msgid "Using a GUI"
msgstr "Использование графического интерфейса"

msgid "Using a client or library"
msgstr "Использование клиента или библиотеки"

msgid "Using domain (or path) based endpoints instead of port-based"
msgstr ""
"Использование точек доступа на основе домена (или пути) вместо точек входа "
"на основе порта"

msgid "Using radosgw as a drop-in replacement for Swift"
msgstr "Использование radosgw, как замены Swift"

msgid "Using this username and password combination, log in to Horizon."
msgstr ""
"Используя эту комбинацию имени пользователя и пароля, войдите в Horizon."

msgid "VLAN"
msgstr "VLAN"

msgid ""
"Variables ``haproxy_security_child_src_records`` and "
"``haproxy_security_connect_src_records`` are only available staring with "
"2024.2 (Dalmatian) version. You need to override "
"``haproxy_security_headers_csp`` as a whole for earlier releases"
msgstr ""
"Переменные ``haproxy_security_child_src_records`` и "
"``haproxy_security_connect_src_records`` доступны только начиная с версии "
"2024.2 (Dalmatian). Для более ранних версий вам необходимо полностью "
"переопределить ``haproxy_security_headers_csp``"

msgid "Virtual machines with SSD storage: ~ 45-60 minutes"
msgstr "Виртуальные серверы с SSD диском: ~45-60 минут"

msgid ""
"We also need to define a complete new set of groups for Ceph, to deploy "
"multiple independent instances of it."
msgstr ""
"Нам также необходимо определить совершенно новый набор групп для Ceph, чтобы "
"развернуть несколько его независимых инстансов."

msgid ""
"We also need to define a couple of extra Keepalived instances in order to "
"secure DNS RR approach, along with configuring Keepalived in unicast mode. "
"For that create a file ``/etc/openstack_deploy/group_vars/haproxy/keepalived."
"yml`` with following content:"
msgstr ""
"Нам также нужно определить несколько дополнительных инстансов Keepalived для "
"обеспечения подхода DNS RR, а также настроить Keepalived в одноадресном "
"режиме. Для этого создайте файл ``/etc/openstack_deploy/group_vars/haproxy/"
"keepalived.yml`` со следующим содержимым:"

msgid "We need to make adjustments to each HAProxy service definition to:"
msgstr ""
"Нам необходимо внести изменения в каждое определение службы HAProxy, чтобы:"

msgid ""
"We recommend you set your ``/etc/environment`` variables with proxy settings "
"before launching any scripts or playbooks to avoid failure."
msgstr ""
"Мы рекомендуем задать ваши переменные окружения с настройками прокси в ``/"
"etc/environment`` перед запуском каких-либо скриптов или плейбуков что бы "
"избежать ошибок."

msgid ""
"We suggest referring to each service api-paste.ini for more details on how "
"to properly configure overrides."
msgstr ""
"Мы рекомендуем обратиться к api-paste.ini каждой службы для получения более "
"подробной информации о том, как правильно настроить переопределения."

msgid ""
"When building an AIO on a new server, it is recommended that all system "
"packages are upgraded and then reboot into the new kernel:"
msgstr ""
"Перед установкой AIO на новый сервер, рекомендуется обновить все системные "
"пакеты и после этого выполнить перезагрузку в новое ядро:"

msgid ""
"When creating a custom group, first create a skeleton in ``/etc/"
"openstack_deploy/env.d/``. The following is an example of an inventory "
"skeleton for a group named ``custom2_hosts`` that will consist of bare metal "
"hosts, and has been created at ``/etc/openstack_deploy/env.d/custom2_hosts."
"yml``."
msgstr ""
"Когда создается пользовательская группа, сначала создайте структуру в ``/etc/"
"openstack_deploy/env.d/``. Следующий пример содержит в себе структуру "
"inventory для группы с названием ``custom2_hosts``, который будет состоять "
"из физических серверов и создан в ``/etc/openstack_deploy/env.d/"
"custom2_hosts.yml``."

msgid ""
"When deploying RabbitMQ with support for quorum and stream queues, the "
"retention behaviour for messages changes. Stream queues maintain an append "
"only log on disk of all messages received until a retention policy indicates "
"they should be disposed of. By default, this policy is set with a per-stream "
"`x-max-age` of 1800 seconds. However, as noted in the `RabbitMQ docs`_, this "
"only comes into effect ones a stream has accumulated enough messages to fill "
"a segment, which has a default size of 500MB."
msgstr ""
"При развертывании RabbitMQ с поддержкой очередей кворума и потоков, "
"поведение хранения сообщений меняется. Потоковые очереди поддерживают журнал "
"только для добавления на диск всех полученных сообщений до тех пор, пока "
"политика хранения не укажет, что их следует удалить. По умолчанию эта "
"политика установлена ​​с `x-max-age` для каждого потока в 1800 секунд. Однако, "
"как отмечено в `документации RabbitMQ`_, это вступает в силу только тогда, "
"когда поток накопил достаточно сообщений для заполнения сегмента, размер "
"которого по умолчанию составляет 500 МБ."

msgid ""
"When deploying with OpenStack-Ansible, you can either use self-signed "
"certificates that are generated during the deployment process or provide SSL "
"certificates, keys, and CA certificates from your own trusted certificate "
"authority. Highly secured environments use trusted, user-provided "
"certificates for as many services as possible."
msgstr ""
"Во время развертывания с OpenStack-Ansible вы можете либо использовать "
"самоподписанные сертификаты, которые будут сгенерированы во время процесса "
"развертывания, либо предоставить SSL сертификаты, ключи и промежуточные "
"сертификаты для вашего доверенного центра сертификации. Высокозащищенные "
"окружения используют доверенные сертификаты, предоставленные пользователями, "
"для максимально возможного количества сервисов."

msgid ""
"When enabled HAProxy will use the same TLS certificate on all interfaces "
"(internal and external). It is not currently possible in OpenStack-Ansible "
"to use different self-signed or user-provided TLS certificates on different "
"HAProxy interfaces."
msgstr ""
"При включении HAProxy будет использовать один и тот же сертификат TLS на "
"всех интерфейсах (внутренних и внешних). В настоящее время в OpenStack-"
"Ansible невозможно использовать различные самоподписанные или "
"предоставленные пользователем сертификаты TLS на различных интерфейсах "
"HAProxy."

msgid ""
"When running OpenStack-Ansible in network environments that block internet "
"connectivity, we recommend the following set of practices and configuration "
"overrides for deployers to use."
msgstr ""
"При запуске OpenStack-Ansible в окружениях, которые блокируют интернет "
"соединение, мы рекомендуем использовать следующий набор практик и "
"переопределений настроек для использования."

msgid ""
"When using VNC for console access there are 3 connections to secure, client "
"to HAProxy, HAProxy to noVNC Proxy and noVNC Proxy to Compute nodes. The "
"`OpenStack Nova Docs for remote console access`_ cover console security in "
"much more detail."
msgstr ""
"При использовании VNC для доступа к консоли необходимо защитить 3 "
"соединения: клиент к HAProxy, HAProxy к noVNC Proxy и noVNC Proxy к "
"вычислительным узлам. В `OpenStack Nova Docs for remote console access`_ "
"безопасность консоли рассматривается гораздо более подробно."

msgid ""
"When using federated login you will need to override the default Content "
"Security Policy to allow access to your authorisation server by overriding "
"the ``haproxy_horizon_csp`` variable in the ``/etc/openstack_deploy/"
"user_variables.yml`` file:"
msgstr ""
"При использовании федеративного входа вам потребуется переопределить "
"политику безопасности контента по умолчанию, чтобы разрешить доступ к вашему "
"серверу авторизации, переопределив переменную ``haproxy_horizon_csp`` в "
"файле ``/etc/openstack_deploy/user_variables.yml``:"

msgid ""
"When you deployed Gnocchi on multiple servers to distribute the work, add "
"Zookeeper as coordination backend. To setup Zookeeper, you can use `this "
"ansible role`_."
msgstr ""
"Когда вы установили Gnocchi на нескольких серверах для распределения работы, "
"добавьте Zookeper для координации. Для установки Zookeeper, вы можете "
"использовать `эту ansible роль`_."

msgid ""
"When your Swift API endpoint uses Ceph as a backend, the only one left for "
"this setup is Redis."
msgstr ""
"Если эндпойнт Swift API использует Ceph в качестве бекэнда, для этой "
"настройки остается только Redis."

msgid ""
"While path-based endpoints might look tempting due to using FQDN and thus "
"not having the need for wildcard TLS, they are harder to maintain and more "
"complex to set up. Also worth mentioning, that not all services are ready to "
"support path-based endpoints, despite this approach being used in devstack."
msgstr ""
"Хотя точки доступа на основе пути могут выглядеть заманчиво из-за "
"использования FQDN и, таким образом, отсутствия необходимости в wildcard "
"TLS, их сложнее поддерживать и настраивать. Также стоит упомянуть, что не "
"все службы готовы поддерживать точки доступа на основе пути, несмотря на то, "
"что этот подход используется в devstack."

msgid ""
"While these are all changes, that need to be done in ``openstack_user_config."
"yml``, there is one more override that needs to be applied."
msgstr ""
"Хотя все эти изменения необходимо внести в ``openstack_user_config.yml``, "
"необходимо применить еще одно переопределение."

msgid ""
"While this is the simplest approach, as it does not require any extra "
"configuration and is easy to start with, it also has some disadvantages. For "
"example, some clients or organizations might not be allowed to connect to "
"custom ports which completely disables the ability to use them in such "
"deployments."
msgstr ""
"Хотя это самый простой подход, так как он не требует дополнительной "
"настройки и прост в запуске, он также имеет некоторые недостатки. Например, "
"некоторым клиентам или организациям может быть запрещено подключаться к "
"произвольным портам, что полностью отключает возможность их использования в "
"таких развертываниях."

msgid ""
"While you can consider having a wildcard or SAN TLS certificate for the "
"domain to cover all service endpoints in this setup, it is still possible to "
"use Let's Encrypt certificates with dns-01 authentication or by supplying a "
"list of subdomains which issued certificate will cover."
msgstr ""
"Хотя вы можете рассмотреть возможность использования wildcard сертификата "
"или сертификата SAN TLS для домена, чтобы охватить все точки доступа службы "
"в этой настройке, по-прежнему можно использовать сертификаты Let's Encrypt с "
"аутентификацией dns-01 или предоставить список поддоменов, на которые будет "
"распространяться выданный сертификат."

msgid ""
"With changes made to ``haproxy_<service>_service_overrides`` variable you "
"need to re-run a service-specific playbook with `haproxy-service-config` "
"tag, for example ``openstack-ansible openstack.osa.keystone --tags haproxy-"
"service-config``."
msgstr ""
"После внесения изменений в переменную "
"``haproxy_<service>_service_overrides`` вам необходимо повторно запустить "
"сценарий для конкретной службы с тегом `haproxy-service-config`, например "
"``openstack-ansible openstack.osa.keystone --tags haproxy-service-config``."

msgid ""
"With content like below, where N should be AZ number depending on the file:"
msgstr ""
"С контентом как указано ниже, где N должен быть номером AZ в зависимости от "
"файла:"

msgid ""
"With that, the only correct approach here would be to adjust ``api-paste."
"ini`` for each respective service. But, Keystone specifically, does not "
"support api-paste.ini files. So the only way around it is actually a uWSGI "
"rewrite and to define a `public_endpoint` in `keystone.conf`:"
msgstr ""
"При этом единственным правильным подходом здесь будет настройка ``api-paste."
"ini`` для каждой соответствующей службы. Но, в частности, Keystone не "
"поддерживает файлы api-paste.ini. Поэтому единственный способ обойти это — "
"фактически использовать uWSGI rewrite и определить `public_endpoint` в "
"`keystone.conf`:"

msgid ""
"Within defined provider networks, ``address_prefix`` is used to override the "
"prefix of the key added to each host that contains IP address information. "
"This should usually be one of either ``container``, ``tunnel``, or "
"``storage``. ``reference_group`` contains the name of a defined pod group "
"and is used to limit the scope of each provider network to that group."
msgstr ""
"С определенными сетями провайдера, ``address_prefix`` используется для "
"переопределения префикса ключа, добавленного на каждый хост, который "
"содержит информацию об IP адресе. Это, обычно, должен быть один из "
"``container``, ``tunnel`` или ``storage``.  ``reference_group`` содержит имя "
"определенной группы и используется для ограничения зоны видимости каждой "
"сети провайдера к данной группе."

msgid ""
"Within defined provider networks, ``address_prefix`` is used to override the "
"prefix of the key added to each host that contains IP address information. "
"We use AZ-specific prefixes for ``container``, ``tunnel``, or ``storage``. "
"``reference_group`` contains the name of a defined AZ group and is used to "
"limit the scope of each provider network to that group."
msgstr ""
"Внутри определенных сетей провайдера `` address_prefix`` используется для "
"переопределения префикса ключа, добавленного к каждому хосту, который "
"содержит информацию IP -адреса. Мы используем AZ-специфические префиксы для "
"`` necuter``, `` tunnel`` или `` storage``. `` reference_group`` содержит "
"имя определенной группы AZ и используется для ограничения объема каждой сети "
"провайдера этой группой."

msgid "Withstand a single Availability Zone failure"
msgstr "Выдерживание отказа одной зоны доступности"

msgid ""
"Write the contents of the ``security.txt`` file in accordance with the "
"standard."
msgstr ""
"Запишите содержимое файла ``security.txt`` в соответствии со стандартом."

msgid "X-Content-Type-Options"
msgstr "X-Content-Type-Options"

msgid ""
"YAML Anchors and Aliases are used heavily in the example below to populate "
"all groups that might become handy while not repeating hosts definitions "
"each time. You can read more about the topic in `Ansible Documentation "
"<https://docs.ansible.com/ansible/latest/playbook_guide/"
"playbooks_advanced_syntax.html#yaml-anchors-and-aliases-sharing-variable-"
"values>`_"
msgstr ""
"Якоря и алиасы YAML широко используются в примере ниже для заполнения всех "
"групп, которые могут стать удобными, одновременно не повторяя определения "
"хостов каждый раз. Вы можете прочитать больше по теме в `Ansible "
"Documentation <https://docs.ansible.com/ansible/latest/playbook_guide/"
"playbooks_advanced_syntax.html#yaml-anchors-and-aliases-sharing-variable-"
"values>`_"

msgid ""
"You also have to configure Ceilometer to actually query radosgw. When your "
"ceilometer isn't configured to poll everything, add these pollsters to your "
"polling.yml file:"
msgstr ""
"Также необходимо настроить Ceilometer для непосредственного опроса radosgw. "
"Если ceilometer не настроен опрашивать все доступные метрики, добавьте "
"следующие метрики для опроса в файл polling.yaml:"

msgid "You also have to install additional packages:"
msgstr "Вам также может потребоваться установить дополнительные пакеты:"

msgid ""
"You also have to install additional pip/distro packages to use the redis "
"cluster:"
msgstr ""
"Вам также потребуется установить дополнительные pip/системные пакеты для "
"использования redis кластера:"

msgid ""
"You also might need to take care of expanding CN names for issued SAN "
"certificate by the PKI role. For that you will have to override "
"``haproxy_vip_binds`` variable like in example below:"
msgstr ""
"Вам также может понадобиться позаботиться о расширении имен CN для выданных "
"SAN-сертификатов ролью PKI. Для этого вам придется переопределить переменную "
"``haproxy_vip_binds``, как в примере ниже:"

msgid ""
"You also might want to adjust HSTS headers defined by "
"``haproxy_security_headers_csp`` variable. While default rules do allow "
"subdomains out of the box, you might want to restrict records a bit more to "
"disallow access on arbitrary ports."
msgstr ""
"Вы также можете захотеть настроить заголовки HSTS, определенные переменной "
"``haproxy_security_headers_csp``. Хотя правила по умолчанию разрешают "
"поддомены из коробки, вы можете захотеть ограничить записи немного больше, "
"чтобы запретить доступ к произвольным портам."

msgid ""
"You can add environment variables from that section to ``user.rc`` file "
"inside openstack_deploy folder (``${OSA_CONFIG_DIR}/user.rc``). ``user.rc`` "
"file is sourced each time you run ``openstack-ansible`` binary."
msgstr ""
"Вы можете добавить переменные среды из этого раздела в файл ``user.rc`` "
"внутри папки openstack_deploy (``${OSA_CONFIG_DIR}/user.rc``). Файл ``user."
"rc`` создается каждый раз при запуске бинарного файла ``openstack-ansible``."

msgid ""
"You can also add the environment variable to ``user.rc`` file inside "
"openstack_deploy folder (``${OSA_CONFIG_DIR}/user.rc``). ``user.rc`` file is "
"sourced each time you run ``openstack-ansible`` binary."
msgstr ""
"Вы также можете добавить переменную среды в файл ``user.rc`` внутри папки "
"openstack_deploy (``${OSA_CONFIG_DIR}/user.rc``). Файл ``user.rc`` создается "
"каждый раз при запуске бинарного файла ``openstack-ansible``."

msgid ""
"You can also declare a custom group for each pod that will also include all "
"containers from hosts that belong to this pod. This might be handy if you "
"want to define some variable for all hosts in the pod using group_variables."
msgstr ""
"Вы также можете объявить произвольную группу для каждого pod-а, которая "
"будет в том числе включать все контейнеры с хостов, которые принадлежат "
"данному pod-у. Это может быть удобно, если вы хотите определить переменные "
"для всех хостов, которые расположены в pod-е через group_vars."

msgid ""
"You can apply security hardening configurations to an existing environment "
"or audit an environment by using a playbook supplied with OpenStack-Ansible:"
msgstr ""
"Вы можете применить настройки усиления безопасности к существующему "
"окружению или провести аудит окружения при помощи предоставляемого OpenStack-"
"Ansible-ом плейбука:"

msgid ""
"You can avoid usage of the ``root`` user on a deployment by following these "
"guidelines:"
msgstr ""
"Вы можете избежать использования пользователя ``root`` при развертывании, "
"следуя следующим рекомендациям:"

msgid ""
"You can create a bridge manually or leverage our systemd_networkd role which "
"is capable of configuring required networking on hosts."
msgstr ""
"Вы можете создать мост вручную или использовать нашу роль systemd_networkd, "
"которая способна настраивать необходимые сетевые подключения на хостах."

msgid "You can do that following in multiple ways:"
msgstr "Вы можете сделать это различными способами:"

msgid "You have to add some pip packages to your gnocchi setup:"
msgstr ""
"Вам необходимо добавить несколько pip пакетов к вашей установке gnocchi:"

msgid ""
"You may also want to add the ``rgw_dns_name`` option if you want to enable "
"bucket hostnames with the S3 API."
msgstr ""
"Вы, возможно, также захотите добавить параметр ``rgw_dns_name``, что бы "
"включить имя серверов вместе с S3 API."

msgid ""
"You may be tempted to copy the ``openrc`` or ``clouds.yaml`` files created "
"by the ``openstack_openrc`` role. However, these files use the ``internal`` "
"`interface`__ by default. This interface use the management network "
"(``172.29.236.0/22``) , which is not routable from outside the host. If you "
"wish to use these files, you will need to change the interface to ``public``."
msgstr ""
"У вас может возникнуть желание скопировать файлы ``openrc`` или ``clouds."
"yaml``, созданные ролью ``openstack_openrc``. Однако эти файлы по умолчанию "
"используют ``internal`` `interface`__. Этот интерфейс использует сеть "
"управления (``172.29.236.0/22``), которая не маршрутизируется извне хоста. "
"Если вы хотите использовать эти файлы, вам нужно будет изменить интерфейс на "
"``public``."

msgid ""
"You may choose to operate and maintain mirrors of OpenStack-Ansible and "
"OpenStack dependencies. Mirrors often provide a great deal of risk "
"mitigation by reducing dependencies on resources and systems outside of your "
"direct control. Mirrors can also provide greater stability, performance and "
"security."
msgstr ""
"Вы можете управлять и поддерживать зеркала OpenStack-Ansible и зависимостей "
"OpenStack. Зеркала обычно предоставляют значительное снижение рисков путем "
"уменьшения зависимости от ресурсов и систем вне вашего прямого контроля. "
"Зеркала также могут дать более высокую стабильность, производительность и "
"безопасность."

msgid ""
"You may want to enable the default radosgw S3 API, in addition to the Swift "
"API. In order to do so, you need to override the ``ceph_conf_overrides_rgw`` "
"variable in ``user_variables.yml``. Below is an example configuration "
"snippet:"
msgstr ""
"Вы можете захотеть подключить стандартный для radosgw S3 API, в дополнение к "
"Swift API. Что бы сделать это, вам необходимо переопределить переменную "
"``ceph_conf_overrides_rgw`` в ``user_variables.yml``. Ниже вы можете найти "
"фрагмент конфигурации в качестве примера:"

msgid ""
"You might encounter an error while running the Ansible bootstrap script when "
"building some of the Python extensions (like pycrypto) which says:"
msgstr ""
"Вы можете столкнуться с ошибками во время выполнения скрипта начальной "
"подготовки Ansible, во время установки некоторых модулей Python (таких как "
"pycrypto), например:"

msgid "Zookeeper for coordination"
msgstr "Zookeeper для координации"

msgid "`<service>_service_adminuri`"
msgstr "`<service>_service_adminuri`"

msgid "`<service>_service_internaluri`"
msgstr "`<service>_service_internaluri`"

msgid "`<service>_service_publicuri`"
msgstr "`<service>_service_publicuri`"

msgid "``/etc/openstack_deploy/group_vars/az1_all.yml``"
msgstr "``/etc/openstack_deploy/group_vars/az1_all.yml``"

msgid "``/etc/openstack_deploy/group_vars/az2_all.yml``"
msgstr "``/etc/openstack_deploy/group_vars/az2_all.yml``"

msgid "``/etc/openstack_deploy/group_vars/az3_all.yml``"
msgstr "``/etc/openstack_deploy/group_vars/az3_all.yml``"

msgid "``apt-get`` proxy configuration"
msgstr "Настройка прокси для ``apt-get``"

msgid "``azN_all`` that will contain `azN_hosts` and `azN_containers` members"
msgstr ""
"``azN_all``, который содержит членов групп `azN_hosts` и `azN_containers`"

msgid "``azN_containers`` that will contain all containers that are spawned on"
msgstr ""
"``azN_containers``, которые будут содержать все контейнеры, которые "
"создаются на"

msgid "``azN_hosts`` which will contain only bare metal nodes"
msgstr "``azN_hosts``, которые будет содержать только физические узлы"

msgid ""
"``podN_all`` that will contain `podN_hosts` and `podN_containers` members"
msgstr ""
"``podN_all`` который содержит членов групп `podN_hosts` и `podN_containers`"

msgid ""
"``podN_containers`` that will contain all containers that are spawned on"
msgstr ""
"``podN_hosts`` будет содержать все контейнеры, которые запущенны на "
"физических нодах"

msgid "``podN_hosts`` which will contain only bare metal nodes"
msgstr "``podN_hosts`` будет содержать только физические узлы"

msgid "`curl`"
msgstr "`curl`"

msgid "`openstack`"
msgstr "`openstack`"

msgid "`wget`"
msgstr "`wget`"

msgid "a development environment"
msgstr "окружения для разработки"

msgid "a simple lab deployment"
msgstr "простое лабораторное развертывание"

msgid "an overview of how all of the OpenStack services fit together"
msgstr "обзор того, как все службы OpenStack взаимодействую друг с другом"

msgid "az1_ceph1"
msgstr "az1_ceph1"

msgid "az1_ceph2"
msgstr "az1_ceph2"

msgid "az1_ceph3"
msgstr "az1_ceph3"

msgid "az1_compute1"
msgstr "az1_compute1"

msgid "az1_compute2"
msgstr "az1_compute2"

msgid "az1_pin_compute1"
msgstr "az1_pin_compute1"

msgid "az1_pin_compute2"
msgstr "az1_pin_compute2"

msgid "az2_ceph1"
msgstr "az2_ceph1"

msgid "az2_ceph2"
msgstr "az2_ceph2"

msgid "az2_ceph3"
msgstr "az2_ceph3"

msgid "az2_compute1"
msgstr "az2_compute1"

msgid "az2_compute2"
msgstr "az2_compute2"

msgid "az3_ceph1"
msgstr "az3_ceph1"

msgid "az3_ceph2"
msgstr "az3_ceph2"

msgid "az3_ceph3"
msgstr "az3_ceph3"

msgid "az3_compute1"
msgstr "az3_compute1"

msgid "az3_compute3"
msgstr "az3_compute3"

msgid "bare metal nodes, that are part of the pod."
msgstr "физические серверы, которые являются частью pod-а."

msgid "compute1"
msgstr "compute1"

msgid "compute2"
msgstr "compute2"

msgid ""
"connecting to your own pre-deployed ceph cluster by pointing to its "
"information in ``user_variables.yml`` and allowing OpenStack-Ansible to ssh "
"to the ceph monitors to retrieve the contents of ceph.conf and the keyrings."
msgstr ""
"подключение к вашему собственному предварительно развернутому кластеру ceph "
"путем указания его информации в ``user_variables.yml`` и разрешение "
"OpenStack-Ansible подключиться по ssh к мониторам ceph для получения "
"содержимого ceph.conf и связок ключей."

msgid ""
"connecting to your own pre-deployed ceph cluster by pointing to its monitors "
"in ``user_variables.yml`` as above and providing data to populate ceph.conf "
"and ceph keyring files on the deploy host. This is described `here <https://"
"docs.openstack.org/openstack-ansible-ceph_client/latest/config-from-file."
"html>`_. No ssh access by OpenStack-Ansible is required to the ceph cluster."
msgstr ""
"подключение к вашему собственному предварительно развернутому кластеру ceph "
"путем указания его мониторов в ``user_variables.yml``, как указано выше, и "
"предоставление данных для заполнения файлов ceph.conf и ceph keyring на "
"хосте развертывания. Это описано `здесь <https://docs.openstack.org/"
"openstack-ansible-ceph_client/latest/config-from-file.html>`_. Доступ "
"OpenStack-Ansible по ssh к кластеру ceph не требуется."

msgid ""
"deploying a ceph cluster as part of the OpenStack-Ansible deployment by "
"using the roles maintained by the `Ceph-Ansible`_ project. Deployers can "
"enable the ``ceph-install.yml`` playbook by adding hosts to the ``ceph-"
"mon_hosts`` and ``ceph-osd_hosts`` groups in ``openstack_user_config.yml``. "
"In order to enable ``ceph-rgw-install.yml`` playbook you need to add ``ceph-"
"rgw_hosts`` in ``openstack_user_config.yml``."
msgstr ""
"развертывание кластера ceph как части развертывания OpenStack-Ansible с "
"использованием ролей, поддерживаемых проектом `Ceph-Ansible`_. Операторы "
"могут включить ``ceph-install.yml``, добавив хосты в группы ``ceph-"
"mon_hosts`` и ``ceph-osd_hosts`` в ``openstack_user_config.yml``. Чтобы "
"включить ``ceph-rgw-install.yml``, вам нужно добавить ``ceph-rgw_hosts`` в "
"``openstack_user_config.yml``."

msgid "https://dl.cloudsmith.io/public/rabbitmq/rabbitmq-erlang"
msgstr "https://dl.cloudsmith.io/public/rabbitmq/rabbitmq-erlang"

msgid "https://dl.cloudsmith.io/public/rabbitmq/rabbitmq-server"
msgstr "https://dl.cloudsmith.io/public/rabbitmq/rabbitmq-server"

msgid ""
"https://docs.openstack.org/performance-docs/latest/test_results/"
"telemetry_gnocchi_with_ceph/index.html"
msgstr ""
"https://docs.openstack.org/performance-docs/latest/test_results/"
"telemetry_gnocchi_with_ceph/index.html"

msgid "https://download.ceph.com"
msgstr "https://download.ceph.com"

msgid "https://downloads.mariadb.com/MariaDB"
msgstr "https://downloads.mariadb.com/MariaDB"

msgid "https://ubuntu-cloud.archive.canonical.com/ubuntu"
msgstr "https://ubuntu-cloud.archive.canonical.com/ubuntu"

msgid "infra1"
msgstr "infra1"

msgid "infra2"
msgstr "infra2"

msgid "infra3"
msgstr "infra3"

msgid "jammy"
msgstr "jammy"

msgid "jammy-updates"
msgstr "jammy-updates"

msgid "lb_vip_address"
msgstr "lb_vip_address"

msgid "log1"
msgstr "log1"

msgid "osd1"
msgstr "osd1"

msgid "osd2"
msgstr "osd2"

msgid "osd3"
msgstr "osd3"

msgid "oslo.messaging library"
msgstr "Библиотека oslo.messaging"

msgid "security.txt"
msgstr "security.txt"

msgid ""
"security.txt is a proposed `IETF standard`_ to allow independent security "
"researchers to easily report vulnerabilities. The standard defines that a "
"text file called ``security.txt`` should be found at \"/.well-known/security."
"txt\". For legacy compatibility reasons the file might also be placed at \"/"
"security.txt\"."
msgstr ""
"security.txt — это предложенный `стандарт IETF`_, позволяющий независимым "
"исследователям безопасности легко сообщать об уязвимостях. Стандарт "
"определяет, что текстовый файл с именем ``security.txt`` должен находиться "
"по адресу \"/.well-known/security.txt\". Для совместимости с устаревшими "
"версиями файл также может находиться по адресу \"/security.txt\"."

msgid "storage1"
msgstr "storage1"
